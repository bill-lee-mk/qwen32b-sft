{
  "total": 237,
  "total_submitted": 237,
  "valid_score_count": 237,
  "error_count": 0,
  "scores": [
    0.96,
    0.74,
    0.95,
    0.95,
    0.6,
    0.3,
    0.96,
    0.95,
    0.95,
    0.94,
    0.95,
    0.74,
    0.96,
    0.6,
    0.6,
    0.75,
    0.74,
    0.6,
    0.75,
    0.95,
    0.6,
    0.0,
    0.6,
    0.72,
    0.95,
    0.0,
    0.0,
    0.0,
    0.0,
    0.6,
    0.96,
    0.74,
    0.0,
    0.0,
    0.94,
    0.0,
    0.0,
    0.0,
    0.0,
    0.96,
    0.0,
    0.6,
    0.6,
    0.42,
    0.0,
    0.6,
    0.74,
    0.0,
    0.0,
    0.0,
    0.74,
    0.0,
    0.96,
    0.0,
    0.0,
    0.6,
    0.0,
    0.6,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0
  ],
  "results": [
    {
      "request_id": "c08714c7-ac6f-4831-90d8-00bf22fb9112",
      "evaluations": {
        "diverse_000": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.96,
              "internal_reasoning": "Step 1: Identify item type → Standalone MCQ practice/assessment. No pre-attempt giveaways; explanation is metadata.\nStep 2 – Issues: Ran checklists.\n- Checklist A (Field Consistency): Answer key = B; explanation says “Shiny is an adjective ...” matching the stem and options. No mismatches.\n- Checklist B1 (Answer Giveaway): None in student-facing text. Explanation is post-attempt metadata. Not a worked example, but no giveaway present.\n- Checklist B2 (Stimulus Quality): No stimulus.\n- Checklist C (Diction/Typo): Minor trailing comma inside the quoted sentence (\"...table,\") but it does not impede understanding; no ambiguity.\nNo issues identified that warrant any metric failure.\nScoring per rules: All binary metrics = 1.0. Overall must be within 0.85–1.0; choose 0.96 (solid quality, minor polish possible).",
              "reasoning": "High-quality Grade 3 ELA item assessing the function of an adjective in context. Correct answer and rationale are accurate and consistent. Clear stem and well-constructed, plausible distractors aligned to common misconceptions. Appropriate difficulty for an “easy” item under L.3.1.A. Minor polish opportunity (punctuation, phrasing) but no substantive issues.",
              "suggested_improvements": "Polish suggestions: 1) Remove the trailing comma in the quoted sentence (“The shiny coin rolled under the table.”). 2) Consider more student-friendly phrasing in the stem: e.g., “What kind of word is ‘shiny’ in this sentence?” or “What does the word ‘shiny’ do in this sentence?”"
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The word “shiny” functions as an adjective modifying “coin.” Answer key = B matches. Explanation aligns with options and stem. No contradictions or mismatches.",
              "reasoning": "The labeled correct answer and explanation are correct and consistent with the sentence.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Assesses identification of adjective function within a simple sentence, directly aligned to L.3.1.A. No giveaways in pre-attempt content. Distractors reflect other parts of speech/functions, supporting diagnostic value.",
              "reasoning": "Measures the intended skill (function of an adjective) appropriately for Grade 3 without revealing the answer.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, school-appropriate language. No cultural references or sensitive content. US-English conventions are fine aside from a minor punctuation quirk that does not affect localization.",
              "reasoning": "Culturally neutral and age-appropriate; solvable without cultural knowledge.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly targets CCSS.ELA-LITERACY.L.3.1.A (functions of parts of speech). The task asks about the function of “shiny,” an adjective.",
              "reasoning": "Directly aligned to the cited standard focusing on parts of speech functions in sentences.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is clear; action required is unambiguous. Minor punctuation (comma inside the closing quote) does not create ambiguity or alternate interpretations. Options are parallel and clear.",
              "reasoning": "The question and choices are clear and unambiguous for Grade 3 students.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and provides no explicit item-format specification to enforce. No identifiable hard spec rules are present to violate.",
              "reasoning": "No explicit item-spec requirements provided; the item follows standard MCQ conventions.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common confusions: noun (names), verb (action), adverb (where). These are plausible errors when identifying adjective function.",
              "reasoning": "Choices are plausible and diagnose confusion between parts of speech and their functions.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided in the context. Applied own bar: For Grade 3 L.3.1.A, an “easy” item involves a short, concrete sentence where the target word clearly modifies a nearby noun and distractors are basic parts of speech. The item meets this: single, simple sentence; adjective directly before the noun; straightforward distractors.",
              "reasoning": "Appropriate as an easy Grade 3 item—single-step identification of an adjective’s function in a simple sentence.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context is used or required; the item is self-contained.",
              "reasoning": "Not applicable; the sentence is provided within the item.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options are grammatically parallel (“It … (part of speech)”). Plausible, homogeneous in specificity/length, and none are obviously silly. Correct answer is not telegraphed by length or wording.",
              "reasoning": "Distractors are well-constructed, plausible, and parallel, supporting discrimination.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No external stimulus/image. Nothing misleading or distracting.",
              "reasoning": "No stimulus present; nothing to impair the task.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying knowledge of parts of speech to a specific sentence, not just recalling a definition; distinguishes students who can recognize adjective function in context.",
              "reasoning": "Students must apply understanding of adjective function in context, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 72.3763210773468,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_000\"\nLINE 11:         'diverse_000', '2.3.0', '{\"request_id\": \"c08714c7-ac...\n                 ^\n"
      ],
      "overall_score": 0.96
    },
    {
      "request_id": "e337d2da-98ac-4add-9c04-4eb652eb0dac",
      "evaluations": {
        "diverse_001": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.74,
              "internal_reasoning": "Step 1 – Intent: Standalone MCQ for Grade 3 ELA (L.3.1.A), practice/assessment style.\n\nStep 2 – Issues:\n- ISSUE1 (factual_accuracy): Snippet: Option A says, '\"it\" is a pronoun that replaces the noun \"puppy.\"' and the answer_explanation repeats this. In the sentence 'The playful puppy chased the ball quickly and barked loudly at it,' the pronoun 'it' refers to 'the ball,' not 'puppy.' Therefore the keyed answer A and the explanation are factually incorrect, and no option correctly explains all three words.\n\nChecklist A (Field Consistency): The key (A) and explanation are consistent with each other but both are wrong with respect to the actual sentence. → Factual Accuracy failure.\nChecklist B (Giveaway): No pre-attempt answer giveaways.\nChecklist C (Diction/Typo): No confusing typos; wording is clear.\n\nStep 3 – Metric scores determined accordingly: factual_accuracy=0.0 due to ISSUE1; all other metrics pass.\n\nStep 4 – Overall per rules: C=1 (factual_accuracy fail), N=0 → overall must be 0.70–0.84. Choose lower half per rule (critical metric failed). Selected 0.74.\n\nStep 5 – Consistency: The single identified issue maps to factual_accuracy; other metrics have no independent issues.",
              "reasoning": "Well-targeted Grade 3 grammar item with clear stem and plausible distractors. However, the keyed answer and explanation misidentify the antecedent of “it.” In the sentence, “it” refers to “the ball,” not “puppy.” This factual error means the keyed answer is incorrect and no option is fully correct.",
              "suggested_improvements": "Fix Option A and the explanation to state that 'it' replaces 'the ball.' For example: Option A → '\"playful\" is an adjective that describes the noun \"puppy\"; \"quickly\" is an adverb that tells how the puppy chased; \"it\" is a pronoun that replaces the noun \"ball.\"' Ensure the answer key points to this corrected option."
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The sentence 'The playful puppy chased the ball quickly and barked loudly at it' makes 'it' corefer with 'the ball.' Option A and the explanation both claim 'it' replaces 'puppy,' which is false. Therefore the labeled correct answer is incorrect and no option fully matches the sentence facts.",
              "reasoning": "The keyed option and explanation wrongly claim “it” replaces “puppy.” In context, “it” refers to “the ball.”",
              "suggested_improvements": "Revise Option A and the explanation so that 'it' is identified as a pronoun replacing 'the ball.' Update the answer key accordingly."
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Despite the factual error in the key, the item’s design aligns with L.3.1.A and appropriately asks students to identify the functions of adjective, adverb, and pronoun in a specific sentence. No answer giveaway issues.",
              "reasoning": "The task targets the intended skill (functions of parts of speech in context) and is grade-appropriate. The failure is factual labeling, not educational intent.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, school-appropriate context; no cultural dependencies or sensitive content.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly aligns to CCSS L.3.1.A: explain functions of adjectives, adverbs, pronouns in a sentence.",
              "reasoning": "Clearly aligned to the standard on parts of speech functions in context.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem clearly states the task; no ambiguous phrasing; students know which words to analyze.",
              "reasoning": "Clear stem and options; unambiguous task.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item-writing spec provided; per rules, pass.",
              "reasoning": "No binding specification to enforce; item format is acceptable.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors reflect common confusions (adjective vs verb; adverb vs adjective; pronoun vs noun/verb). Diagnostic value present for Grade 3.",
              "reasoning": "Incorrect choices map to plausible part-of-speech confusions.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided. Applied own bar: For Grade 3 L.3.1.A, 'Hard' can involve identifying multiple parts of speech and their functions including pronoun antecedent across a compound predicate. This item requires analyzing three words and their roles; this is at least medium and plausibly hard for Grade 3. Therefore the labeled difficulty is acceptable.",
              "reasoning": "Cognitive demand (analyzing functions of three words in context) is appropriate for an upper-end Grade 3 item.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "Self-contained sentence; no external passage needed.",
              "reasoning": "No passage required; references are internal and clear.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are grammatically parallel and mutually exclusive. While some options are clearly wrong, they reflect typical misunderstandings and don’t telegraph the (intended) answer by length or style.",
              "reasoning": "Plausible distractors representing common errors; no obvious giveaways by form.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No external stimulus/image; not applicable; nothing harmful.",
              "reasoning": "No stimulus issues present.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires application of grammatical knowledge to a specific sentence, not mere recall; distinguishes understanding of adjective/adverb/pronoun functions.",
              "reasoning": "Students must apply concepts to evidence in the sentence, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 77.49188494682312,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.74
    },
    {
      "request_id": "9455d2de-d5ef-4031-bb9a-93c2aca5ac50",
      "evaluations": {
        "diverse_002": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.95,
              "internal_reasoning": "Step 1: Identify intent → Practice MCQ for Grade 3 ELA (L.3.1.A). Student-facing content: stem and 4 options; no images. Metadata marks correct answer B with explanation.\nStep 2 – Issues: Ran checklists.\n- Checklist A (Field Consistency): Correct answer B matches explanation; options align with parts of speech present in the sentence. No mismatches.\n- Checklist B1 (Giveaway): No pre-attempt answer reveal; answer only in metadata. Not a worked example; still no giveaway.\n- Checklist B2 (Stimulus): No stimulus.\n- Checklist C (Diction/Typo): No errors; clear wording.\nNo issues identified.\nStep 3: All metrics pass (1.0).\nStep 4: Overall per rules: C=0, N=0 → 0.85–1.0. Choose 0.95 as solid, typical high quality.\nStep 5: Consistency: All passes, no contradictions.",
              "reasoning": "Strong, clear Grade 3 language question on identifying the function of an adverb. Correct answer and explanation are accurate and consistent. Options are plausible and map to common confusions (noun/verb/adjective). Wording is unambiguous and age-appropriate. No stimulus issues or localization concerns.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The word \"silently\" is indeed an adverb modifying the verb \"watched\"; labeled answer B and the explanation correctly state this. No contradictory information or field mismatches.",
              "reasoning": "All content is factually correct; the key and explanation accurately identify “silently” as an adverb modifying the verb.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The item directly assesses L.3.1.A (functions of parts of speech) by asking for the function of an adverb in context. No answer giveaway occurs pre-attempt. The distractors target related functions (noun, verb, adjective), which reinforces the intended skill.",
              "reasoning": "Targets the intended skill (identifying an adverb’s function) appropriately for Grade 3 and maintains assessment integrity.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, classroom-appropriate content. No culture-specific references, stereotypes, or sensitive content. Language suitable for en-US Grade 3.",
              "reasoning": "Culturally neutral, age-appropriate, and clear for the locale.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Standard CCSS.ELA-LITERACY.L.3.1.A focuses on explaining functions of parts of speech. The item asks for the function of an adverb in a specific sentence—direct alignment.",
              "reasoning": "Directly aligned to L.3.1.A by requiring identification/explanation of an adverb’s function in context.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is explicit. Options are parallel and unambiguous. No merged words or grammatical confusion. No alternative interpretations that would change the task.",
              "reasoning": "Clear stem and parallel, understandable options; students know exactly what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context has no explicit hard item-spec requirements to enforce; thus no spec to violate. Item follows standard MCQ conventions.",
              "reasoning": "No applicable hard item specification provided; item format is appropriate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common confusions: noun naming (A), verb as action (C), adjective describing noun (D). These are plausible for students who misidentify parts of speech.",
              "reasoning": "Choices diagnose typical confusions between noun/verb/adjective vs adverb functions.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided for this standard; applying Scenario 2. For Grade 3 L.3.1.A, ‘Medium’ can involve identifying parts of speech by function within a sentence with multiple POS present (adjective, adverb, verb, noun, pronoun). This item meets that bar: students must analyze function, not just label by suffix, in a short sentence with multiple cues.",
              "reasoning": "Cognitive demand fits a Medium Grade 3 task: analyze a sentence to determine the function of “silently.”",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "Self-contained sentence provided; no external passage needed or referenced.",
              "reasoning": "No passage needed; reference is clear and complete within the item.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options begin with “It …,” are grammatically parallel, plausible, and of similar length. None are obviously irrelevant; each corresponds to a real function (noun/verb/adjective) competing with the correct adverb function.",
              "reasoning": "Plausible, parallel, and balanced options that don’t telegraph the answer.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No external stimulus used; nothing misleading or distracting.",
              "reasoning": "No stimulus; not applicable and thus no issues.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying knowledge of parts of speech to determine function in context, distinguishing between adjective and adverb roles—diagnostic of understanding, not pure recall.",
              "reasoning": "Students must apply understanding of grammatical functions in context, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 47.732665061950684,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.95
    },
    {
      "request_id": "74c1955c-e82e-4187-9208-93899c874163",
      "evaluations": {
        "diverse_003": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.95,
              "internal_reasoning": "Step 1: Identified student-facing stem and four MC options. No stimuli, hints, or passages. Metadata labels correct answer as B with explanation about irregular plural “foot → feet.”\nStep 2 – Issues: None found.\n- Checklist A (Field Consistency): Labeled correct answer B matches content; explanation correctly states irregular plural and aligns with option B; no mismatches.\n- Checklist B (Giveaway): No pre-attempt answer reveal; standard MCQ format → no giveaway.\n- Checklist C (Diction/Typo): Stem and options are clear; intentional errors appear only in distractors.\nAll other metrics show no concrete violations.\nStep 3: All metrics pass (1.0) except overall (continuous) which reflects minor, optional polish opportunities.\nStep 4: With C=0 and N=0, overall must be in 0.85–1.0; choose 0.95 (solid item, simple but well-constructed).\nStep 5: Self-consistency confirmed.",
              "reasoning": "Strong, clear Grade 3 item assessing irregular plural nouns. The correct answer is accurately labeled and explained. Distractors are plausible and diagnose common errors (“foots,” possessive “feet’s,” and failure to pluralize). Wording is clear and age-appropriate. No stimuli or spec issues.",
              "suggested_improvements": "Optional: Consider slightly more idiomatic phrasing like “in the snow” instead of “on the snow,” though current wording is acceptable. You could also vary the context in future items to check transfer (e.g., “The table has four sturdy feet.”)."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The irregular plural of “foot” is “feet,” and option B correctly reflects this. Answer key marks B; explanation matches and contains no contradictions or mismatches with options. No images/passages to verify.",
              "reasoning": "Correct answer and explanation are accurate and consistent with the options.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Targets CCSS L.3.1.B: forming/using regular and irregular plural nouns. No answer giveaway in student-facing text. The task requires recognizing and applying the irregular plural “foot → feet” in context.",
              "reasoning": "Directly assesses the intended grammar skill without giveaways and at an appropriate level for Grade 3.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, school-appropriate context; no culturally specific or sensitive content. Language is US-appropriate. “On the snow” is acceptable regionally, if slightly less common than “in the snow.”",
              "reasoning": "Culturally neutral and age-appropriate; no localization concerns.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Explicitly aligned to CCSS.ELA-LITERACY.L.3.1.B (regular/irregular plural nouns). The item asks for the correct plural of “foot” in a sentence, which matches the standard.",
              "reasoning": "Direct alignment to the Grade 3 standard on plural nouns, particularly irregular forms.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous; students know to choose the sentence with the correct plural of “foot.” No phrases with dual interpretations; task is clear. Intentional errors are confined to distractors.",
              "reasoning": "Clear stem and options; students can easily understand what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item-spec requirements provided; thus no enforceable constraints. Format is a standard MCQ aligning with the intended skill.",
              "reasoning": "No applicable hard specifications are violated.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common errors: leaving noun singular after a number (A), adding regular -s to an irregular noun (C), and using possessive apostrophe for plural (D).",
              "reasoning": "Choices effectively diagnose common pluralization misconceptions.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided for this context. Using Scenario 2 rules: For Grade 3 plural nouns, an ‘easy’ item would involve a single, common irregular in a simple sentence with plausible distractors. This item matches that bar.",
              "reasoning": "Appropriate as an easy item for Grade 3 irregular plurals.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context is used or needed; the item is self-contained.",
              "reasoning": "Not applicable; question stands alone without a passage.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options are parallel in structure and length; only the noun form varies. Distractors are plausible and homogeneous, without telegraphing the answer.",
              "reasoning": "Grammatically parallel, plausible, and well-balanced choices.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; therefore no risk of harm or distraction.",
              "reasoning": "Not applicable; absence of a stimulus is fine here.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying knowledge of irregular pluralization within sentence context and discriminating among plausible errors. This goes beyond pure recall in the format of the task.",
              "reasoning": "Supports mastery by requiring application of pluralization rules in context.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 72.03440237045288,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.95
    },
    {
      "request_id": "ebf54815-9c71-49b0-a5c4-93d753d14539",
      "evaluations": {
        "diverse_004": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Intent: This is a standalone MCQ (practice/assessment). No instructional framing or reveal cues. Target standard inferred from context: CCSS.ELA-LITERACY.L.3.1.B (regular/irregular plural nouns) for Grade 3.\n\nStep 2 – Issues (committed):\n- ISSUE1 – Educational Accuracy: Answer giveaway in student-facing option text. Snippet: \"The correct choice that matches the standard.\" This makes the correct answer trivially identifiable pre-attempt.\n- ISSUE2 – Curriculum Alignment: Stem does not assess plural nouns; it asks about \"the skill described in L.3.1.B at hard difficulty\" without any content involving plural nouns. Misaligned with the standard’s intent.\n- ISSUE3 – Clarity & Precision: Stem uses metadata/code (“L.3.1.B”) and vague phrase \"best demonstrates the skill… at hard difficulty\"; unclear to a Grade 3 student what action or knowledge is required.\n- ISSUE4 – Distractor Quality: B–D are generic placeholders (\"An incorrect distractor.\") and A announces correctness; not plausible, not parallel, telegraphs the answer.\n- ISSUE5 – Reveals Misconceptions: Because distractors are generic, the item provides no diagnostic insight into plural noun misconceptions (e.g., overgeneralizing -s/-es, apostrophes for plurals, irregular forms).\n- ISSUE6 – Difficulty Alignment: Labeled hard but requires no grade-level reasoning; the task is trivial due to giveaway and lacks any plural-noun application. Scenario 2 (no difficulty definitions provided): For Grade 3 L.3.1.B, \"hard\" should involve applying pluralization (esp. irregulars) in context (sentence editing/selection). This item does not meet that bar.\n- ISSUE7 – Mastery Learning Alignment: Requires no reasoning; correctness is given away; yields no diagnostic value.\n\nChecklist A – Field Consistency: Answer key (A) matches options and explanation. No cross-field mismatches.\nChecklist B1 – Answer Giveaway: Present (option A explicitly states it is correct) in pre-attempt text; practice/assessment → fail educational_accuracy.\nChecklist B2 – Stimulus Quality: No stimulus.\nChecklist C – Diction/Typo: No typos, but semantic ambiguity noted in ISSUE3.\n\nStep 3 – Metric scores set accordingly (see per-metric sections).\n\nStep 4 – Overall per rules: C=1 (educational_accuracy fail); N=6 (clarity_precision, curriculum_alignment, reveals_misconceptions, difficulty_alignment, distractor_quality, mastery_learning_alignment). Range required: 0.55–0.75. Choose lower half (0.60) because a critical metric fails and multiple non-critical failures.\n\nStep 5 – Self-consistency: Each 0.0 metric ties to at least one issue; no stray issues.\n",
              "reasoning": "Significant flaws prevent this item from serving its purpose. The stem is meta and unclear to Grade 3, the correct answer is given away in the option text, the content does not actually assess plural nouns, and the distractors provide no diagnostic value. These lead to failures in educational accuracy, alignment, clarity, difficulty, distractor quality, and mastery-learning alignment. While there are no factual contradictions or stimulus problems, the item requires redesign to be instructionally useful.",
              "suggested_improvements": "Redesign the item to directly assess L.3.1.B. Suggestions:\n- Write a clear, age-appropriate stem that asks students to form or choose the correct plural in context (e.g., \"Choose the sentence that uses the plural of 'child' correctly.\"). Avoid standard codes and meta-language.\n- Provide four plausible options that use regular/irregular plurals in authentic sentences. Ensure only one is fully correct.\n- Remove any self-referential giveaway text. Do not label an option as \"the correct choice.\"\n- Craft distractors to reflect common errors: over-adding -s/-es (childs), misusing apostrophes (child's for plural), leaving irregular nouns unchanged (child), or wrong irregular form (childes).\n- For \"hard\" difficulty, embed the noun in a longer sentence with subject-verb agreement and nearby irregulars, or require choosing the correctly edited sentence among minimal pairs.\n- Include a concise rationale explaining why the correct option is right and why each distractor is wrong (shown post-attempt)."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No factual claims about language rules are made in the student-facing content. The labeled correct answer (A) matches the answer_explanation. No contradictions or mismatches across fields. No images to verify.",
              "reasoning": "No factual errors or internal contradictions are present; the key and explanation are consistent with the options.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "Primary failures: (1) Trivial answer giveaway: option A literally says it is the correct choice. (2) The item does not actually assess forming/using regular/irregular plurals; it references a standard code and difficulty level instead of presenting plural-noun content. As a practice/assessment item with pre-attempt visibility, this undermines the educational purpose.",
              "reasoning": "The correct answer is given away in option A (\"The correct choice that matches the standard.\"), and the item does not assess plural nouns at all. This fails the educational intent.",
              "suggested_improvements": "Replace meta-language with a real plural-noun task and remove any text that declares an option correct. Ask students to choose or form correct plural nouns in context."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, non-cultural content; no sensitive topics; inclusive language.",
              "reasoning": "Culturally neutral and age-appropriate; no localization concerns.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "The stem does not require forming/using plural nouns; it asks which option \"demonstrates the skill described in L.3.1.B\" with generic placeholders. This is misaligned with the standard’s scope (forming/using regular and irregular plural nouns).",
              "reasoning": "The item does not measure forming or using plural nouns, so it is not aligned to L.3.1.B.",
              "suggested_improvements": "Write a task that requires selecting or producing correct plural forms (especially irregulars) in context, consistent with Grade 3 Language standards."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "Ambiguity and unclear action: \"Which choice best demonstrates the skill described in L.3.1.B at hard difficulty?\" A Grade 3 student likely does not recognize the code and cannot infer what action is required. Two plausible interpretations: (a) they must know the standard code to choose; (b) they should scan options for an example of plural nouns. Neither is clear, and the options provide no meaningful content to decide.",
              "reasoning": "The stem uses a standard code and meta-phrasing that are unclear for Grade 3 and do not specify a concrete task. This creates genuine ambiguity about what to do.",
              "suggested_improvements": "State the task plainly without codes (e.g., \"Choose the sentence that uses the plural of 'goose' correctly.\"). Provide content that makes the required action clear."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context is guidance-only (SOFT). No explicit item-writing specification with enforceable constraints is provided. Therefore, no spec to enforce; pass by rule.",
              "reasoning": "No clear, prescriptive item specification to enforce; thus no spec violation.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "Distractors are generic placeholders and do not represent plausible plural-noun errors (e.g., childs, childrens, child’s). Therefore, the item cannot reveal specific misconceptions.",
              "reasoning": "The distractors are not tied to common plural-noun errors, so the item offers little diagnostic value.",
              "suggested_improvements": "Use distractors that mirror real misconceptions: overgeneralizing -s/-es, incorrect irregular forms, or misuse of apostrophes for plurals."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "Scenario 2 (no Difficulty Definitions available): For Grade 3 L.3.1.B, a \"hard\" item should require applying pluralization—especially irregulars—in context (sentence selection/editing, subtle distractors, subject-verb agreement interplay). This item is trivial due to a self-identified correct option and includes no plural-noun reasoning, so it fails the intended difficulty level.",
              "reasoning": "The task does not reflect a hard-level application of plural nouns; it is trivial and does not demand grade-appropriate reasoning.",
              "suggested_improvements": "Increase rigor by embedding irregular plurals in authentic sentences with subtle errors and require choosing the only fully correct sentence."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage provided or referenced; N/A passes by rule.",
              "reasoning": "Self-contained item; no passage required.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "Choices are not grammatically/semantically parallel. A announces correctness; B–D are non-specific placeholders. This telegraphs the answer and provides no plausible alternatives.",
              "reasoning": "Distractors are implausible and unbalanced; the correct option is telegraphed by wording.",
              "suggested_improvements": "Write four parallel, content-rich options with only one fully correct use of plural nouns. Ensure similar length/specificity and plausibility for all choices."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus included; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus; no issues.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "The item requires no application or reasoning; correctness is declared in the option text; offers no diagnostic discrimination between mastery levels.",
              "reasoning": "No meaningful reasoning is required and the correct answer is given away, so it does not support mastery learning.",
              "suggested_improvements": "Require students to apply plural-noun rules in context and structure options to differentiate common errors from the correct form."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 118.8928575515747,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_004\"\nLINE 11:         'diverse_004', '2.3.0', '{\"request_id\": \"ebf54815-9c...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "42bc7033-a450-450c-81d1-5d7f07851366",
      "evaluations": {
        "diverse_005": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.3,
              "internal_reasoning": "Step 1 – Intent: This is a practice/assessment MCQ (no instructional walkthrough). Target standard inferred from metadata and stem: CCSS.ELA-LITERACY.L.3.1.B (form/use regular and irregular plural nouns).\n\nStep 2 – Issues (commit list):\n- ISSUE1 – Educational Accuracy: Answer giveaway in student-facing option. Snippet: \"A) The correct choice that matches the standard.\" This trivially reveals the right answer before attempt; also item does not actually assess the standard.\n- ISSUE2 – Clarity & Precision: Stem is ambiguous and not student-friendly: \"Which choice best demonstrates the skill described in L.3.1.B at medium difficulty?\" Third graders won’t know the code; unclear what action/skill is required.\n- ISSUE3 – Curriculum Alignment: Item does not present content requiring forming/using plural nouns. All options are meta placeholders, not sentences with plurals.\n- ISSUE4 – Distractor Quality: Options B–D are labeled “An incorrect distractor,” making them implausible and telegraphing the answer. Correct option is self-identified.\n- ISSUE5 – Reveals Misconceptions: Because choices do not embody common plural-noun errors (e.g., “mouses,” “childs”), the item cannot surface misconceptions.\n- ISSUE6 – Difficulty Alignment: With no difficulty definitions provided, a “medium” L.3.1.B item should require applying plural rules in context. This item is trivial meta-selection (or impossible without knowing the code), far below intended cognitive demand.\n- ISSUE7 – Factual Accuracy: Explanation claims “Option A is correct because it matches the skill described in the standard,” but Option A contains no linguistic content that demonstrates the skill; thus the rationale is factually untrue relative to the presented choices.\n\nChecklist A – Field Consistency: Labeled correct answer = A, and explanation names A; but explanation’s claim is unsupported/false given placeholders → captured in ISSUE7 (factual).\n\nChecklist B – Answer Giveaway (practice/assessment): B1 fails. The correct answer is trivially identified by the text of Option A before attempt. No reveal cue. B2 (stimulus) not applicable (no stimulus).\n\nChecklist C – Diction/Typo: No typos/merged words; main problem is semantic clarity, already captured.\n\nStep 3 – Metric scoring based on issues.\nStep 4 – Overall per rules: C=2 (factual_accuracy, educational_accuracy). Therefore overall must be 0.0–0.65. Multiple additional non-critical failures → choose 0.30 (lower end). \nStep 5 – Consistency: Each failed metric cites a concrete issue; no orphan issues.",
              "reasoning": "This item is non-functional as a Grade 3 plural-nouns question. The stem references a standard code students won’t know, and the options are placeholders. Option A literally says it is the correct choice, giving away the answer. The item does not present any content that assesses forming or using plural nouns, so it’s misaligned to the intended standard. Distractors are not plausible and cannot reveal misconceptions. Overall, the question should be rewritten to include an authentic plural-noun task with meaningful choices.",
              "suggested_improvements": "- Replace the stem with a concrete, student-friendly task that targets plural nouns, e.g.: \"Choose the correct plural to complete the sentence: The goose had two _____.\"\n- Provide meaningful choices that reflect common errors/misconceptions: A) gooses B) geese C) goosies D) goose.\n- Remove any reference to standard codes or difficulty labels from student-facing text.\n- Ensure the correct option is not telegraphed; make all choices plausible and parallel.\n- Provide an explanation that teaches the rule (e.g., “goose → geese is an irregular plural”)."
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE7: The explanation states, “Option A is correct because it matches the skill described in the standard.” However, Option A text is merely “The correct choice that matches the standard.” No option demonstrates forming/using plural nouns. Thus the claim that A matches the skill is factually false relative to the content presented. Field consistency check confirmed labeling is consistent (A), but the rationale content is inaccurate.",
              "reasoning": "The rationale asserts A demonstrates the standard, but none of the options contain any plural-noun content. The justification is false given the provided choices.",
              "suggested_improvements": "Provide a real correct option that actually demonstrates the skill (e.g., a sentence using an irregular plural) and update the explanation to reference that concrete content."
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: For a practice/assessment item, Option A explicitly says it is the correct choice, making the answer trivially obtainable pre-attempt (no reveal cue). Additionally, the item doesn’t assess the intended skill (plural nouns) because all options are meta placeholders. This fails educational purpose and constitutes an explicit answer giveaway per B1 rules.",
              "reasoning": "The answer is given away in Option A, and the item does not require using or identifying plural nouns. It fails to assess the intended Grade 3 skill.",
              "suggested_improvements": "Write a content-based prompt that requires applying plural-noun rules and remove any self-identifying “correct” labels from options."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "No cultural content or sensitive material. Neutral phrasing. No region-specific references required.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: CCSS.ELA-LITERACY.L.3.1.B addresses forming/using regular and irregular plural nouns. The item presents no sentences or noun forms to evaluate or produce. Therefore it does not measure the stated standard.",
              "reasoning": "The content does not assess forming or using plural nouns; thus it’s misaligned with L.3.1.B.",
              "suggested_improvements": "Create items where students select or produce correct plural forms in context, including irregular plurals (e.g., child→children, mouse→mice)."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: The stem “Which choice best demonstrates the skill described in L.3.1.B at medium difficulty?” is ambiguous for Grade 3. Students could interpret it as needing to recall a standard code or to pick any option that says it’s correct. Two plausible but conflicting interpretations change responding: (1) choose based on knowledge of the code (impossible for most 3rd graders), or (2) choose the option that literally says it’s correct. Therefore clarity fails per the two-interpretations rule.",
              "reasoning": "The stem references a standard code and “medium difficulty,” which third graders won’t understand, making the task unclear.",
              "suggested_improvements": "Use student-friendly language describing the actual task (e.g., “Choose the sentence that uses the correct plural form”). Avoid mentioning standards or difficulty in the stem."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit, enforceable item-writing specification provided. Confidence level is SOFT; no clear hard rules to enforce. Per rules, pass by default when no spec is identified.",
              "reasoning": "No clear spec to enforce; thus compliant by default.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE5: Choices do not reflect common plural-noun errors; they are meta labels. As such, the item cannot diagnose misunderstandings about pluralization.",
              "reasoning": "The distractors do not represent realistic plural-noun mistakes, so the item cannot surface misconceptions.",
              "suggested_improvements": "Include distractors that mirror typical errors (e.g., regularizing irregulars: “mouses,” “childs,” or incorrect endings like “goosies”)."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "No Difficulty Definitions are provided in the curriculum context. Applied own bar: For L.3.1.B, a medium item should require applying plural-noun rules in context (choosing or producing correct plural forms; plausible distractors; brief reasoning). The presented item is trivial meta-selection with a self-identified correct option, far below Grade 3 expectations, constituting a ≥2-grade under-shoot of cognitive demand.",
              "reasoning": "The task is far simpler than a typical Grade 3 medium item on plural nouns; it requires no application of the skill.",
              "suggested_improvements": "Design a task that requires selecting/producing correct plural forms in a sentence, with plausible distractors and without giveaways."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage/stimulus to reference; self-contained.",
              "reasoning": "No passage involved; nothing to reference.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: Distractors are labeled “An incorrect distractor,” which is implausible and telegraphs the answer. Correct option is self-labeled as correct. This violates plausibility and telegraphing checks.",
              "reasoning": "Choices are meta, implausible, and the correct answer is telegraphed; poor distractor design.",
              "suggested_improvements": "Replace with grammatically parallel, contentful choices that are all plausible (e.g., multiple plural forms), ensuring none self-identify as correct or incorrect."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; nothing harmful or misleading.",
              "reasoning": "No image or additional stimulus; no issues.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "The item requires no application or reasoning about plural nouns; the correct answer is given away and options lack content. This offers no diagnostic value or evidence of understanding.",
              "reasoning": "No meaningful reasoning is required; the design precludes demonstrating mastery.",
              "suggested_improvements": "Require students to analyze or produce plural forms in context and justify/explain the choice in the explanation field to support mastery learning."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 91.54262781143188,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_005\"\nLINE 11:         'diverse_005', '2.3.0', '{\"request_id\": \"42bc7033-a4...\n                 ^\n"
      ],
      "overall_score": 0.3
    },
    {
      "request_id": "19ae3e9d-d932-49a9-b148-97e2ffeeb8e5",
      "evaluations": {
        "diverse_006": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.96,
              "internal_reasoning": "Step 1 – Intent: Standalone Grade 3 ELA MCQ for practice/assessment on abstract nouns (CCSS.ELA-LITERACY.L.3.1.C). No stimuli, hints, or special UI cues.\n\nStep 2 – Issues:\n- No issues found.\nChecklist A (Field consistency): Answer key A = “kindness”; explanation aligns with options and correctly defines abstract noun. No mismatches.\nChecklist B (Answer giveaway): No pre-attempt giveaways; stem simply asks to identify an abstract noun.\nChecklist C (Diction/typos): Clean, age-appropriate language; no merged words or confusing symbols.\n\nStep 3 – Metrics: All metrics pass with reasons below.\n\nStep 4 – Overall: C=0, N=0 → range 0.85–1.0. High quality but routine item; assign 0.96 (acceptable-high).\n\nStep 5 – Consistency: No failures; all metrics reflect the absence of issues.",
              "reasoning": "Clear, accurate Grade 3 item aligned to abstract nouns. Correct answer and rationale are sound; distractors are concrete nouns and plausible. Language is clear and age-appropriate. No stimuli or specification conflicts. Difficulty is appropriate for an easy classification task. No localization concerns.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "All content is correct: “kindness” is an abstract noun; “balloon,” “mountain,” and “backpack” are concrete nouns. The explanation matches the labeled answer and options. No contradictions or mismatches.",
              "reasoning": "The labeled correct answer and explanation are factually correct and consistent with the options.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Assesses identification of abstract nouns, matching CCSS L.3.1.C. No answer giveaways; requires conceptual recognition. Appropriate for Grade 3.",
              "reasoning": "The task directly measures identifying an abstract noun without giving away the answer.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, universal vocabulary with no cultural references or sensitivities. Age-appropriate.",
              "reasoning": "Content is culturally neutral and suitable for a broad audience.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Standard targeted: CCSS.ELA-LITERACY.L.3.1.C (use/identify abstract nouns). Item aligns by asking to identify an abstract noun among options.",
              "reasoning": "Directly aligned to L.3.1.C by focusing on abstract vs. concrete nouns.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous; options are simple, single-word nouns. No grammatical or semantic ambiguity.",
              "reasoning": "The question clearly asks what is needed, and students will understand how to respond.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit hard item specification provided. Under the rules, pass by default. The format (single MCQ, four options) is typical for this skill.",
              "reasoning": "No applicable hard specifications to violate; the item format is standard.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors are all concrete nouns, a common misconception is thinking nouns must be tangible. Choices can diagnose misunderstanding of abstract vs. concrete.",
              "reasoning": "Options likely reveal whether students mistakenly think nouns must name physical objects.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2: No Difficulty Definitions provided. Applied an Easy bar for Grade 3 ELA: single-step classification using a taught concept with familiar vocabulary. Item fits this bar—one-step identification with clear contrast among options.",
              "reasoning": "Cognitive demand is easy and appropriate for Grade 3: identify the abstract noun among concrete nouns.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context needed or referenced; question is self-contained.",
              "reasoning": "Not applicable; the item stands alone without a passage.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options are nouns; three are concrete and plausible. Grammatically parallel, similar length, homogeneous category. Correct answer not telegraphed by style or length.",
              "reasoning": "Distractors are plausible and well-constructed, supporting diagnostic value.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; thus no potential for misleading or distracting visuals.",
              "reasoning": "No stimuli involved; nothing harmful or misleading.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying the concept of abstract vs. concrete nouns, not merely recalling a random fact. Correctness indicates understanding of the concept.",
              "reasoning": "Students must apply their understanding of abstract nouns to classify correctly, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 45.04139995574951,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.96
    },
    {
      "request_id": "7c80da21-fc9f-4eb7-87a7-6abe6157e84e",
      "evaluations": {
        "diverse_007": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.95,
              "internal_reasoning": "Step 1: Identified this as a Grade 3 ELA MCQ targeting CCSS L.3.1.C (abstract nouns). No images. Student-facing stem and options clear; answer key = A (pride).\nStep 2 – Issues: Ran checklists.\n- Checklist A (Field Consistency): Options A–D match explanation; labeled correct answer A fits both blanks; explanation is broadly consistent (minor imprecision: calling “drums” a sound, but not materially misleading). No contradictions.\n- Checklist B1 (Answer Giveaway): Practice/assessment item; no answers shown pre-attempt. No giveaway.\n- Checklist B2 (Stimulus Quality): No stimulus.\n- Checklist C (Diction/Typo): No merged words or distracting symbols.\nNo issues identified → all binary metrics pass.\nStep 3: Metrics → factual_accuracy=1, educational_accuracy=1, curriculum_alignment=1, clarity_precision=1, specification_compliance=1, reveals_misconceptions=1, difficulty_alignment=1, passage_reference=1, distractor_quality=1, stimulus_quality=1, mastery_learning_alignment=1, localization_quality=1.\nStep 4: Overall scoring per rules: C=0, N=0 ⇒ range 0.85–1.0. Choose 0.95 (solid quality; not marking as “exceptional”).\nStep 5: Consistency check: All metrics and narrative aligned.",
              "reasoning": "Strong, grade-appropriate item assessing abstract nouns. “Pride” correctly completes both sentences and is an abstract noun. Distractors are plausible for sentence 1 but break in sentence 2, revealing understanding. Wording is clear, and difficulty is appropriately high for Grade 3 due to vocabulary and dual-context fit.",
              "suggested_improvements": "Minor refinement: In the explanation, distinguish that “drums” are tangible objects (while “music” and “voices” are heard), and emphasize that the phrase “felt a surge of …” cues a feeling, reinforcing why “pride” is the best fit."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Verified that “pride” is an abstract noun and fits both blanks. Other options are not abstract for Grade 3’s five-senses definition and do not fit the second sentence idiomatically. Explanation has a slight imprecision (labeling “drums” as a sound) but the core claims are accurate and non-misleading.",
              "reasoning": "The labeled answer is correct; all details are consistent and accurate for Grade 3 pedagogy.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The item directly targets selecting an abstract noun and applying it across two contexts. No pre-attempt giveaways. It assesses both understanding of abstract nouns and collocational use (felt a surge of X).",
              "reasoning": "Effectively measures the intended skill (abstract nouns) with appropriate contexts and no answer giveaways.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral school-based context; no culturally specific or sensitive content; language appropriate for U.S. Grade 3.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly aligns to CCSS L.3.1.C (use abstract nouns). Selecting an abstract noun and applying it in sentences matches the standard.",
              "reasoning": "Direct alignment with CCSS L.3.1.C on abstract nouns.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem clearly states the task. Sentences are unambiguous. Vocabulary (“auditorium,” “surge”) raises difficulty but does not create ambiguity. No merged words or confusing symbols.",
              "reasoning": "Clear instructions and sentences; no ambiguity about what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item spec with prescriptive format rules provided. Per rules, pass by default; the item follows standard MCQ conventions.",
              "reasoning": "No conflicting item-spec requirements; format is appropriate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors (drums, music, voices) are plausible for sentence 1 and reflect a common misconception (treating perceivable sounds as abstract). They fail in sentence 2, diagnosing misunderstanding.",
              "reasoning": "Choices surface the misconception that non-tangible but perceivable nouns (like music) are abstract.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2 (no provided difficulty definitions). Applied a Grade 3 “hard” bar: requires understanding the abstract/concrete distinction plus semantic fit across two contexts and coping with higher-level vocabulary (“auditorium,” “surge”). This exceeds simple recall and fits a hard classification for Grade 3.",
              "reasoning": "Cognitive demand and vocabulary support a hard difficulty label for Grade 3.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context required; item is self-contained.",
              "reasoning": "Not applicable; the question is self-contained.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options are singular/mass nouns, succinct, grammatically parallel, and plausible in sentence 1 but not 2. No length or specificity cues give away the answer.",
              "reasoning": "Plausible, parallel distractors that do not telegraph the answer.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No stimulus to evaluate; thus acceptable by default.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying the abstract noun concept and evaluating semantic fit across two sentences—beyond rote recall. Good diagnostic value.",
              "reasoning": "Students must apply understanding in context, not just recall a definition.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 80.14349007606506,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.95
    },
    {
      "request_id": "0c0eea55-7541-4b1d-87bf-e0d2cc751b1f",
      "evaluations": {
        "diverse_008": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.95,
              "internal_reasoning": "Step 1 – Intent: Standalone MCQ for Grade 3 ELA practice/assessment on abstract nouns (CCSS L.3.1.C). No images; answer key and explanation are metadata, not student-facing.\n\nStep 2 – Issues:\n- Checklist A (Field Consistency): Correct answer labeled C (“silence”). Explanation aligns with options and standard. No mismatches.\n- Checklist B1 (Answer Giveaway): No pre-attempt giveaways. Only stem and options visible.\n- Checklist B2 (Stimulus Quality): No stimulus.\n- Checklist C (Diction/Typo): Clear, grammatical wording; no merged non-words or stray symbols.\nResult: No issues identified.\n\nStep 3 – Metric scoring: All metrics pass based on absence of issues and strong alignment with Grade 3 standard for abstract nouns. Distractors are plausible concrete nouns from the sentence. \n\nStep 4 – Overall per rules: C=0 (no critical fails), N=0 (no non-critical fails) → 0.85–1.0. Item is solid but routine; choose 0.95 (acceptable, not unusually exceptional).\n\nStep 5 – Consistency: Scores reflect identified (lack of) issues; all passes consistent.",
              "reasoning": "Strong Grade 3 ELA item targeting abstract nouns. The correct answer is accurately keyed, the wording is clear, and the distractors are plausible concrete nouns, which helps diagnose misconceptions. No images or extraneous content. Overall, well-aligned and appropriate difficulty.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "All content is correct: “silence” is an abstract noun; other options are concrete (audience = group of people, stage = place, dancer = person). Answer key “C” matches. No contradictions or mismatches in explanation.",
              "reasoning": "The labeled correct answer is accurate and the explanation matches the options and concepts.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Assesses identification of an abstract noun in context, exactly aligned with L.3.1.C. No giveaways; student must apply concept knowledge to a sentence.",
              "reasoning": "Effectively measures the intended skill (identifying an abstract noun) without giving away the answer.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, classroom-appropriate context; no cultural assumptions or sensitive content. Language is standard US English as requested.",
              "reasoning": "Culturally neutral and age-appropriate; no localization concerns.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly targets CCSS.ELA-LITERACY.L.3.1.C (use/identify abstract nouns). Cognitive demand and format match Grade 3 expectations.",
              "reasoning": "Directly aligned to the stated standard on abstract nouns for Grade 3.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is explicit: “Which word … is an abstract noun?” Sentence is clearly presented in quotes. No ambiguous phrasing or unclear instructions.",
              "reasoning": "Clear, unambiguous wording; students know exactly what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit hard item-writing specifications provided. Under rules, pass by default. Content follows typical MCQ conventions for this standard.",
              "reasoning": "No applicable hard specifications; item follows standard practice.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors include plausible concrete nouns from the sentence (audience, stage, dancer), capturing common confusion (e.g., thinking collective nouns like “audience” might be abstract).",
              "reasoning": "Options are designed to surface confusion between abstract and concrete nouns.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2 applies: No Difficulty Definitions provided. Applied a Grade 3 ‘medium’ bar: student must read a sentence and discriminate among multiple nouns, requiring conceptual understanding of abstract vs. concrete. This fits medium difficulty for this standard—more than simple recall, but not multi-step or advanced reasoning.",
              "reasoning": "Appropriate medium difficulty for Grade 3: selecting the abstract noun among several plausible nouns in context.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "Self-contained sentence provided; no external passage needed or referenced.",
              "reasoning": "No passage involved; N/A and acceptable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All choices are single-word nouns from the sentence; grammatically parallel; plausible; similar specificity and length; no option telegraphs the answer.",
              "reasoning": "Choices are parallel, plausible, and well-balanced; the correct answer is distinguishable only by the target concept.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No external stimulus (image/audio). The provided sentence is clear and accurate; nothing misleading or distracting.",
              "reasoning": "No harmful stimulus present.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying the concept of abstract vs. concrete nouns to a new sentence; diagnostic beyond pure recall.",
              "reasoning": "Demands conceptual application, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 44.48356819152832,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.95
    },
    {
      "request_id": "87259f5f-16b8-48c1-8999-5ac4ffeb1ef9",
      "evaluations": {
        "diverse_009": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.94,
              "internal_reasoning": "Step 1: Identified student-facing stem and options; answer key and explanation are metadata. No hints/stimuli.\nStep 2 – Issues: Ran checklists.\n- Checklist A (Field Consistency): Answer key B = “tried” matches options and the explanation. No mismatches.\n- Checklist B1 (Answer Giveaway): Practice/assessment item; no answer shown pre-attempt. No giveaway.\n- Checklist B2 (Stimulus Quality): No stimulus.\n- Checklist C (Diction/Typo): Wording clear; punctuation and grammar correct.\nNo issues identified.\nStep 3: All metrics pass (no concrete violations).\nStep 4: C=0, N=0 ⇒ overall must be in 0.85–1.0. Solid item but not exceptional; assign 0.94.\nStep 5: Self-consistency: All passes align with no issues found.",
              "reasoning": "Clear, well-aligned 3rd-grade ELA item on forming the past tense of a regular verb ending in consonant + y. The correct answer is properly labeled, distractors are plausible, and the context cue “Yesterday” supports the task. No inconsistencies or clarity issues.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "All facts align: “try” forms past tense “tried” by changing y to i and adding -ed. The labeled correct answer (B) matches this. No contradictions or mismatches across fields.",
              "reasoning": "The correct answer and explanation are accurate and consistent with standard grammar rules.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Targets forming/using regular verbs (L.3.1.D). No giveaway. Students must apply past-tense formation in context using temporal cue “Yesterday.”",
              "reasoning": "Effectively assesses forming the past tense of a regular verb in context without revealing the answer.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral U.S. English context, age-appropriate, no cultural dependencies or sensitive content.",
              "reasoning": "Culturally neutral and appropriate for U.S. 3rd-grade learners.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly aligns with CCSS L.3.1.D: form and use regular verbs; specifically the consonant + y to ied rule.",
              "reasoning": "Directly measures the intended standard on verb tense formation for Grade 3.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Prompt and sentence are unambiguous. Clear task: choose past tense of “try” to complete the sentence. No ambiguous phrasing.",
              "reasoning": "The wording clearly specifies the task and provides a helpful time cue (“Yesterday”).",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item spec with enforceable constraints provided (SOFT context). Thus, no spec violations.",
              "reasoning": "No applicable hard specification rules were provided; the item follows standard MCQ conventions.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors represent common errors: base form (try), 3rd person singular present (tries), and present participle (trying). These diagnose misunderstanding of tense and agreement.",
              "reasoning": "Wrong choices map to typical tense/agreement confusions, aiding diagnosis.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided; applying Scenario 2. For Grade 3 L.3.1.D, “easy” entails straightforward application of a common past-tense rule with a clear time cue. Item fits: single-step selection using a standard rule.",
              "reasoning": "Appropriate as an easy item for Grade 3: single-rule application with clear context.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage; item is self-contained.",
              "reasoning": "No external passage needed or referenced.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options are grammatical forms of the base verb and parallel in structure (single-word verb forms). Plausible, balanced length, and only one fits past-tense requirement in context.",
              "reasoning": "Choices are parallel, plausible, and diagnostic without telegraphing the answer.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No stimulus; therefore no risk of visual confusion or contradiction.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires application of a morphological rule in context, not pure recall of a fact; distinguishes understanding of tense formation.",
              "reasoning": "Students must apply a tense-formation rule within a sentence context, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 49.31945013999939,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.94
    },
    {
      "request_id": "4d0bdfd3-0d26-4eda-bba7-a3cc27b74d84",
      "evaluations": {
        "diverse_010": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.95,
              "internal_reasoning": "Step 1: Determined this is a standalone practice/assessment MCQ for Grade 3 ELA (verbs past tense). No images/stimuli.\nStep 2 – Issues: Ran checklists.\n- Checklist A (Field Consistency): Answer key A matches the option that correctly uses went/played/dug/called/was. Explanation aligns with options and labels incorrect forms in B/C/D implicitly. No mismatches.\n- Checklist B1 (Answer Giveaway): No pre-attempt giveaways; options are standard. No hidden/reveal cues needed.\n- Checklist B2 (Stimulus): No stimulus.\n- Checklist C (Diction/Typo): Stem clear; intentional misspellings only in distractors.\nNo issues identified. All metrics pass.\nStep 3: Scores—factual_accuracy=1.0, educational_accuracy=1.0, others pass.\nStep 4: Overall scoring rule: C=0, N=0 → 0.85–1.0. Choose 0.95 (solid, clear item but not exceptional/novel).\nStep 5: Consistency: No failed metrics; overall within acceptable range.",
              "reasoning": "Well-aligned Grade 3 ELA item assessing regular and irregular past-tense verbs. The correct answer is accurate and consistently supported by the explanation. Instructions are clear, distractors are plausible and diagnose common errors, and there are no giveaways or confusing elements.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "All information is correct and internally consistent. Option A correctly uses: went (irregular), played (regular -ed), dug (irregular), called (regular -ed), was (irregular). The explanation matches this exactly. Other options each contain at least one incorrect form (“playd”, present “go”, “digged”), aligning with the rationale. No contradictions or metadata mismatches.",
              "reasoning": "The labeled correct answer is truly correct, and the explanation accurately describes why. No contradictions or errors.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The item directly assesses forming/using regular and irregular past-tense verbs in context, appropriate to L.3.1.D. It’s a practice/assessment item with no pre-attempt answer reveal. Students must evaluate all five verb forms, including irregulars (“go,” “dig,” “be”) and regulars (“play,” “call”).",
              "reasoning": "Targets the intended grammar skill and requires applying it to a paragraph without any answer giveaway.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, age-appropriate U.S. English context (“Last Saturday,” park, dog). No sensitive or culture-specific content required for solving.",
              "reasoning": "Culturally neutral and age-appropriate; no sensitive content.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Explicitly aligns with CCSS.ELA-LITERACY.L.3.1.D (form and use regular/irregular verbs). The paragraph integrates multiple verbs, both regular and irregular, in past tense.",
              "reasoning": "Directly aligned to L.3.1.D by assessing past-tense regular and irregular verbs in context.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem clearly states the task: choose the option that uses past tense for ALL verbs in parentheses. The paragraph and options are unambiguous. No wording that could be read two ways.",
              "reasoning": "Clear instructions and unambiguous task; students know exactly what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context is SOFT and does not provide prescriptive item-writing specifications (no hard rules like word counts or format). Per rules, with no clear spec, compliance passes.",
              "reasoning": "No explicit item specification provided; nothing to violate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common errors: overgeneralizing -ed to irregulars (“digged”), keeping present form (“go”), and misspelling/incorrect regularization (“playd”). These are plausible misconceptions for Grade 3.",
              "reasoning": "Wrong choices reflect realistic student errors, helping diagnose understanding.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided; applying Scenario 2 rules. Difficulty bar used: \n- Easy: identify single regular/irregular verb form\n- Medium: evaluate multiple verbs with at least one irregular in a short context\n- Hard: evaluate several verbs (incl. multiple irregulars) across a paragraph with near-miss distractors, requiring careful holistic checking.\nThis item includes five verbs (three irregular: go→went, dig→dug, be→was; two regular: play→played, call→called) and plausible distractors. It fits medium-to-hard; the metadata “hard” is acceptable and not a clear mismatch.",
              "reasoning": "Cognitive demand is appropriate for Grade 3 and consistent with a hard label given multiple verbs and tricky distractors.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "Self-contained item with no external passage; nothing to reference.",
              "reasoning": "No passage involved; N/A and acceptable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options are parallel full-paragraph completions. Distractors are plausible and target specific errors. Length and specificity are balanced; the correct option isn’t telegraphed by length or format.",
              "reasoning": "Plausible, well-targeted distractors with consistent structure and length.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; therefore no risk of being misleading, wrong, or distracting.",
              "reasoning": "No image or external stimulus; nothing harmful.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Students must apply knowledge of regular/irregular past tense forms across multiple instances in context, not merely recall a single fact. The task distinguishes partial vs full mastery (e.g., catching only some irregulars).",
              "reasoning": "Requires application and checking multiple forms, supporting diagnostic insight.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 75.98872637748718,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.95
    },
    {
      "request_id": "0253729b-9e65-4672-b049-4db3c9335a69",
      "evaluations": {
        "diverse_011": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.74,
              "internal_reasoning": "Step 1: Identify type → Practice MCQ for Grade 3 ELA (L.3.1.D). No stimulus. \n\nStep 2 – Issues:\n- ISSUE1 (factual_accuracy): Explanation text says: \"by changing the final y to i and adding -ed.\" Verb is \"bark\" (no final y). This is a factual/grammar rule error in supporting text. Correct rule: simply add -ed → \"barked\".\n- ISSUE2 (distractor_quality): Option C \"barkeddd\" is an implausible misspelling (triple d), reducing distractor plausibility/diagnostic value.\n\nChecklist A (Field Consistency): Correct answer B matches options; explanation’s rule is incorrect → factual issue logged. \nChecklist B (Giveaway): No answer giveaway pre-attempt. \nChecklist C (Diction/Typo): Student-facing stem/options are clear; misspellings A and C are intentional distractors; no confusing merged words in the stem.\n\nStep 3 – Metric scores: factual_accuracy=0.0 (ISSUE1). educational_accuracy=1.0 (assesses past tense selection; no giveaway). curriculum_alignment=1.0 (L.3.1.D regular verb past tense). clarity_precision=1.0 (clear stem). specification_compliance=1.0 (no enforceable spec provided; Confidence=SOFT). reveals_misconceptions=1.0 (A and D reflect common errors). difficulty_alignment=1.0 (No definitions; for Grade 3, this is easy but within grade; not ≥2-grade mismatch). passage_reference=1.0 (N/A). distractor_quality=0.0 (ISSUE2). stimulus_quality=1.0 (no stimulus). mastery_learning_alignment=1.0 (requires applying tense knowledge). localization_quality=1.0 (neutral context).\n\nStep 4 – Overall per rules: C=1 (factual_accuracy), N=1 → overall range 0.70–0.84. Choose lower half because a critical metric failed → 0.74.\n\nStep 5 – Consistency: Each 0.0 maps to a concrete issue; no unreferenced fails.",
              "reasoning": "Clear, age-appropriate MCQ that targets forming/using past tense verbs. The correct answer (barked) is right and options A and D provide plausible distractors that can diagnose common errors. However, the explanation contains a factual error about the spelling rule (it incorrectly mentions changing y to i), and one distractor (barkeddd) is implausible. These reduce factual accuracy and distractor quality, respectively.",
              "suggested_improvements": "- Fix the explanation: \"'Barked' is the past tense of the regular verb 'bark.' For regular verbs like 'bark,' add -ed: bark → barked. Options A and C are misspellings, and D is present tense.\"\n- Replace option C with a more plausible distractor, e.g., \"barkeded\" (overgeneralized -ed), \"barking\" (tense/form confusion), or \"bark\" (base form), to better diagnose misconceptions."
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "Explanation states: \"by changing the final y to i and adding -ed.\" The base verb is \"bark\" (ending in k), so this rule is incorrect. While the labeled correct option B is factually correct, the supporting text contains a factual grammar rule error, which triggers a factual_accuracy failure per Field Consistency/Supporting Text rules.",
              "reasoning": "The explanation gives an incorrect spelling rule for forming the past tense of “bark.” The verb does not end in y; the past tense is formed by simply adding -ed.",
              "suggested_improvements": "Revise the explanation to: “’Barked’ is the past tense of the regular verb ‘bark.’ For regular verbs like ‘bark,’ add -ed: bark → barked.”"
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The task directly assesses selecting the correct past tense verb based on temporal context (“Last night”). No answer is given away pre-attempt, and the skill aligns with L.3.1.D. The incorrect explanation (metadata) does not undermine the student-facing task’s educational aim.",
              "reasoning": "The item appropriately checks students’ ability to select the past tense form of a regular verb using context cues. No pre-attempt giveaways.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, age-appropriate context (“puppy,” “home”). No cultural assumptions or sensitive content.",
              "reasoning": "Content is culturally neutral and appropriate for Grade 3.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly targets CCSS.ELA-LITERACY.L.3.1.D (form/use regular and irregular verbs) via choosing a regular verb’s past tense in context.",
              "reasoning": "Strong alignment with L.3.1.D: forming/using past tense verbs.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous; task is clear; no confusing wording. Wrong spellings are confined to answer options as distractors and do not confuse the task.",
              "reasoning": "Clear stem and straightforward completion task. No ambiguity.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and contains no enforceable item spec. Therefore, no spec violations can be claimed.",
              "reasoning": "No explicit item-format specifications provided to enforce; compliant by default.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Options A (barkd) captures omission of -e in -ed; D (barks) captures present vs. past tense confusion. These plausibly reveal misconceptions. Option C is weak but the item still surfaces key errors.",
              "reasoning": "Distractors capture common errors (omitting -ed or using present tense), offering diagnostic value.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided. Applied own bar: For Grade 3 verbs (L.3.1.D), Easy: choose past tense of a regular verb with clear time cue; Medium: irregular verbs or less obvious context; Hard: multiple verbs or subtle agreement/tense shifts. This item is Easy despite being labeled “medium,” but it is within grade expectations and not ≥2 grade levels off, so pass per borderline rule.",
              "reasoning": "Cognitive demand is appropriate for Grade 3; although simpler than “medium,” it’s not misaligned enough to fail.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage/stimulus to reference; N/A passes.",
              "reasoning": "Self-contained item; no passage required.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "While A and D are plausible, C (“barkeddd”) is an implausible, non-diagnostic misspelling (triple d), weakening overall choice quality (plausibility/diagnostic value).",
              "reasoning": "One distractor is obviously unrealistic (“barkeddd”), reducing plausibility and diagnostic value.",
              "suggested_improvements": "Replace C with a more plausible error, e.g., “barkeded” (double -ed overgeneralization), “barking” (form/tense confusion), or “bark” (base form). Ensure all choices remain grammatically parallel."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus; not applicable but passes by default.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Student must apply knowledge of past tense formation using a time cue; not pure recall of an isolated fact. Differentiates between students who understand tense versus those who don’t.",
              "reasoning": "Requires applying tense knowledge in context, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 127.25024747848511,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.74
    },
    {
      "request_id": "af3b4a95-4707-4314-be69-559f339093ca",
      "evaluations": {
        "diverse_012": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.96,
              "internal_reasoning": "Step 1 – Intent: Standalone MCQ for practice/assessment on Grade 3 ELA tense use (CCSS L.3.1.E). Answer key and explanation are metadata only.\nStep 2 – Issues: No issues found.\n- Checklist A (Field Consistency): Labeled correct answer B matches options; explanation correctly identifies simple present “sing” aligned with habitual time phrase “Every morning.” No mismatches.\n- Checklist B (Answer Giveaway): No pre-attempt giveaways in student-facing content. Answer/explanation only in metadata.\n- Checklist C (Diction/Typo): Clear, grammatical stem and options; no merged words or confusing symbols.\nStep 3 – Metric scoring: All binary metrics pass (1.0). Step 4 – Overall: With C=0, N=0, overall in 0.85–1.0; choose 0.96 reflecting strong quality.\nStep 5 – Consistency: All passes align with no identified issues.",
              "reasoning": "Strong, clear item aligned to Grade 3 conventions of standard English. The correct option uses simple present appropriately for a habitual action, and distractors represent common tense confusions. No clarity, alignment, or formatting problems identified.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Correct answer is indeed B (“sing” = simple present). A uses past (sang), C future (will sing), D present progressive (are singing). Explanation accurately states the habitual-action cue. No contradictions or mismatches.",
              "reasoning": "Answer key and explanation are correct and consistent with the options and standard grammar.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Assesses identification of simple present tense for habitual actions, directly matching L.3.1.E. No answer is revealed in student-facing text; skills targeted appropriately for Grade 3.",
              "reasoning": "Effectively measures the intended skill (simple present tense) without giveaways and at an appropriate level.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, universal context; no cultural specifics or sensitive content; age-appropriate language.",
              "reasoning": "Culturally neutral and age-appropriate; no localization concerns.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Standard CCSS.ELA-LITERACY.L.3.1.E targets forming/using simple verb tenses. Item asks for correct use of simple present in a habitual context—directly aligned.",
              "reasoning": "Direct alignment to Grade 3 standard on simple verb tenses.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous: “Which sentence uses the simple present tense correctly?” Each option is a clear, grammatical sentence. No alternative interpretations would change how to answer.",
              "reasoning": "Wording is clear and unambiguous; students know exactly what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context provides no explicit hard item-spec rules to enforce (confidence SOFT). No identifiable spec violations.",
              "reasoning": "No applicable hard specification; item follows common MCQ conventions.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common tense confusions: past (A), future (C), present progressive (D). Good diagnostic value for tense understanding.",
              "reasoning": "Incorrect choices are plausible and reflect typical tense errors.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2: No Difficulty Definitions provided. Applied bar for Grade 3 ELA – Easy: identify simple present vs. other tenses given a habitual time cue. The task is single-step recognition using a familiar adverbial phrase (“Every morning”). This fits Easy for Grade 3.",
              "reasoning": "Cognitive demand matches “easy” for Grade 3: simple recognition of tense in a familiar context.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context required; the item is self-contained.",
              "reasoning": "Not passage-based; no reference issues.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are parallel in structure, plausible, and differ only by tense; no length imbalance; one clear correct answer.",
              "reasoning": "Well-constructed, parallel options with plausible distractors.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus included; nothing misleading or distracting.",
              "reasoning": "No stimulus present; not applicable but acceptable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying knowledge of tense and time cues, distinguishing among similar forms; diagnostic of understanding rather than rote recall.",
              "reasoning": "Supports mastery by requiring application of tense knowledge to a realistic sentence frame.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 39.50779628753662,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.96
    },
    {
      "request_id": "a07d9826-0ded-453b-9d22-4485c1c5fac7",
      "evaluations": {
        "diverse_013": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Read & gather:\n- Student-facing stem: \"Which choice best demonstrates the skill described in L.3.1.E at hard difficulty?\"\n- Options: A) \"The correct choice that matches the standard.\" B) \"An incorrect distractor.\" C) \"Another incorrect distractor.\" D) \"Another incorrect distractor.\"\n- Labeled correct: A. Explanation: \"Option A is correct because it matches the skill described in the standard.\"\n- No stimulus/passage.\n\nStep 2 – Issues (committed list):\nISSUE1 (educational_accuracy): Option A text literally states it’s the correct choice: \"The correct choice that matches the standard.\" This trivially gives away the answer in a practice/assessment-type item.\nISSUE2 (curriculum_alignment): The item does not actually assess CCSS.ELA-LITERACY.L.3.1.E (forming/using simple verb tenses). The stem references a standard code rather than presenting sentences where students identify or use simple tenses.\nISSUE3 (clarity_precision): Stem \"Which choice best demonstrates the skill described in L.3.1.E at hard difficulty?\" is unclear for 3rd graders who won’t know the code or what action is required. A student might think they must recall what L.3.1.E is versus choosing a sentence that shows correct tense use.\nISSUE4 (distractor_quality): B–D are explicitly labeled as incorrect: \"An incorrect distractor.\" / \"Another incorrect distractor.\" These are implausible and provide no meaningful alternatives.\nISSUE5 (mastery_learning_alignment): The task requires no grammar reasoning; selecting the option labeled “correct” shows no understanding of verb tenses.\nISSUE6 (difficulty_alignment): Labeled \"hard\" but cognitively trivial (answer is given away), clearly mismatched to intended difficulty.\nISSUE7 (reveals_misconceptions): Because options don’t embody real tense errors, the item can’t diagnose misconceptions about simple verb tenses.\n\nChecklist A – Field consistency: Answer key (A) matches the option text and explanation; no mismatches.\nChecklist B1 – Giveaway: Yes, explicit giveaway in student-facing options (practice/assessment context). Fail educational_accuracy.\nChecklist B2 – Stimulus: None present; no issues.\nChecklist C – Diction/typos: No typos; wording is meta/unclear but not a typo.\n\nStep 3 – Metric scoring based on issues:\n- factual_accuracy: pass (no factual contradictions)\n- educational_accuracy: fail (ISSUE1)\n- curriculum_alignment: fail (ISSUE2)\n- clarity_precision: fail (ISSUE3)\n- specification_compliance: pass (no enforceable spec provided)\n- reveals_misconceptions: fail (ISSUE7)\n- difficulty_alignment: fail (ISSUE6)\n- passage_reference: pass (N/A)\n- distractor_quality: fail (ISSUE4)\n- stimulus_quality: pass (no stimulus)\n- mastery_learning_alignment: fail (ISSUE5)\n- localization_quality: pass (no cultural issues)\n\nStep 4 – Overall per rules: C=1 (educational_accuracy), N=6 (curriculum_alignment, clarity_precision, reveals_misconceptions, difficulty_alignment, distractor_quality, mastery_learning_alignment). Range 0.55–0.75; choose lower half due to critical failure and multiple non-critical fails → 0.60.\n\nStep 5 – Consistency check: All identified issues map to failed metrics; no failed metric lacks an issue.",
              "reasoning": "This item is unusable as a student assessment of L.3.1.E. The stem refers to a standard code rather than presenting a grammar task, and Option A literally says it is the correct choice, making the answer trivial. Distractors are placeholders that do not represent plausible tense errors, so the item cannot diagnose misconceptions. The result is a severe misalignment with the intended standard and difficulty.",
              "suggested_improvements": "- Replace the meta stem with a concrete, age-appropriate prompt targeting simple verb tenses (e.g., “Which sentence correctly uses the simple past tense?”).\n- Provide authentic choices that demonstrate correct and incorrect simple tense usage (e.g., I walk; I walked; I will walk), avoiding labels that reveal correctness.\n- Ensure distractors reflect common tense confusions (past vs present vs future; inconsistent verb tense within a sentence).\n- Match the intended hard difficulty by using sentences that require careful attention (e.g., context cues, time adverbs) without exceeding grade level.\n- Remove references to standard codes from the student-facing stem; keep them in metadata for teachers."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No factual claims about grammar or real-world facts are made. The key and explanation consistently identify A as correct; while pedagogically poor, this is not a factual contradiction.",
              "reasoning": "There are no factual errors or internal contradictions in the content as written.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The option text \"The correct choice that matches the standard.\" trivially reveals the answer in a practice/assessment context. The stem is meta and does not engage the intended grammar skill (simple tenses).",
              "reasoning": "The answer is given away directly in Option A, and the item does not actually assess forming or using simple verb tenses.",
              "suggested_improvements": "Create a real grammar task using sentences that require identifying or choosing correct simple tense forms, and remove any option text that labels correctness."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral language; no culture-specific content; age-appropriate context (despite being meta). Using a standard code is not a cultural issue.",
              "reasoning": "The content is culturally neutral and appropriate for a broad audience.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: The question references L.3.1.E but does not present any sentences or tasks involving forming/using simple verb tenses. It’s meta-selection rather than skill assessment.",
              "reasoning": "It does not measure the Grade 3 skill of forming and using simple verb tenses; it only references the standard code.",
              "suggested_improvements": "Ask students to choose or form verbs in simple past/present/future within sentences that include time cues and subject-verb agreement considerations."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: Stem \"Which choice best demonstrates the skill described in L.3.1.E at hard difficulty?\" is ambiguous for students unfamiliar with the code. Alternate interpretation: students might try to recall the meaning of L.3.1.E instead of evaluating sentence tense usage, which changes the approach to answering.",
              "reasoning": "The stem’s reference to a standard code is unclear to Grade 3 students and does not clearly state what action to take.",
              "suggested_improvements": "State the task explicitly without codes (e.g., “Which sentence uses the simple past tense correctly?”)."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit, enforceable item specification with hard requirements was provided. Under the evaluator rules, pass by default.",
              "reasoning": "No clear external item-spec rules to enforce; therefore, no spec violations.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE7: Choices do not embody real tense errors; they are placeholders. The item provides no diagnostic insight into students’ understanding of simple verb tenses.",
              "reasoning": "Because distractors are not plausible tense mistakes, the item cannot surface misconceptions about verb tenses.",
              "suggested_improvements": "Use distractors reflecting common errors (e.g., wrong tense for time adverbs, inconsistent tense within a sentence, misusing future markers)."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "No Difficulty Definitions provided in curriculum context. Applied own bar: For Grade 3 L.3.1.E, “hard” should involve nuanced context cues/time adverbs or multi-clause sentences requiring careful tense choice. Actual item is trivial due to the self-labeled correct option; thus it is far below intended difficulty (and even below grade level cognitive demand).",
              "reasoning": "The problem is labeled hard but is trivial; it does not require analysis or application appropriate to a hard item for Grade 3.",
              "suggested_improvements": "Increase cognitive demand with realistic sentences that require selecting the correct simple tense based on context while avoiding unnecessary complexity."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context to reference; N/A passes per rules.",
              "reasoning": "No passage involved; nothing to reference.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: Distractors are explicitly labeled as incorrect and are not plausible alternatives. No grammatical parallelism or content plausibility relative to the target skill.",
              "reasoning": "Answer choices are placeholders and make the correct answer obvious; distractor quality is poor.",
              "suggested_improvements": "Write grammatically parallel sentences that differ only in tense correctness; ensure each distractor is a realistic error students might make."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus is provided; no risk of being wrong, misleading, or distracting.",
              "reasoning": "No image or passage; nothing to evaluate for stimulus quality.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE5: The task requires no reasoning or application of grammar knowledge; the correct choice is explicitly labeled, offering no diagnostic value.",
              "reasoning": "The item does not require applying knowledge or reasoning; it cannot distinguish understanding from guessing or copying.",
              "suggested_improvements": "Require students to analyze sentences and select the one that correctly uses simple verb tenses, or edit a sentence to correct its tense usage."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 67.54794764518738,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_013\"\nLINE 11:         'diverse_013', '2.3.0', '{\"request_id\": \"a07d9826-0d...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "80c2bfa2-ff22-456b-b2d2-09e05377be1f",
      "evaluations": {
        "diverse_014": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Intent: This is a standalone MCQ intended as a practice/assessment item for Grade 3 ELA (CCSS L.3.1.E – simple verb tenses). No instructional walkthrough; therefore apply practice/assessment rules.\n\nStep 2 – Issues (committed):\n- ISSUE1 (educational_accuracy – answer giveaway): Option A text reads, “The correct choice that matches the standard.” This trivially reveals the answer before any attempt.\n- ISSUE2 (curriculum_alignment): Stem references “L.3.1.E” but no content assesses forming/using simple verb tenses. Stem: “Which choice best demonstrates the skill described in L.3.1.E at medium difficulty?” Options are meta, not language samples.\n- ISSUE3 (clarity_precision): The stem uses the code “L.3.1.E” without student-friendly wording; a Grade 3 student would not know this code or what action is required. Multiple plausible interpretations (e.g., pick a sentence using simple tense vs. pick a meta-description).\n- ISSUE4 (distractor_quality): Choices B–D are generic (“An incorrect distractor.” / “Another incorrect distractor.”). Option A is labeled “The correct choice…”. They are implausible and telegraph the answer; poor plausibility/parallelism.\n- ISSUE5 (reveals_misconceptions): With placeholder, content-free options, the item does not target common misconceptions (e.g., tense shifts, irregular past forms), offering no diagnostic value.\n- ISSUE6 (difficulty_alignment): Labeled “medium” but the task is trivial because A is declared correct; cognitive demand far below Grade 3 expectations for this standard.\n- ISSUE7 (mastery_learning_alignment): Requires no reasoning or application; success depends on spotting the meta label, not demonstrating verb tense understanding.\n\nChecklist A (Field Consistency): Answer key (A) matches explanation; no cross-field mismatches noted.\nChecklist B1 (Answer Giveaway): Fails – explicit giveaway in student-facing option A text.\nChecklist B2 (Stimulus Quality): No stimulus.\nChecklist C (Diction/Typo): No typos, but clarity problem due to code reference.\n\nStep 3 – Metric scoring: factual_accuracy=1.0 (no concrete factual errors), educational_accuracy=0.0 (giveaway), curriculum_alignment=0.0, clarity_precision=0.0, specification_compliance=1.0 (no enforceable spec provided), reveals_misconceptions=0.0, difficulty_alignment=0.0, passage_reference=1.0, distractor_quality=0.0, stimulus_quality=1.0, mastery_learning_alignment=0.0, localization_quality=1.0.\n\nStep 4 – Overall per rules: C=1 (educational_accuracy), N=6 (clarity, curriculum, distractor_quality, reveals_misconceptions, difficulty, mastery). Range = 0.55–0.75. Choose lower half (0.60) due to critical failure and multiple non-critical failures.\n\nStep 5 – Consistency: Each failed metric is supported by a specific issue; no metric without an issue is failed.",
              "reasoning": "Significant flaws: the correct answer is explicitly given in option A, the stem uses a standard code unfamiliar to Grade 3 students, and the item does not actually assess simple verb tenses. Distractors are placeholders, offering no diagnostic value. As a result, the item fails its educational intent and alignment, with low difficulty and no mastery value. No factual errors or stimulus problems were found.",
              "suggested_improvements": "- Replace the meta stem with student-friendly language: “Which sentence uses the simple past tense correctly?”\n- Provide authentic options that test simple verb tenses (present, past, future), including plausible distractors that reflect common errors (e.g., irregular past forms, tense shifts within a sentence).\n- Remove meta labels like “The correct choice…” from options.\n- Calibrate to medium difficulty by using irregular verbs or subtle time cues (yesterday/tomorrow) and near-miss distractors.\n- Ensure instructions avoid standard codes; use clear, age-appropriate wording."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No mathematical/scientific claims or real-world facts to verify. The answer key and explanation consistently identify A as correct. While pedagogically poor, this is not a factual mismatch per policy.",
              "reasoning": "No concrete factual errors or internal contradictions were found.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "Primary failure due to answer giveaway (Checklist B1): Option A reads, “The correct choice that matches the standard.” This is student-facing in a practice/assessment context, so the final answer is trivially visible before any reasoning. Additionally, the item does not actually assess L.3.1.E (assessed under curriculum_alignment).",
              "reasoning": "Option A explicitly labels itself as correct, making the answer trivial. The item also does not genuinely assess forming/using simple verb tenses.",
              "suggested_improvements": "Use student-friendly stems tied to the skill (e.g., choose the sentence in simple past). Provide authentic sentence options and remove meta labels that reveal the answer."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "No cultural references or sensitive content; neutral classroom phrasing. Age-appropriateness issues are pedagogical, not localization.",
              "reasoning": "Content is culturally neutral and age-appropriate in tone.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "The standard L.3.1.E addresses forming/using simple verb tenses. The item’s stem references the code but provides only meta placeholder options, not sentences demonstrating tense usage. This fails to assess the targeted standard.",
              "reasoning": "The question does not assess forming and using simple verb tenses; it’s meta about the standard instead.",
              "suggested_improvements": "Provide sentences requiring students to identify or use simple present/past/future tenses, including irregular verbs and time cues to align with L.3.1.E."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "Condition 1: Ambiguity—“Which choice best demonstrates the skill described in L.3.1.E at medium difficulty?” relies on a code unfamiliar to Grade 3 students and doesn’t specify what action is required. Condition 2: Alternate interpretations—students could think they must choose (a) a sentence using a specific tense, or (b) a meta description (since the options are meta). These would change how they answer.",
              "reasoning": "The stem is unclear for Grade 3 and uses the code L.3.1.E without explanation, making the task ambiguous.",
              "suggested_improvements": "Replace the code with student-friendly wording and specify the task (e.g., “Choose the sentence that uses the simple future tense correctly.”)."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context is SOFT and provides no explicit, prescriptive item-spec rules (no must/forbidden/format constraints). Per policy, with no clear spec, this metric passes.",
              "reasoning": "No enforceable item specification was provided; thus there is nothing to violate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "Distractors are content-free placeholders and do not target common tense errors (e.g., irregular past vs. regular, tense shifts). This offers no diagnostic insight into student misunderstandings.",
              "reasoning": "Choices do not reflect plausible tense misconceptions, so the item cannot reveal learning gaps.",
              "suggested_improvements": "Create distractors that mirror real mistakes (e.g., “Yesterday, I walk to school.” vs. “Yesterday, I walked to school.”)."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "Scenario 2 (No Difficulty Definitions): Define “medium” for Grade 3 L.3.1.E as requiring application—choosing among plausible sentences with varied tenses/irregular verbs. Actual item is trivial because the correct option announces itself; cognitive demand is far below Grade 3 expectations (≥2 grade levels easier). Therefore, clear mismatch.",
              "reasoning": "Labeled “medium,” but the task is trivial and requires no application or reasoning.",
              "suggested_improvements": "Design options with subtle tense contrasts and irregular verbs, remove giveaways, and ensure students must analyze form and use of simple tenses."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context is referenced or required; N/A passes.",
              "reasoning": "Self-contained item; no passage needed.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "Options are not plausible: A is explicitly labeled correct; B–D are generic placeholders. This violates plausibility and telegraphs the answer; poor homogeneity and diagnostic value.",
              "reasoning": "Distractors are generic and implausible, and the correct answer is telegraphed by wording.",
              "suggested_improvements": "Write realistic sentence options with consistent structure and specificity; ensure all are plausible and only one is correct for the targeted tense skill."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus is present; nothing misleading or distracting to evaluate. Per policy, absence of stimulus passes.",
              "reasoning": "No image or passage; no stimulus issues.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "The item requires no computation, application, or reasoning—students can answer by picking the meta-labeled option. This meets the fail conditions (purely trivial, no diagnostic value).",
              "reasoning": "Does not require understanding or application of verb tenses; success is unrelated to mastery.",
              "suggested_improvements": "Require students to analyze sentences for correct simple tense usage or correct a sentence with a tense error to demonstrate understanding."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 90.012526512146,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_014\"\nLINE 11:         'diverse_014', '2.3.0', '{\"request_id\": \"80c2bfa2-ff...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "9d730dd0-aed3-4000-b8a4-ffc6bd478c12",
      "evaluations": {
        "diverse_015": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.75,
              "internal_reasoning": "Step 1: Determined this is a Grade 3 ELA MCQ (practice/assessment). Student-facing content: stem and four options; no stimuli. Metadata: correct answer labeled A; explanation provided.\n\nStep 2 – Issues (commit):\nISSUE1 (factual_accuracy): Snippet: \"In sentence A, the singular subject 'puppy' matches the singular verb 'wags,' and the singular pronouns 'its' and 'his' correctly refer back to the puppy.\" Problem: Option A uses \"its\" and \"it\" (and another \"its\"), not \"his\". This is a field mismatch between the explanation and the actual option text.\n\nChecklist A (Field Consistency): Mismatch found in explanation vs. option A pronouns → factual_accuracy issue logged. Correct answer key (A) itself is correct.\nChecklist B (Answer Giveaway): None; no pre-attempt reveal of the answer.\nChecklist C (Diction/Typo): Student-facing text is clear; no typos.\n\nStep 3 – Metric scores set accordingly: factual_accuracy=0.0 due to ISSUE1; all others pass.\n\nStep 4 – Overall per rules: C=1 (factual_accuracy), N=0 → overall must be 0.70–0.84. Since a critical metric failed, choose lower half → 0.75.\n\nStep 5 – Consistency: The single issue maps to factual_accuracy; all other metrics have no issues and pass.",
              "reasoning": "Well-constructed Grade 3 item assessing subject-verb and pronoun-antecedent agreement with clear, plausible distractors. However, the provided explanation incorrectly states that sentence A uses the pronoun “his.” This metadata error reduces reliability, though the student-facing content is sound.",
              "suggested_improvements": "Correct the explanation to match option A. For example: \"In sentence A, the singular subject 'puppy' matches the singular verb 'wags,' and the singular pronouns 'it' and 'its' correctly refer back to the puppy.\""
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "Field consistency failure: The explanation claims option A uses pronouns \"its\" and \"his.\" Actual option A text is \"The puppy wags its tail when it sees its owner,\" which contains pronouns \"its,\" \"it,\" and \"its\"—no \"his.\" Correct option key (A) is accurate; only the explanation is incorrect.",
              "reasoning": "The explanation mismatches the option text by attributing the pronoun “his” to sentence A, which it does not contain.",
              "suggested_improvements": "Revise the explanation to reference \"it\" and \"its\" (not \"his\")."
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The item cleanly targets L.3.1.F (subject-verb and pronoun-antecedent agreement). No answer giveaway in student-facing content. Metadata error does not affect the educational intent of the item itself.",
              "reasoning": "The question directly assesses subject-verb and pronoun-antecedent agreement at an appropriate level without revealing the answer.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, universally accessible language; no culture-specific references; age-appropriate.",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Aligned to CCSS.ELA-LITERACY.L.3.1.F—ensuring subject-verb and pronoun-antecedent agreement. Options are constructed to test these agreements explicitly.",
              "reasoning": "Clearly aligned with L.3.1.F by focusing on subject-verb and pronoun-antecedent agreement.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem and choices are unambiguous about the task; no conflicting interpretations or malformed text.",
              "reasoning": "Wording is clear and unambiguous for Grade 3 readers.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit hard item specification provided; under SOFT context and rules, no enforceable spec to violate.",
              "reasoning": "No clear item-writing spec to enforce; the item follows standard MCQ conventions.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors reflect common errors: using plural \"their\" with singular antecedent, gendered \"his\" mixed with neuter \"it,\" and number mismatch in the noun (\"tails\"). These are plausible misconceptions.",
              "reasoning": "Incorrect choices reflect realistic agreement mistakes students might make.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2 (no difficulty definitions provided). Applied an \"easy\" bar for Grade 3 L.3.1.F: short sentence, single-step identification of correct agreement, straightforward distractors. The item matches this level.",
              "reasoning": "Appropriate as an easy item for Grade 3: brief sentence-level grammar choice.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context required; item is self-contained.",
              "reasoning": "No passage involved; N/A and acceptable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are grammatically parallel and similar in length; each wrong option is plausible and diagnostically meaningful. None are obviously absurd or telegraph the answer.",
              "reasoning": "All distractors are plausible and target typical agreement errors.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus; not applicable and acceptable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires application of grammar rules (agreement) rather than recall of a fact; can distinguish understanding of pronoun and verb agreement.",
              "reasoning": "Students must apply agreement rules, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 87.15674114227295,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.75
    },
    {
      "request_id": "abfba875-0c9b-4e54-93a9-429843b0fd10",
      "evaluations": {
        "diverse_016": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.74,
              "internal_reasoning": "Step 1 – Intent: MCQ practice item for Grade 3 ELA (L.3.1.F) on subject-verb and pronoun-antecedent agreement.\n\nStep 2 – Issues:\n- ISSUE1 (factual_accuracy – Field Consistency): The answer_explanation says: \"the singular pronoun 'its' correctly refers back to the flock,\" but Option B actually uses \"it\" (\"...and it begins to sing loudly.\"). This is a mismatch between supporting text and the actual option content.\n\nChecklist A (Field Consistency): Mismatch found between explanation ('its') and option B ('it').\nChecklist B (Answer Giveaway): No giveaways in student-facing content; answer key is metadata only.\nChecklist C (Diction/Typo): Student-facing text is clean; no merged words or confusing symbols.\n\nStep 3 – Metric scoring based only on identified issues:\n- factual_accuracy = 0.0 due to the explanation/option mismatch.\n- All other metrics have no identified issues and pass.\n\nStep 4 – Overall per rules: C=1 (factual_accuracy fail), N=0 → overall must be in 0.70–0.84. Because a critical metric failed, choose the lower half of the range → 0.74.\n\nStep 5 – Self-consistency: The only failed metric is factual_accuracy, tied to ISSUE1. All others pass; consistent.",
              "reasoning": "Well-targeted Grade 3 grammar item with clear stem and plausible distractors. However, the explanation incorrectly references “its” when the correct option uses “it,” creating a field mismatch. Fixing the explanation would make the item solid across metrics.",
              "suggested_improvements": "Correct the explanation to match Option B: e.g., “In option B, the singular subject ‘The flock of birds’ takes the singular verb ‘flies,’ and the singular pronoun ‘it’ correctly refers back to ‘flock.’”"
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The explanation states: “the singular pronoun ‘its’ correctly refers back to the flock,” but Option B uses “it,” not “its.” This is a concrete field mismatch between supporting text and the option content, triggering a factual_accuracy failure per the Field Consistency rule.",
              "reasoning": "The answer explanation mentions “its,” but Option B uses “it.” This mismatch makes the supporting content factually inconsistent with the item.",
              "suggested_improvements": "Revise the explanation to reference “it,” not “its,” and ensure all supporting text precisely matches the options."
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The item directly assesses subject-verb and pronoun-antecedent agreement with a collective noun (“flock”)—appropriate for L.3.1.F. No answer giveaways in student-facing content. Explanation mismatch is not an educational intent issue.",
              "reasoning": "Assesses the intended grammar skills appropriately for Grade 3, with no pre-attempt answer reveal.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, universally understandable content; no cultural sensitivities or localization issues.",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly targets CCSS L.3.1.F (subject-verb and pronoun-antecedent agreement). Complexity and focus are aligned.",
              "reasoning": "Directly aligned to L.3.1.F by requiring correct agreement with a collective noun and a matching pronoun.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous; each option is clearly written. No phrases with multiple plausible interpretations affecting student action.",
              "reasoning": "Wording is clear and unambiguous; students know exactly what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and provides no enforceable item-format specifications. No clear, explicit spec to enforce; thus pass.",
              "reasoning": "No explicit item-format requirements were provided; no violations identified.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors reflect common errors: plural verb with collective noun; pronoun agreeing with the object of a preposition (“birds” → they) instead of the head noun (“flock”). Good diagnostic value.",
              "reasoning": "Incorrect choices model common agreement mistakes, giving diagnostic insight.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions found for this standard (all unspecified). Applied own bar: For Grade 3 grammar, identifying the head noun in a prepositional phrase (“flock of birds”) and ensuring both verb and pronoun agreement is a moderate-to-challenging task. Labeled difficulty is “hard,” which is acceptable because it requires attention to two agreement points and collective-noun reasoning—plausibly at the upper end for Grade 3. Not ≥2 grade levels off.",
              "reasoning": "Cognitive demand (two agreement checks with a collective noun) suits an upper-end Grade 3 difficulty; “hard” is reasonable.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context involved; item is self-contained.",
              "reasoning": "No passage required or referenced; N/A but acceptable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are grammatically parallel, plausible, and differentiate between verb and pronoun agreement. No length or specificity imbalances that telegraph the answer.",
              "reasoning": "All distractors are plausible and well-constructed, targeting realistic errors.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus; not applicable but acceptable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires application of agreement rules (not mere recall) across both verb and pronoun elements; distinguishes partial vs. full understanding.",
              "reasoning": "Students must apply rules to evaluate sentences, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 75.22030138969421,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.74
    },
    {
      "request_id": "fe6944eb-f7cf-42b4-8f00-456967a09681",
      "evaluations": {
        "diverse_017": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Intent: This is a practice/assessment-style MCQ for Grade 3 ELA, targeting CCSS L.3.1.F (subject-verb and pronoun-antecedent agreement). No stimulus. Correct answer labeled A in metadata.\n\nStep 2 – Issues:\nISSUE1 (educational_accuracy): Stem: \"Which choice best demonstrates the skill described in L.3.1.F at medium difficulty?\" This does not actually assess subject-verb/pronoun-antecedent agreement; it's meta-referential and asks about a standard code rather than having students apply the skill.\nISSUE2 (educational_accuracy – giveaway): Option A text: \"The correct choice that matches the standard.\" This trivially signals itself as correct before any attempt, failing the triviality test for practice/assessment items.\nISSUE3 (clarity_precision): The stem references a standard code (\"L.3.1.F\") without explaining it; for Grade 3 students this is unclear/ambiguous and does not specify what action/skill to demonstrate.\nISSUE4 (curriculum_alignment): No option content involves subject-verb or pronoun-antecedent agreement; thus the item does not measure the stated standard.\nISSUE5 (distractor_quality): Options B–D are placeholders (\"An incorrect distractor.\", \"Another incorrect distractor.\") and are not plausible or content-aligned, violating plausibility/homogeneity expectations.\nISSUE6 (reveals_misconceptions): Because distractors are generic and unrelated to the target skill, the item cannot surface typical misconceptions (e.g., singular/plural verb agreement, pronoun-antecedent mismatch).\nISSUE7 (difficulty_alignment): Labeled \"medium\" but provides either trivial selection (pick the self-labeled correct option) or an impossible meta task; does not reflect medium cognitive demand for L.3.1.F.\nISSUE8 (mastery_learning_alignment): Requires no application or reasoning about grammar; success hinges on recognizing a meta-labeled correct option.\n\nChecklist A – Field consistency: No internal contradictions across fields; answer key says A and explanation says A, though content is placeholder. No mismatched option references. → No factual_accuracy issue.\nChecklist B – Answer giveaway: Present in student-facing option A text; no reveal cues. → educational_accuracy failure.\nChecklist C – Diction/Typo: No typos/merged words; issue is semantic clarity, not mechanics.\n\nStep 3 – Metric scoring set accordingly.\nStep 4 – Overall per rules: C=1 (educational_accuracy), N=6 (clarity_precision, curriculum_alignment, distractor_quality, reveals_misconceptions, difficulty_alignment, mastery_learning_alignment) ⇒ overall in 0.55–0.75. Chose 0.60 (lower half) due to critical failure and multiple non-critical failures.\nStep 5 – All issues map to at least one failed metric; no orphaned issues.",
              "reasoning": "This item does not present any content that assesses Grade 3 subject-verb or pronoun-antecedent agreement. The stem references a standard code students won’t understand, and option A literally says it is the correct choice, giving away the answer. Distractors are generic placeholders and do not reveal misconceptions. As a result, the item fails its educational purpose and alignment, lacks clarity for the target audience, and does not require any reasoning.",
              "suggested_improvements": "- Replace the stem with a student-friendly prompt that directly targets L.3.1.F (e.g., “Which sentence uses correct subject-verb agreement?” or “Which sentence has a pronoun that matches its antecedent?”).\n- Replace placeholders with real, grade-appropriate sentences, including one correct answer and plausible distractors that reflect common errors (e.g., singular/plural mismatches, ambiguous pronouns).\n- Remove meta language and any self-referential wording like “The correct choice…”.\n- Calibrate to medium difficulty by using mildly complex structures (e.g., compound subjects, intervening phrases, or simple pronoun-antecedent contexts) while staying Grade 3-appropriate.\n- Keep rationale/explanations in post-attempt feedback, not in options."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No concrete factual claims (dates, definitions, counts) to verify. Answer key and explanation both point to A; no contradictions among fields. Although content is non-substantive, that is not a factual error per rubric.",
              "reasoning": "No factual errors or internal contradictions are present.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "Fails purpose on two grounds: (1) It doesn’t assess L.3.1.F at all; the stem is meta (“skill described in L.3.1.F”) and options lack grammar content. (2) Explicit giveaway: Option A literally says “The correct choice…,” making the answer trivial before any attempt in a practice/assessment context.",
              "reasoning": "The item does not require applying subject-verb or pronoun-antecedent agreement and trivially reveals the answer through option A’s wording.",
              "suggested_improvements": "Use student-facing wording tied to the skill (e.g., choose the sentence with correct agreement) and ensure no option text labels itself as correct. Provide real sentences reflecting the target skill."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "No cultural or sensitive content. Neutral language.",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "Target standard inferred (L.3.1.F). The item includes no sentences or pronoun/antecedent content, so it cannot measure this standard.",
              "reasoning": "The question does not assess subject-verb or pronoun-antecedent agreement; it is meta-referential and misaligned with L.3.1.F.",
              "suggested_improvements": "Include sentence-level options that test subject-verb agreement and pronoun-antecedent agreement directly, aligned to Grade 3 expectations."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "Ambiguity: \"Which choice best demonstrates the skill described in L.3.1.F at medium difficulty?\" A Grade 3 student is unlikely to know “L.3.1.F” or what “the skill” refers to, making required action unclear. Alternate interpretations: (a) guess at the meta-correct choice; (b) be confused about what the skill is. This changes how a student might answer (guess vs apply grammar).",
              "reasoning": "The stem uses a standard code and vague phrasing; students won’t know what skill is being asked, making the task unclear.",
              "suggested_improvements": "Name the skill in student-friendly terms (e.g., “subject-verb agreement”) and specify exactly what to choose (e.g., “Choose the sentence that is written correctly.”)."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and provides no explicit item-spec rules (no must/forbidden constraints). Per rules, treat as no enforceable spec; therefore pass.",
              "reasoning": "No clear, enforceable item specification was provided; no spec violations identified.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "Distractors are content-free placeholders and do not embody typical L.3.1.F errors, so the item cannot reveal misconceptions about agreement.",
              "reasoning": "Choices do not reflect common mistakes (e.g., singular/plural mismatches, pronoun-antecedent errors), providing no diagnostic value.",
              "suggested_improvements": "Write distractors that mirror realistic errors (e.g., “The dogs runs fast.” or “Each student forgot their pencil.”) so selections reveal specific misunderstandings."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "Scenario 2 applies (no difficulty definitions). Difficulty bar for “medium” in Grade 3 L.3.1.F: Students discriminate among 3–4 sentences with subtle agreement contrasts (e.g., compound subjects, intervening phrases, simple pronoun-antecedent) requiring application rather than mere recall. Actual item is either trivial (pick the self-labeled correct option) or impossible (meta prompt without content). This is a clear mismatch with intended medium difficulty.",
              "reasoning": "The task does not present a medium-level application of the skill; it is either trivial or non-actionable for students.",
              "suggested_improvements": "Provide 3–4 grammatically similar sentences with one correct and others containing realistic agreement errors to achieve a medium level of challenge."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage is provided or required; item is self-contained (despite being ill-formed).",
              "reasoning": "No passage context is involved; N/A and acceptable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "Options B–D are generic placeholders and not plausible alternatives; they do not match the specificity of a real correct option, and the correct answer is telegraphed by A’s wording. Violates plausibility, homogeneity, and balance.",
              "reasoning": "Distractors are not meaningful or plausible; the correct answer is telegraphed by wording.",
              "suggested_improvements": "Replace with realistic, content-based distractors that are grammatically parallel and plausibly incorrect for the targeted skill; ensure no option self-identifies as correct."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus; nothing to impair learning.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "The item does not require application of agreement rules or any reasoning; success is based on recognizing a meta cue (“The correct choice…”). This fails the mastery criterion.",
              "reasoning": "The task does not require evidence-based reasoning or application of the target skill.",
              "suggested_improvements": "Require students to evaluate sentences for agreement and select or correct them, prompting genuine application of the rule."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 95.41950225830078,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_017\"\nLINE 11:         'diverse_017', '2.3.0', '{\"request_id\": \"fe6944eb-f7...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "522fb71c-043e-4ce3-94e4-5983ff242de2",
      "evaluations": {
        "diverse_018": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.75,
              "internal_reasoning": "Step 1: Determined item is a Grade 3 ELA MCQ targeting CCSS L.3.1.G (comparative/superlative adjectives/adverbs). No stimulus. \n\nStep 2 – Issues:\n- ISSUE1 (factual_accuracy): Stem says “Which word correctly completes the sentence to show a superlative adjective?” for the sentence “Of all the runners, Maya finished the race the _______.” In this context, the blank modifies the verb “finished,” so the required form is a superlative adverb (fastest), not a superlative adjective. This mislabels the part of speech.\n- ISSUE2 (factual_accuracy): Explanation states: “'Fastest' is the superlative form of the adjective 'fast.'” While “fast” can be an adjective in other contexts, here “fastest” functions as an adverb. The explanation reinforces the mislabel.\n\nChecklist A (Field Consistency): Correct answer key C = “fastest” matches options and the explanation’s intent. No mismatches across fields.\nChecklist B (Answer Giveaway): No pre-attempt reveal of the answer. Answer key is metadata only → no giveaway.\nChecklist C (Diction/Typo): No typos or confusing symbols; directions are otherwise clear.\n\nStep 3 – Metric scores derived from issues: factual_accuracy fails due to mislabeling; all other metrics pass.\nStep 4 – Overall score per rules: C=1 (critical fail), N=0 → overall must be in 0.70–0.84. Because a critical metric failed, choose lower half → 0.75.\nStep 5 – Consistency: All issues mapped to factual_accuracy; other metrics unaffected.",
              "reasoning": "Strong, age-appropriate MCQ assessing superlatives with clear context cues (“Of all the runners…”). Options are well-constructed and diagnostic. However, the item inaccurately labels the needed form as a “superlative adjective” when the word functions as a superlative adverb in this sentence. The explanation repeats this mislabel. Everything else aligns well with Grade 3 standards and intent.",
              "suggested_improvements": "Fix the part-of-speech labeling: either (a) change the stem to “superlative form” or “superlative adverb,” and update the explanation to note that “fastest” functions as an adverb here; or (b) change the sentence so the blank clearly requires an adjective (e.g., “Of all the runners, Maya is the ______ runner.”) and keep “superlative adjective.”"
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The prompt asks for a “superlative adjective,” but in “finished the race the _______,” the blank modifies a verb; thus, the correct form is a superlative adverb, not an adjective. ISSUE2: The explanation claims “'Fastest' is the superlative form of the adjective 'fast',” which is misleading in this sentence’s usage; here “fastest” functions adverbially. These constitute factual inaccuracies about part of speech in context.",
              "reasoning": "The item misidentifies the required part of speech: the sentence requires a superlative adverb, not a superlative adjective, and the explanation reinforces this mislabel.",
              "suggested_improvements": "Revise the stem to request a “superlative adverb” or “superlative form,” and update the explanation to note that “fastest” functions as an adverb in this sentence. Alternatively, change the sentence to require an adjective (e.g., “…Maya is the ______ runner”) if you want to keep “superlative adjective.”"
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Despite the mislabel, the task still targets the intended skill domain (forming/choosing superlative vs comparative forms) within L.3.1.G. No answer giveaway or off-target assessment.",
              "reasoning": "The item meaningfully assesses knowledge of superlative versus comparative forms appropriate to Grade 3.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral U.S. English context with no cultural dependencies or sensitive content.",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly aligns with CCSS L.3.1.G (forming and using comparative/superlative adjectives and adverbs, and choosing between them). The sentence context (“Of all the runners…”) cues superlative use.",
              "reasoning": "Clearly aligned to the standard on comparative and superlative forms.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Wording is clear and unambiguous about the task (choose the correct word to complete the sentence). Although the part-of-speech label is inaccurate, it does not create an ambiguous task for students per the clarity criteria.",
              "reasoning": "Students can understand exactly what to do and how to answer.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context is SOFT; no explicit hard item-spec requirements provided. No enforceable spec to violate.",
              "reasoning": "No clear item spec was provided; nothing indicates non-compliance.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common errors: base form (fast), comparative instead of superlative (faster), and misformed comparative with “more” for a one-syllable word (more fast).",
              "reasoning": "Choices are diagnostic of typical misconceptions about degrees of comparison.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2 applies: No Difficulty Definitions provided. For Grade 3 L.3.1.G, “Easy” can mean selecting the correct degree of comparison using clear context cues (“Of all the runners…”). This item requires recognizing the superlative signal and choosing the appropriate form, which fits an Easy classification for the grade.",
              "reasoning": "Cognitive demand is appropriate for an Easy Grade 3 item on superlatives.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No external passage; the item is self-contained.",
              "reasoning": "Not applicable; passes by default.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options are parallel single-word forms; plausible and homogeneous; correct answer not telegraphed by length or specificity. Each distractor represents a realistic error type.",
              "reasoning": "Options are well-crafted and balanced.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus is present; nothing misleading or distracting.",
              "reasoning": "No image or extra stimulus; not applicable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying knowledge of degrees of comparison to sentence context with a superlative cue. Not mere rote recall in isolation; demonstrates understanding of when to use superlative.",
              "reasoning": "The task elicits applied understanding of superlative usage.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 105.54463529586792,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.75
    },
    {
      "request_id": "4c1a698c-c9a6-42b0-abbb-379b2f1046f2",
      "evaluations": {
        "diverse_019": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.95,
              "internal_reasoning": "Step 1: Classified as a Grade 3 ELA MCQ targeting CCSS.ELA-LITERACY.L.3.1.G (comparative/superlative adjectives/adverbs). Practice/assessment item; no reveal cues needed beyond standard options.\n\nStep 2 – Issues:\n- Checklist A (Field Consistency): Answer key = A; explanation matches option A; no mismatches.\n- Checklist B1 (Giveaway): No answer shown pre-attempt; options only. Not a worked example. No trivial giveaway.\n- Checklist B2 (Stimulus): No stimulus.\n- Checklist C (Diction/Typos): No errors in student-facing text.\nNo issues identified.\n\nVerification: Option A correctly uses a comparative adverb (“more quickly”) to compare two (Maya, Leo) and a superlative adverb (“the fastest … of all three runners”) for a group of three. B incorrectly uses “quicker” as an adverb and “most fast”; C misuses “fastest than”; D uses nonstandard “quicker” and lacks “the” before superlative while A is fully correct.\n\nScores: All binary metrics pass (1.0). Overall chosen in ACCEPTABLE range (0.85–1.0) with 0.95 since no issues and strong alignment/quality.",
              "reasoning": "Well-constructed Grade 3 ELA item assessing comparative vs. superlative adverbs. Correct answer and rationale are accurate; wording is clear; distractors reflect common errors; difficulty is appropriate for a “hard” item at this grade level. No issues found.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Checked correctness and consistency: A is the only option that uses a proper comparative adverb (“more quickly”) and a proper superlative adverb with appropriate group reference (“the fastest of all three runners”). Answer key and explanation are consistent. No contradictions or factual errors.",
              "reasoning": "The labeled correct answer (A) is truly correct, and the explanation aligns with it.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Targets L.3.1.G by requiring identification of comparative and superlative adverbs in context. Practice/assessment item with no pre-attempt answer reveal. Task directly measures intended skill and avoids unrelated demands.",
              "reasoning": "Directly assesses forming/choosing comparative and superlative adverbs without giveaways or off-target skills.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral names (Maya, Leo, Carlos), common context (running), no cultural assumptions or sensitive content. Age-appropriate language.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Explicitly aligned to CCSS.ELA-LITERACY.L.3.1.G: using comparative/superlative adverbs appropriately. Complexity and focus match Grade 3 conventions of standard English.",
              "reasoning": "Strong alignment to CCSS L.3.1.G (comparative/superlative adverbs).",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem clearly states what to find, including the two-vs-three comparison cue. No ambiguous phrasing or grammatical confusion. Options are complete sentences.",
              "reasoning": "Clear, precise prompt and options; unambiguous task.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context marked SOFT and no explicit item spec with hard format rules provided. Therefore, no enforceable spec; default pass.",
              "reasoning": "No explicit hard specification to enforce; item follows typical MCQ conventions.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors reflect common mistakes: using adjective instead of adverb (“quicker”), incorrect superlative formation (“most fast”), and misusing superlative with ‘than’ (“fastest than”). These diagnose misunderstandings about forms and comparative vs. superlative usage.",
              "reasoning": "Wrong choices mirror realistic student errors, supporting diagnostic value.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided; applying Scenario 2 rules. Difficulty bar for “hard” at Grade 3 for this standard: requires distinguishing adjective vs. adverb forms, applying comparative vs. superlative correctly in a two-vs-three comparison within full sentences, and evaluating multiple subtle errors. This item meets that bar (multi-faceted grammatical judgment).",
              "reasoning": "Cognitive demand is appropriate for a harder Grade 3 conventions item.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context needed; item is self-contained.",
              "reasoning": "No passage involved; N/A and acceptable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are grammatically parallel (sentences), plausible to students with partial understanding, and balanced in length. The correct answer isn’t telegraphed by length or specificity. Each distractor features a distinct, teachable error.",
              "reasoning": "Plausible, well-constructed distractors with good parallelism and balance.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No stimulus; no risk of harm.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying rules about comparative/superlative adverbs and adjective vs. adverb distinction within context, not mere recall. Provides diagnostic insight based on chosen error type.",
              "reasoning": "Promotes genuine application of grammar rules and yields diagnostic information.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 65.27937626838684,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.95
    },
    {
      "request_id": "c5a5ae8e-48d3-49ec-82e8-9587cef42710",
      "evaluations": {
        "diverse_020": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Intent: Standalone MCQ for Grade 3 ELA L.3.1.G (comparative/superlative adjectives/adverbs). No worked-example cues; treat as practice/assessment.\n\nStep 2 – Issues:\n- ISSUE1 (Educational Accuracy): Stem \"Which choice best demonstrates the skill described in L.3.1.G at medium difficulty?\" does not present any language sample to evaluate; item asks about a code rather than forming/using comparatives/superlatives. The task does not measure the intended skill.\n- ISSUE2 (Clarity & Precision): Student-facing reference to the standard code \"L.3.1.G\" is unclear for 3rd graders; the task is ambiguous about what action is required (identify a correct sentence? choose comparative vs. superlative? adjective vs. adverb?). Multiple interpretations would change how a student answers.\n- ISSUE3 (Distractor Quality): Options are placeholders (e.g., \"An incorrect distractor.\") lacking linguistic content; not plausible, not parallel, and provide no basis for selection.\n- ISSUE4 (Reveals Misconceptions): Because options contain no substantive language, the item cannot surface common errors (e.g., -er/-est vs. more/most, irregular forms) and has no diagnostic value.\n- ISSUE5 (Curriculum Alignment): The item does not require forming/using comparative/superlative adjectives/adverbs or choosing between them; thus misaligned to CCSS L.3.1.G.\n- ISSUE6 (Difficulty Alignment): No Difficulty Definitions provided; applying own bar: medium for L.3.1.G should require selecting or producing correct comparative/superlative (possibly including irregular forms) in short contexts. This item demands no such reasoning; it’s effectively non-task, so difficulty label mismatches.\n- ISSUE7 (Mastery Learning Alignment): No computation/reasoning or application; choosing \"A\" is arbitrary.\n\nChecklists:\n- A Field Consistency: Answer key (A) matches explanation; no internal contradictions. PASS.\n- B1 Giveaway: No explicit answer shown pre-attempt; however, item is non-functional. PASS (no giveaway).\n- B2 Stimulus: No stimulus. PASS.\n- C Diction/Typo: No typos/merged words; clarity issue stems from jargon (standard code). \n\nStep 3 – Metric scores set accordingly (educational_accuracy=0.0; curriculum_alignment=0.0; clarity_precision=0.0; distractor_quality=0.0; reveals_misconceptions=0.0; difficulty_alignment=0.0; mastery_learning_alignment=0.0; others pass).\n\nStep 4 – Overall per rules: C=1 (educational_accuracy fail), N=6 (multiple non-critical fails). Required range = 0.55–0.75. Choose lower half due to critical failure and many additional issues.\n\nStep 5 – Consistency: Each failed metric tied to a concrete issue above; passing metrics have no identified issues.",
              "reasoning": "This item is meta and does not actually assess L.3.1.G. The stem references a standard code and the options are placeholders, so students cannot apply or demonstrate using comparative/superlative adjectives or adverbs. Wording is unclear for 3rd graders, and distractors are not plausible. As a result, it fails educational purpose, alignment, clarity, difficulty fit, diagnostic value, and mastery-learning intent.",
              "suggested_improvements": "Redesign the item to directly assess L.3.1.G with student-friendly wording and substantive options. Example: \"Choose the sentence that correctly uses the superlative form.\" Options such as: (A) \"Of all the puppies, Max is the most playful.\" (correct); (B) \"Max is playfuller than his brother.\"; (C) \"Max is the more playful of all.\"; (D) \"Max is the playfulest puppy.\" Avoid referencing the standard code in the stem. Include plausible distractors reflecting common errors (using -er/-est incorrectly, misusing more/most, irregular forms like good/better/best, or adverbs like quickly/more quickly/most quickly). Provide an explanation that cites the rule and the comparison context (two vs. more than two)."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No factual claims beyond internal labels. Answer key indicates A; explanation also says A. No contradictions, math/science facts, or stimuli to verify. Checklist A passed.",
              "reasoning": "The answer key and explanation are internally consistent, and there are no factual claims to contradict.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The item does not require forming/using comparative or superlative adjectives/adverbs or choosing between them; it merely references a standard code. Thus, it fails to assess the intended skill.",
              "reasoning": "The question does not ask students to form or choose comparative/superlative adjectives/adverbs; it references a code instead of presenting language to analyze or produce.",
              "suggested_improvements": "Pose a concrete language task aligned to L.3.1.G (e.g., select the correct comparative/superlative form in a sentence, or choose between \"more\"/\"most\" and -er/-est based on context)."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, school-appropriate language; no cultural references or sensitive content.",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE5: L.3.1.G targets forming/using comparative/superlative adjectives/adverbs and choosing between them. The item does not require this; it is misaligned.",
              "reasoning": "The item does not engage the L.3.1.G skill; it lacks any comparative/superlative usage or choice tasks.",
              "suggested_improvements": "Include sentences requiring students to pick or form comparative/superlative adjectives/adverbs, including irregular forms (good/better/best; well/better/best) and adverbs (quickly/more quickly/most quickly)."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: The stem uses the code \"L.3.1.G\" and vague phrasing (\"best demonstrates the skill\") without defining the skill for students. Plausible alternate interpretations (identify a correct sentence vs. identify alignment to a code) would change how a student answers.",
              "reasoning": "Referencing the standard code in the stem makes the task unclear for 3rd graders and ambiguous about what to do.",
              "suggested_improvements": "Replace the code with clear, student-friendly wording that specifies the task, e.g., \"Choose the sentence that correctly uses the comparative form of the adjective.\""
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and no explicit item-writing spec is provided. No enforceable spec to violate; pass by rule.",
              "reasoning": "No clear, prescriptive specification to enforce; therefore, no spec violation.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: Options are generic placeholders and cannot surface typical L.3.1.G errors (e.g., mixing -er/-est with more/most, irregular forms).",
              "reasoning": "The distractors do not reflect realistic mistakes, so the item offers no diagnostic insight.",
              "suggested_improvements": "Create distractors that embody common misconceptions: using -er with a two-syllable adjective that needs more (\"beautifuler\"), misusing most with -est (\"most fastest\"), or irregular forms (\"goodest\")."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "Scenario 2 from guidance: No Difficulty Definitions provided. Applied own bar for \"medium\" at Grade 3 L.3.1.G: students select correct comparative/superlative in short contexts, possibly including irregulars or adverbs. Current item requires no such reasoning; it’s non-functional relative to the labeled difficulty, so mismatch.",
              "reasoning": "Labeled \"medium,\" but the task provides no substantive challenge or application; it does not meet a reasonable bar for medium difficulty at this grade/standard.",
              "suggested_improvements": "Target medium difficulty by requiring choice between comparative and superlative in context (two vs. more-than-two), include an irregular form or an adverb case, and avoid trivial cues."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context is referenced or needed.",
              "reasoning": "Self-contained; no passage issues.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: Choices are meta/placeholders and not plausible or content-rich; they lack parallel grammatical structure and do not meaningfully compete with the correct answer.",
              "reasoning": "Distractors are not plausible or content-based, making the correct answer arbitrary rather than earned.",
              "suggested_improvements": "Write four parallel sentence options where only one correctly uses the comparative/superlative; ensure others reflect realistic errors (wrong form, wrong degree, irregular errors, adjective vs. adverb confusion)."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; nothing misleading or distracting.",
              "reasoning": "No image or passage to evaluate; no harm present.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE7: The item does not require application or reasoning; selection is arbitrary and cannot distinguish levels of understanding.",
              "reasoning": "No meaningful thinking is required; getting it right would not indicate mastery and getting it wrong would not diagnose a misconception.",
              "suggested_improvements": "Require students to apply rules (e.g., choose the correct degree based on number compared; form the correct irregular comparative/superlative; distinguish adjective vs. adverb cases)."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 75.99278593063354,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_020\"\nLINE 11:         'diverse_020', '2.3.0', '{\"request_id\": \"c5a5ae8e-48...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "c1abdbd7-39dd-4448-bede-0ec4a69725f9",
      "evaluations": {
        "diverse_022": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Intent: Standalone MCQ (practice/assessment). Target standard inferred: CCSS.ELA-L.3.1.H (Use coordinating and subordinating conjunctions).\n\nStep 2 – Issues:\n- ISSUE1 (educational_accuracy): Option A text says, “The correct choice that matches the standard.” This is an explicit pre-attempt answer giveaway; student can select A without applying the skill.\n- ISSUE2 (curriculum_alignment): Stem asks about “the skill described in L.3.1.H,” but no options demonstrate use/identification of coordinating/subordinating conjunctions. The item does not assess the stated skill.\n- ISSUE3 (clarity_precision): The phrase “the skill described in L.3.1.H at hard difficulty” uses jargon a 3rd grader won’t understand, making it unclear what content/feature to look for in choices.\n- ISSUE4 (distractor_quality): B–D are generic (“An incorrect distractor.”/“Another incorrect distractor.”) and not plausible content-based alternatives.\n- ISSUE5 (mastery_learning_alignment): Because A is labeled as correct, the task requires no reasoning or application of conjunction knowledge.\n- ISSUE6 (difficulty_alignment): Labeled as “hard” but is trivial due to giveaway; does not meet hard-level cognitive demand for L.3.1.H.\n- ISSUE7 (reveals_misconceptions): Distractors do not reflect common errors with conjunctions (e.g., misuse of because/so, run-ons, comma usage), so the item has little diagnostic value.\n\nChecklist A (Field Consistency): Answer key A matches presented options; explanation consistent with key. No mismatches.\nChecklist B (Answer Giveaway): Fails. The correct answer is trivially visible in a student-facing option.\nChecklist C (Diction/Typo): No typos/merged non-words; clarity issue due to jargon/opaque reference.\n\nStep 3 – Metric scoring based on issues identified.\nStep 4 – Overall score: C=1 (educational_accuracy fail), N=6 (clarity_precision, curriculum_alignment, difficulty_alignment, distractor_quality, reveals_misconceptions, mastery_learning_alignment). Deterministic range 0.55–0.75. Lower half chosen due to a critical failure and multiple non-critical failures.\nStep 5 – Consistency: Each 0.0 metric has a corresponding issue; passing metrics have none.",
              "reasoning": "The item does not assess the Grade 3 standard (using coordinating and subordinating conjunctions). The stem is meta-jargony and unclear for 3rd graders, and option A literally states it is the correct choice, making the answer trivial. Distractors are placeholders and do not surface misconceptions. As a result, educational accuracy, curriculum alignment, distractor quality, difficulty alignment, and mastery learning alignment all fail.",
              "suggested_improvements": "- Replace the stem with a clear, student-friendly task (e.g., “Which sentence correctly uses a subordinating conjunction?”).\n- Provide authentic, content-based answer choices that demonstrate correct vs. incorrect use of coordinating/subordinating conjunctions.\n- Remove any giveaway language from options. Ensure the correct choice is not signaled by wording.\n- Tailor distractors to common misconceptions (e.g., comma misuse with coordinating conjunctions; incorrect subordinators; sentence fragments).\n- Align difficulty by requiring students to analyze multi-clause sentences or choose conjunctions to express specific relationships (cause, time, contrast)."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No factual claims to verify beyond internal consistency. The labeled correct answer (A) matches the answer key and explanation. No contradictory numbers or references. Checklist A found no mismatches.",
              "reasoning": "Content is internally consistent; no factual assertions are incorrect.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: Option A says “The correct choice that matches the standard,” a visible pre-attempt giveaway. For practice/assessment, this trivially exposes the correct answer without requiring application of L.3.1.H. Additionally, the task does not actually assess using conjunctions; it asks about a standard code.",
              "reasoning": "The correct answer is trivially identifiable from option text, and the item does not actually require using or identifying conjunctions.",
              "suggested_improvements": "Remove giveaway language and design the item to require recognizing or using coordinating/subordinating conjunctions."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, school-appropriate language. No cultural sensitivities or regional references required to solve.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: The stated target is L.3.1.H, but the item does not present sentences or tasks involving coordinating/subordinating conjunctions. It assesses recognition of a meta description rather than the skill.",
              "reasoning": "Does not measure the Grade 3 standard on conjunctions; no skill-aligned content is present.",
              "suggested_improvements": "Present sentences requiring students to select, identify, or correct coordinating/subordinating conjunctions aligned to L.3.1.H."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: The phrase “the skill described in L.3.1.H at hard difficulty” is opaque to 3rd graders. Alternate interpretations affecting answers: a) Student guesses randomly; b) Student picks A because it uniquely signals correctness; c) Student tries to recall what the code means. The required action (what content to evaluate) is unclear since options are not examples of the skill.",
              "reasoning": "The stem uses jargon and meta references that make the task unclear to the intended audience.",
              "suggested_improvements": "Replace the standard code with student-friendly wording and provide clear, content-based examples to evaluate."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context has no explicit, enforceable item-writing spec for this standard (confidence SOFT). Per rules, pass by default when no clear spec applies.",
              "reasoning": "No clear item specification to enforce.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE7: Distractors are placeholders and do not reflect realistic errors with conjunctions (e.g., misuse of because/so, run-ons, fragments). Hence, the item has poor diagnostic value.",
              "reasoning": "Incorrect options are not plausible and do not target common errors.",
              "suggested_improvements": "Craft distractors from authentic student errors with coordinating/subordinating conjunctions."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "No Difficulty Definitions provided → Scenario 2. Applied bar for “hard” at Grade 3 L.3.1.H: analyzing multi-clause sentences to choose or evaluate appropriate coordinating vs. subordinating conjunctions, possibly with subtle meaning contrasts (cause, time, contrast) and multiple steps of reasoning. Actual item is trivial due to the giveaway and lacks any content to analyze, representing a ≥2-grade under-demand relative to the intended level.",
              "reasoning": "Labeled hard but requires no analysis of conjunctions; cognitive demand is far below a hard-level Grade 3 task.",
              "suggested_improvements": "Increase complexity by requiring evaluation of multi-clause sentences and nuanced conjunction choice; remove giveaway cues."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context. Item is self-contained (despite other flaws).",
              "reasoning": "No passage involved; N/A.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: Choices B–D are generic placeholders and not plausible alternatives. Option A’s self-referential correctness also telegraphs the answer, further degrading option quality.",
              "reasoning": "Distractors are implausible and do not create a meaningful choice set.",
              "suggested_improvements": "Write content-based, parallel sentences that test conjunction use; ensure all options are plausible to a partially knowledgeable student."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus included; nothing misleading or distracting from a stimulus standpoint.",
              "reasoning": "No image/passage; not applicable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE5: The item can be answered without demonstrating understanding; option A is labeled as correct. No computation, analysis, or application of conjunction knowledge is required.",
              "reasoning": "Does not require reasoning or application; provides no evidence of mastery.",
              "suggested_improvements": "Require students to analyze or construct sentences using coordinating/subordinating conjunctions so performance reflects understanding."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 85.85451555252075,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_022\"\nLINE 11:         'diverse_022', '2.3.0', '{\"request_id\": \"c1abdbd7-39...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "82a5d276-5b25-4975-85cc-94651256aa95",
      "evaluations": {
        "diverse_023": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.72,
              "internal_reasoning": "Step 1 – Determine intent: Standalone MCQ for Grade 3 ELA (practice/assessment). No stimuli.\n\nStep 2 – Issues:\n- ISSUE1 (factual_accuracy): Multiple correct answers. Prompt: “Which sentence correctly uses both a coordinating conjunction and a subordinating conjunction?” Labeled correct: B. However, option C (“Because I brought my notebook, I could take good notes and I was ready.”) also correctly uses a subordinating conjunction (“Because”) and a coordinating conjunction (“and”). Therefore, the key is not unique. The explanation asserts only B is correct.\n- ISSUE2 (distractor_quality): Option C, intended as a distractor, is actually correct, undermining the integrity of the distractor set.\n- ISSUE3 (reveals_misconceptions): Because a distractor is also correct, the item cannot reliably diagnose misunderstandings about conjunction types; student selection of C would be marked wrong despite demonstrating the target skill.\n\nChecklist A (Field Consistency): The answer key specifies B; explanation matches B. However, existence of another correct option (C) creates a content/key mismatch ⇒ factual accuracy issue recorded as ISSUE1.\nChecklist B1 (Answer giveaway): None present pre-attempt.\nChecklist B2 (Stimulus quality): No stimulus.\nChecklist C (Diction/Typo): Wording is clear. Minor comma omissions in A/C/D are style-level and do not impede understanding for Grade 3; not flagged under clarity.\n\nStep 3 – Metric scores set accordingly.\n\nStep 4 – Overall per rules: C=1 (factual_accuracy fail), N=2 (distractor_quality, reveals_misconceptions). Range 0.70–0.84. Choose lower half due to critical metric failure.\n\nStep 5 – Self-consistency: Each 0.0 metric tied to a specific issue; others pass.",
              "reasoning": "The item targets Grade 3 use of coordinating and subordinating conjunctions and is clearly worded. However, there are two correct options: B and C both use a coordinating conjunction (“and”) and a subordinating conjunction (“because”). Since only B is keyed as correct, the item contains a content/key mismatch. This also means a supposed distractor (C) is actually correct, reducing diagnostic value. Aside from that, alignment, difficulty, and clarity are appropriate.",
              "suggested_improvements": "- Make only one option correct. For example:\n  • Keep B as the correct answer.\n  • Revise C to remove the coordinating conjunction: “Because I brought my notebook, I could take good notes.” (then it has only a subordinating conjunction)\n  • Or change C’s subordinating conjunction to a preposition/phrase so it no longer includes both types: “Since bringing my notebook, I could take good notes.”\n  • Revise D to use only coordinating conjunction(s) or only subordinating conjunction(s) (e.g., “I brought my notebook, so I could take good notes.” without the final “, and I was ready.”)\n- Optionally add commas for compound sentences to model conventions: e.g., “I brought my notebook, but I still took good notes.”\n- Update the explanation to explicitly state why each incorrect option fails (e.g., A and D do not include a subordinating conjunction)."
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: Option C also fulfills the prompt. C includes “Because” (subordinating) and “and” (coordinating). The question asks for a sentence that “correctly uses both,” implying a unique correct answer. Keying only B creates a content/key mismatch.",
              "reasoning": "There are two correct answers (B and C), but only B is keyed. This makes the answer key factually inaccurate.",
              "suggested_improvements": "Revise options so only one sentence contains both a coordinating and a subordinating conjunction, then update the key accordingly."
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Despite the keying error, the item’s intent—identifying a sentence that uses both coordinating and subordinating conjunctions—aligns with the standard and is appropriate for Grade 3. No pre-attempt giveaways.",
              "reasoning": "The task targets the intended skill and grade level with an appropriate prompt and choices.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, school-based context; no cultural sensitivities or localization pitfalls.",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Matches CCSS L.3.1.H: use coordinating and subordinating conjunctions. Item directly assesses recognition of both types in a sentence.",
              "reasoning": "Directly aligned to the standard on conjunctions for Grade 3.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Prompt is unambiguous. Options are straightforward. Comma omissions do not create ambiguity for the task; students can still discern conjunction types.",
              "reasoning": "Wording clearly states the task; no ambiguity about what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item-spec requirements provided. Per rules, pass by default.",
              "reasoning": "No applicable hard specifications to violate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: Since C is actually correct, the item cannot reliably diagnose misconceptions—students demonstrating understanding might select C and be marked wrong.",
              "reasoning": "Because a distractor is actually correct, the item fails to diagnose misunderstandings about conjunction types.",
              "suggested_improvements": "Correct the option set so that only one sentence includes both conjunction types; ensure other options reflect common errors (e.g., only coordinating, only subordinating, misuse of subordinators)."
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided. Applied own bar: Medium for Grade 3 = recognizing both types of conjunctions within a sentence and distinguishing among options. This requires application beyond simple recall, appropriate for Grade 3.",
              "reasoning": "Cognitive demand (identify both conjunction types in context) is appropriate for a medium Grade 3 item.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage/stimulus required or referenced.",
              "reasoning": "Self-contained item; no passage issues.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: One distractor (C) is actually correct, so the set does not function as intended; this undermines plausibility balance and item functioning.",
              "reasoning": "A supposed distractor is correct, compromising the quality and function of the choices.",
              "suggested_improvements": "Revise C so it does not contain both a coordinating and a subordinating conjunction, or rewrite it to contain an error in conjunction use. Ensure all distractors are plausible but clearly incorrect."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; nothing misleading or distracting.",
              "reasoning": "No harmful stimulus present.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires analyzing sentence structure and conjunction function—non-trivial reasoning for Grade 3.",
              "reasoning": "Students must apply understanding of conjunction types in context, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 91.13754892349243,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.72
    },
    {
      "request_id": "598c946f-c7db-4be7-b34c-ea134936b110",
      "evaluations": {
        "diverse_024": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.95,
              "internal_reasoning": "Step 1: Identified as a standalone MCQ practice/assessment item for Grade 3 ELA (CCSS L.3.1.I). No images/stimuli.\nStep 2 – Issues: Ran all checklists.\n- Checklist A (Field Consistency): Correct answer labeled D; rationale matches option D and definition of complex sentence. No mismatches.\n- Checklist B (Answer Giveaway): No pre-attempt giveaways. Answer and explanation are metadata only.\n- Checklist C (Diction/Typo): Wording is clear; punctuation appropriate; no merged words or confusing symbols.\nNo issues identified.\nStep 3: All metrics pass (1.0) as no issues were found.\nStep 4: Overall chosen in ACCEPTABLE band (0.85–0.98) since all metrics pass with strong alignment and quality; item is solid but not exceptional/novel to merit 0.99+.\nStep 5: Consistency check passed: no failed metrics, overall within correct range.",
              "reasoning": "Clear, accurate MCQ asking students to identify a complex sentence. Options are well-crafted: A is simple, B and C are compound, D is complex with a subordinating conjunction. Aligned to Grade 3 conventions standard on sentence types. No answer giveaways, language is clear, distractors are plausible and diagnostic. Appropriate difficulty for an easy item at this grade.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Definition applied correctly: complex sentence = one independent + at least one dependent clause introduced by a subordinating conjunction (e.g., “while”). Option D fits this: Dependent clause “While the turtle moved slowly,” + independent clause “the crab scurried nearby.” Options A (simple), B and C (compound) are accurately non-complex. Answer key D matches reasoning. No contradictions.",
              "reasoning": "All grammatical classifications are correct and the labeled answer D is truly complex. The explanation accurately describes why.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Intended skill: distinguish sentence types, especially complex sentences via subordinating conjunctions. Item directly targets this. No pre-attempt answer reveal. For Grade 3, recognizing ‘while’ as a subordinating conjunction is appropriate and supports the standard. The explanation text (metadata) reinforces the concept accurately.",
              "reasoning": "Effectively assesses identification of a complex sentence without giveaways and fits the intended learning goal.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral animal context; no cultural sensitivities or region-specific knowledge needed; language appropriate for US English and Grade 3.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Standard CCSS.ELA-LITERACY.L.3.1.I (produce simple, compound, complex sentences). While the standard emphasizes producing, identification/recognition items are commonly used formatively and align to understanding of the same concepts at Grade 3.",
              "reasoning": "Aligns with Grade 3 conventions of standard English on sentence types.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous: “Which sentence is a complex sentence?” Each option is clearly punctuated and easy to parse for Grade 3. No ambiguous phrasing that would change student action.",
              "reasoning": "Clear, concise prompt and plainly written options.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and no explicit hard item specification (format/word count/etc.) is provided. Per rules, pass specification compliance when no clear enforceable spec exists.",
              "reasoning": "No applicable hard item specification to violate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to likely misconceptions: (A) simple vs complex confusion; (B/C) compound (coordinating conjunctions) vs complex (subordinating) confusion. These are plausible and diagnostic.",
              "reasoning": "Choices reflect common errors distinguishing compound vs complex sentences.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2 applies: No Difficulty Definitions provided. Applied an ‘easy’ bar for Grade 3 sentence-type identification: recognizing a common subordinating conjunction and distinguishing among simple/compound/complex in short sentences. The item meets this: short sentences, familiar conjunctions, single-step recognition. Not overly trivial for Grade 3 and not ≥2 grades off.",
              "reasoning": "Appropriate as an easy Grade 3 item requiring recognition of a subordinating conjunction and clause structure.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context; the question is self-contained.",
              "reasoning": "No passage needed or referenced.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All choices are grammatical, parallel (complete sentences), plausible, and comparable in length. Correct answer is not telegraphed by length or specificity. Distractors represent realistic alternatives (simple, compound).",
              "reasoning": "Plausible, well-balanced distractors that differentiate understanding.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; therefore no risk of misleading or distracting imagery.",
              "reasoning": "No stimulus issues.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires analyzing sentence structure (identifying dependent vs independent clause via subordinating conjunction). Not pure fact recall like a single trivia item; shows understanding of clause relationships for Grade 3.",
              "reasoning": "Students must apply understanding of clauses/conjunctions to choose correctly.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 57.541170597076416,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.95
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "885b596d-ea27-452b-ac99-6c126fa4e241",
      "evaluations": {
        "diverse_029": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Intent: MCQ for Grade 3 ELA targeting CCSS L.3.2.A (capitalize appropriate words in titles). Clearly a practice/assessment-style item (no instructional walkthrough). \n\nStep 2 – Issues:\n- ISSUE1 (educational_accuracy): Explicit giveaway in options. Snippet: \"The correct choice that matches the standard.\" This makes the correct answer trivially obtainable without applying the skill.\n- ISSUE2 (curriculum_alignment): The stem asks, \"Which choice best demonstrates the skill described in L.3.2.A at medium difficulty?\" but no titles or capitalization tasks are presented. The content does not assess capitalization in titles at all.\n- ISSUE3 (clarity_precision): Stem references a standard code (\"L.3.2.A\") and difficulty label, which 3rd graders won’t understand; unclear what actionable skill is being assessed.\n- ISSUE4 (distractor_quality): Distractors are self-labeled and implausible (e.g., \"An incorrect distractor.\"). Not parallel, telegraphs the answer, and provides no real alternatives.\n- ISSUE5 (reveals_misconceptions): Choices do not target common errors about title capitalization (e.g., capitalizing short prepositions, not capitalizing important words). No diagnostic value.\n- ISSUE6 (difficulty_alignment): Labeled as \"medium\" but requires no application of rules; the answer is self-identified. Clear mismatch.\n- ISSUE7 (mastery_learning_alignment): No reasoning or application required; success depends on noticing the self-referential label, not understanding capitalization rules.\n\nChecklist A (Field Consistency): Answer key (A) matches explanation; no mismatches.\nChecklist B1 (Answer Giveaway): As a practice/assessment item, the correct answer is trivially given away by option text before attempt → educational_accuracy failure.\nChecklist B2 (Stimulus Quality): No stimulus.\nChecklist C (Typos/Diction): No typos, but stem is meta/unclear for students.\n\nStep 3 – Metric scores set accordingly.\nStep 4 – Overall per rules: C=1 (educational_accuracy), N=6 (curriculum_alignment, clarity_precision, distractor_quality, reveals_misconceptions, difficulty_alignment, mastery_learning_alignment) → overall must be 0.55–0.75. Lower half chosen due to critical failure and multiple non-critical failures.\nStep 5 – Consistency: Each 0.0 score tied to a concrete issue above.",
              "reasoning": "This item is meta and non-functional for Grade 3 students. The correct option literally identifies itself, so students don’t apply the target skill. The stem references a standard code and difficulty level that students wouldn’t understand, and none of the options involve capitalization of titles. Distractors are placeholders that don’t model real errors, offering no diagnostic value. Overall, the question does not assess L.3.2.A and contains an explicit answer giveaway.",
              "suggested_improvements": "- Replace the stem with student-friendly language tied to the skill, e.g., \"Which title is capitalized correctly?\"\n- Provide four realistic title options (e.g., \"A Day at the Zoo,\" \"A day at The zoo,\" \"A Day At the zoo,\" \"A day At the Zoo\") with one correct and three plausible near-miss errors (capitalize first/last words, major words; do not capitalize short articles/prepositions unless first/last).\n- Remove references to standard codes/difficulty from the stem.\n- Ensure the correct option does not self-identify; make all choices grammatically parallel and plausible.\n- Craft distractors to reflect common misconceptions (capitalizing short prepositions, failing to capitalize the last word, etc.).\n- Provide an explanation referencing the rule (e.g., \"Capitalize the first and last words and all important words; do not capitalize short articles and prepositions unless first or last.\")"
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No factual claims beyond metadata. The labeled answer (A) matches the explanation. No contradictions or image content. Field Consistency Check passed.",
              "reasoning": "Answer key and explanation are internally consistent; no factual content to contradict.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The correct answer is trivially given away: option A says \"The correct choice that matches the standard.\" In a practice/assessment item, this is a pre-attempt giveaway. Additionally, the content does not actually assess capitalization in titles.",
              "reasoning": "The correct option self-identifies, so students need not apply any capitalization rules. The item also fails to present any titles to evaluate, so it doesn’t assess the intended skill.",
              "suggested_improvements": "Remove meta/self-referential option text; present actual titles and require choosing the correctly capitalized one."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "No cultural content; neutral language. Suitable for en-US context.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: Target standard L.3.2.A is about capitalizing appropriate words in titles. The item contains no titles and does not evaluate capitalization. Clear misalignment.",
              "reasoning": "Does not measure capitalization of titles; thus, it does not align with CCSS L.3.2.A.",
              "suggested_improvements": "Create options that show titles with varying capitalization so the item directly assesses the standard."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: Stem \"Which choice best demonstrates the skill described in L.3.2.A at medium difficulty?\" is unclear for 3rd graders; they won’t know what L.3.2.A refers to, nor what action specifically demonstrates the skill. This ambiguity affects how a student would approach the question.",
              "reasoning": "Referencing a standard code and difficulty label is not student-friendly and leaves the task’s criteria unclear.",
              "suggested_improvements": "Use student-facing language tied to the skill, e.g., \"Which title is capitalized correctly?\" Avoid standard codes in the stem."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item-format specification with enforceable rules is provided; curriculum confidence is SOFT. Per rules, pass by default.",
              "reasoning": "No clear skill specification to enforce beyond general standards guidance.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE5: Distractors do not represent realistic misconceptions about title capitalization; they are placeholders labeled \"An incorrect distractor.\" Provides no diagnostic insight.",
              "reasoning": "Incorrect options are not plausible errors a student might make, so the item cannot reveal misconceptions.",
              "suggested_improvements": "Design distractors to reflect common errors (e.g., capitalizing short prepositions, failing to capitalize the last word, lowercasing important words)."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "No Difficulty Definitions provided (all unspecified). Applied own bar: For L.3.2.A at Grade 3, \"medium\" should require evaluating multiple realistic title options with near-miss errors (not just the most obvious one). This item is trivial because the correct option self-identifies; no application required. Clear mismatch.",
              "reasoning": "Labeled \"medium\" but requires no skill application; the answer is given away, so the difficulty is effectively below easy.",
              "suggested_improvements": "Use realistic, closely competing title options that require students to apply capitalization rules to distinguish the correct answer."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context. Self-contained.",
              "reasoning": "No passage is involved; nothing to reference.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: Choices are non-parallel and self-referential (e.g., \"The correct choice...\", \"An incorrect distractor.\"). Implausible distractors telegraph the answer and provide no meaningful comparison.",
              "reasoning": "Options are not plausible or well-constructed, and the correct answer is telegraphed.",
              "suggested_improvements": "Replace with four parallel title options differing only in capitalization patterns; ensure only one is correct and others are plausible near-miss errors."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus is present; nothing harmful.",
              "reasoning": "No image or additional stimulus; not applicable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE7: The task does not require reasoning or application of rules; students can select the self-identified correct option. No diagnostic value.",
              "reasoning": "Does not require understanding or multi-step thinking; success is possible without engaging with the target concept.",
              "suggested_improvements": "Require students to evaluate capitalization in multiple realistic titles so that correct responses indicate understanding of the rule."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 88.35625433921814,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_029\"\nLINE 11:         'diverse_029', '2.3.0', '{\"request_id\": \"885b596d-ea...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "ec1f0b0b-0735-4199-a07c-1ec85c9c20f3",
      "evaluations": {
        "diverse_030": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.96,
              "internal_reasoning": "Step 1 – Intent: Practice/assessment MCQ for Grade 3 ELA (CCSS L.3.2.B: Use commas in addresses).\nStep 2 – Issues: No issues found.\n- Checklist A (Field Consistency): Answer key = A; explanation matches content and options.\n- Checklist B (Giveaway): No pre-attempt giveaways; straightforward stem and options only.\n- Checklist C (Diction/Typo): Clear, grammatical; no merged words or confusing symbols.\nStep 3 – Metrics: All pass (1.0) given no identified issues.\nStep 4 – Overall: C=0, N=0 ⇒ range 0.85–1.0; choose 0.96 (high-quality, clean alignment and distractors, not necessarily exceptional).\nStep 5 – Consistency: All failures = none; scores consistent.",
              "reasoning": "Well-aligned Grade 3 item assessing commas in addresses. Correct answer and rationale are accurate. Clear stem, plausible distractors reflecting common comma errors, appropriate difficulty, and suitable for en-US locale.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Option A (“123 Oak Road, Dallas, TX 75201.”) correctly uses commas: after street and after city, no comma before ZIP. B lacks comma after street; C lacks comma after city and incorrectly adds one before ZIP; D has no commas. Explanation matches this.",
              "reasoning": "All information is correct and consistent; the labeled correct answer and explanation are accurate.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Targets L.3.2.B directly by asking for correct comma usage in an address within a sentence. No answer is revealed pre-attempt. The task assesses the intended skill at the right grain size.",
              "reasoning": "Effectively assesses commas in addresses without giveaways and at an appropriate level for Grade 3.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Uses a U.S. address format (“Dallas, TX 75201”) consistent with en-US locale; culturally neutral and age-appropriate.",
              "reasoning": "U.S. address context and abbreviation are appropriate for en-US with no sensitive or culture-bound barriers.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Explicitly aligned to CCSS.ELA-LITERACY.L.3.2.B (Use commas in addresses); the item precisely measures that skill.",
              "reasoning": "Direct alignment with the stated standard: commas in addresses.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous; options are complete sentences. No alternate interpretations of the task.",
              "reasoning": "Clear wording; students know exactly what to do.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item specification with enforceable format rules provided. Under rules, pass by default.",
              "reasoning": "No conflicting specification; item format is appropriate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors reflect common comma mistakes: missing comma after street (B), missing comma after city and extra before ZIP (C), no commas (D).",
              "reasoning": "Incorrect choices map to typical errors students might make with address commas.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided; using own bar. For Grade 3 commas-in-addresses, an Easy item asks students to recognize correct punctuation in a single straightforward sentence with familiar structure. This item meets that bar.",
              "reasoning": "Cognitive demand matches an easy, single-step recognition task for Grade 3.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context required; item is self-contained.",
              "reasoning": "Not applicable; the question is standalone and clear.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are grammatically parallel, plausible, and differentiated by specific comma placements; none are obviously out of place.",
              "reasoning": "Strong, plausible distractors with clear, teachable differences.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus included; nothing misleading or distracting.",
              "reasoning": "Not applicable; absence of stimulus poses no issue.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying a punctuation rule to evaluate sentence correctness. Distinguishes students who understand comma placement in addresses from those who don’t.",
              "reasoning": "Supports mastery by requiring rule application rather than rote recall.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 55.762354612350464,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.96
    },
    {
      "request_id": "4f6eb9db-78a0-4e9f-b0f1-c2c7dac72692",
      "evaluations": {
        "diverse_031": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.74,
              "internal_reasoning": "Step 1: Item parsed as a Grade 3 ELA MCQ targeting CCSS.ELA-LITERACY.L.3.2.B (commas in addresses). Student-facing stem and options are clear. Correct key labeled as C.\n\nStep 2 – Issues:\n- ISSUE1 (Factual Accuracy – Field Consistency): The answer_explanation says: \"Option C places a comma after '18 Harbor Road' and after 'Wilmington'...\" but the options use the city \"Boston\" not \"Wilmington\". This mismatch constitutes a field consistency error in supporting text.\n\nChecklist A (Field Consistency): Failed due to the “Wilmington” vs. “Boston” mismatch in explanation.\nChecklist B1 (Answer Giveaway): No giveaway in student-facing content. Answer key and rationale are metadata.\nChecklist B2 (Stimulus Quality): No stimulus provided; N/A.\nChecklist C (Diction/Typo): No student-facing typos or merged words detected; clear stem and options.\n\nStep 3 – Metric scoring based on identified issues:\n- factual_accuracy = 0.0 due to ISSUE1.\n- All other metrics pass; no other issues identified.\n\nStep 4 – Overall score per rules: C=1 (factual_accuracy fail), N=0 → overall must be in 0.70–0.84. Choose lower half because a critical metric failed. Selected 0.74.\n\nStep 5 – Consistency: The single cited issue drives the single failed metric; others pass consistently.",
              "reasoning": "The item is well-constructed and clearly assesses commas in a U.S. address within a sentence. The correct answer (C) is accurate: it uses commas after the street and city, and no comma between state and ZIP. However, the explanation references a different city (“Wilmington”) than the one in the options (“Boston”), creating a field consistency error in the supporting text. Student-facing content is otherwise clear and aligned to the standard, with strong, plausible distractors that reflect common mistakes.",
              "suggested_improvements": "Fix the explanation to reference the actual city in the options (e.g., change “Wilmington” to “Boston”) so the rationale matches the item content precisely."
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "Field mismatch in supporting text: The explanation mentions the city “Wilmington,” which does not appear in any option; the item uses “Boston, Massachusetts 02110.” This violates the Field Consistency Check and thus factual_accuracy must be 0.0.",
              "reasoning": "The explanation references “Wilmington” instead of the city used in the options (“Boston”), creating an inconsistency in supporting fields.",
              "suggested_improvements": "Update the explanation to: “Option C places a comma after ‘18 Harbor Road’ and after ‘Boston’; it does not add a comma between the state and the ZIP code.”"
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The stem asks students to identify correct comma usage in an address, directly targeting CCSS L.3.2.B. No pre-attempt answer giveaways. The correct option reflects the rule (comma after street and city; no comma between state and ZIP).",
              "reasoning": "Assesses the intended skill appropriately for Grade 3; no visible answer giveaway; the correct option exemplifies the rule accurately.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "U.S. address conventions are appropriate for en-US locale; content is culturally neutral and age-appropriate.",
              "reasoning": "Uses standard U.S. address formatting; no cultural sensitivities or localization issues.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Direct alignment to CCSS.ELA-LITERACY.L.3.2.B (Use commas in addresses). The task precisely matches the standard’s focus.",
              "reasoning": "Directly targets the Grade 3 standard on commas in addresses.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous. Options are full sentences and clearly comparable. No ambiguous phrasing; students know exactly what to do.",
              "reasoning": "Clear, concise wording with no ambiguity about the task.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item-writing specification provided; per rules, pass by default. Also conforms to common MCQ norms.",
              "reasoning": "No enforceable specification present; the item follows standard MCQ conventions.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common errors: missing comma after street (A), missing comma between city and state (B), extra comma before ZIP (D). Diagnostic value is high.",
              "reasoning": "Incorrect choices reflect typical punctuation mistakes, offering good diagnostic insight.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided. Applied my own bar: For Grade 3 commas-in-addresses, “Hard” would likely involve multiple addresses or editing tasks with varied structures. This single-selection identification item is closer to Medium. However, per Borderline Rule for Difficulty Alignment, fail only with ≥2-grade mismatch; here it aligns with Grade 3 expectations, so pass.",
              "reasoning": "Cognitive demand is appropriate for Grade 3; while not ‘hard,’ it is suitable for the grade and standard.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context; item is self-contained.",
              "reasoning": "N/A; the item does not rely on a passage.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are parallel, plausible, and similar in length; no option is conspicuously different. Only C adheres fully to rules, and others represent realistic mistakes.",
              "reasoning": "Well-balanced, plausible distractors without telegraphing.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; nothing misleading or distracting.",
              "reasoning": "N/A; absence of stimulus poses no issue.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires application of a punctuation rule, not mere recall of a fact; differentiates students who know where commas belong in addresses.",
              "reasoning": "Supports mastery by requiring rule application to evaluate full-sentence options.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 74.88444423675537,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.74
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "6d81aacb-84dc-4bfa-b8d4-ab739d7c3472",
      "evaluations": {
        "diverse_034": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.94,
              "internal_reasoning": "Step 1: Determine intent → Standalone MCQ for practice/assessment (no instructional walkthrough).\nStudent-facing content: stem and four options. Metadata: correct answer A and explanation (used only for verification).\n\nStep 2 – Issues:\n- Checklist A (Field Consistency): Answer key A matches the content; explanation is consistent with option A and the punctuation rules. No contradictions.\n- Checklist B1 (Answer Giveaway): No answer or rationale exposed pre-attempt. Not a worked example. No giveaway.\n- Checklist B2 (Stimulus Quality): No stimulus present.\n- Checklist C (Diction/Typo): Wording is clear, no typos or merged words.\nResult: No issues identified.\n\nStep 3 – Metric scoring: With no issues, all binary metrics pass.\n\nStep 4 – Overall: C=0, N=0 → range 0.85–1.0. This is a solid, well-aligned item with plausible distractors; typical quality rather than exceptional, so choose 0.94.\n\nNotes on correctness: Option A correctly punctuates interrupted dialogue per en-US conventions: comma inside closing quotation marks after the first segment (\"Ready,\"), comma after dialogue tag (\"whispered Leo,\"), lowercase continuation (\"when you are.\"). Options B–D each reflect common errors (comma outside quotes; missing comma after tag; improper capitalization).",
              "reasoning": "Strong, well-aligned Grade 3 item targeting commas and quotation marks in dialogue. The correct option follows en-US conventions for interrupted dialogue, and distractors reflect common mistakes, offering good diagnostic value. No clarity, alignment, or consistency problems found.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Verified option A is correct under American English punctuation for interrupted dialogue. Explanation text matches the rules and the option. No internal contradictions or mismatches across fields.",
              "reasoning": "The labeled correct answer is actually correct and the explanation accurately states why. No contradictions found.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Assesses CCSS L.3.2.C skill directly (commas and quotation marks in dialogue). No pre-attempt giveaway. The item cleanly targets the intended punctuation concept.",
              "reasoning": "Directly measures the intended punctuation skill without giving away the answer or assessing unrelated abilities.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Locale is en-US; option A follows U.S. style (commas and periods inside closing quotes; lowercase continuation). No culturally sensitive or inappropriate content.",
              "reasoning": "Uses U.S. punctuation conventions appropriately; content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Standard provided: CCSS.ELA-LITERACY.L.3.2.C. The item asks for correct use of commas and quotation marks in dialogue, matching the standard’s focus. Complexity is appropriate for grade level.",
              "reasoning": "Fully aligned to CCSS L.3.2.C by focusing on comma and quotation mark use in dialogue, including interrupted dialogue.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous; options are parallel and differ only in punctuation/capitalization. No phrases with multiple interpretations; action required is clear.",
              "reasoning": "Clear prompt and options; students can easily understand the task.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit hard item-spec requirements provided beyond the general standard (context confidence SOFT). No identifiable spec to enforce; therefore no violations.",
              "reasoning": "No applicable hard-format specifications appear; the item meets common MCQ norms.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors reflect common errors: comma outside quotes (B), missing comma after tag (C), improper capitalization after interrupted dialogue (D). These are plausible and diagnostic.",
              "reasoning": "Incorrect choices map to typical punctuation mistakes, providing good diagnostic value.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided in curriculum context. Applied own bar: \n- Easy: simple, single-segment dialogue punctuation.\n- Medium: dialogue with clear tag placement and commas.\n- Hard: interrupted dialogue requiring comma placement inside quotes, comma after tag, and lowercase continuation.\nThis item uses interrupted dialogue and multiple conventions simultaneously, fitting a higher difficulty within Grade 3 expectations without exceeding the grade band.",
              "reasoning": "For Grade 3, handling interrupted dialogue with multiple conventions is appropriately challenging for a “hard” label while remaining on-standard.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage provided or required; item is self-contained.",
              "reasoning": "No passage involved; not applicable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are grammatically parallel, similar length, and differ only in punctuation/capitalization. All distractors are plausible; none are obviously off-pattern or telegraph the answer.",
              "reasoning": "Well-constructed, parallel, and plausible distractors support quality assessment.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus; not applicable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires application of specific punctuation rules across an interrupted sentence structure—not pure recall of a single fact. Correctness differentiates understanding of multiple conventions.",
              "reasoning": "Demands applied knowledge of punctuation rules, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 64.79182934761047,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.94
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "47b7e7c1-1508-4735-ba10-da0357d22da0",
      "evaluations": {
        "diverse_039": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.96,
              "internal_reasoning": "Step 1: Identify student-facing content: Stem asks, “Which word correctly adds the suffix '-ing' to the base word 'study'?” with options A-D. Metadata: answer key C, explanation provided. No hints/stimuli.\n\nStep 2 – Issues: Ran all checklists.\n- Checklist A (Field Consistency): Answer key C corresponds to “studying”; explanation matches rule. No mismatches.\n- Checklist B1 (Answer Giveaway): Practice/assessment item; no student-visible giveaway. Answer only in metadata.\n- Checklist B2 (Stimulus Quality): No stimulus present.\n- Checklist C (Diction/Typo): Wording clear; punctuation/quotes fine.\nNo issues identified.\n\nStep 3: Metric scoring: With no issues, all binary metrics = 1.0.\n\nStep 4: Overall per rules: C=0, N=0 → 0.85–1.0. Item is clean and well-aligned but not extraordinary → choose 0.96.\n\nStep 5: Self-consistency: All metrics pass; overall within allowed range.",
              "reasoning": "Clear, well-aligned Grade 3 spelling item on adding -ing to a base word ending in consonant + y. Correct answer and explanation are accurate and consistent. Options are plausible distractors that reflect common errors. No clarity, alignment, or format issues.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Rule stated in the explanation is correct: for consonant + y words (study), keep y and add -ing → studying. Answer key C matches options and explanation. No contradictions or errors.",
              "reasoning": "The labeled correct answer and the explanation are accurate and consistent with standard spelling rules.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Targets CCSS L.3.2.E skill of adding suffixes to base words. No answer giveaway in student-facing text. Cognitive demand appropriate for easy practice.",
              "reasoning": "Assesses adding -ing to a base word appropriately without revealing the answer beforehand.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral language, no cultural references, age-appropriate.",
              "reasoning": "Content is culturally neutral and appropriate for US Grade 3.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly aligns to CCSS.ELA-LITERACY.L.3.2.E: conventional spelling for suffixes; specific case of -ing after consonant + y.",
              "reasoning": "Directly measures the standard about conventional spelling when adding suffixes.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem is unambiguous; task is clear; punctuation and quotation marks are correct. No alternative interpretations.",
              "reasoning": "Wording clearly states the task and cannot be reasonably misinterpreted.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and no explicit item-writing spec with hard rules is provided. Per rules, treat as no spec to enforce.",
              "reasoning": "No explicit conflicting specification; item format is standard MCQ.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common errors: dropping y (studing), omitting final g (studyin), overapplying doubling/change (studdying). These can diagnose misconceptions about suffix rules.",
              "reasoning": "Incorrect choices are plausible and reflect typical spelling mistakes.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2 applies: no difficulty definitions provided. Applied an “easy” bar for Grade 3 L.3.2.E: single-step recognition/application of a common suffix rule with a familiar base word. Item meets this bar appropriately.",
              "reasoning": "Cognitive demand matches an easy Grade 3 spelling item: apply a single known rule.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage/context required; item is self-contained.",
              "reasoning": "No passage involved; not applicable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "All options are parallel in form (attempts at the -ing form), plausible, and balanced in length; correct answer is not telegraphed by length or structure.",
              "reasoning": "Choices are well-constructed and plausible, enabling meaningful discrimination.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus; not applicable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying a specific spelling rule rather than recalling an unrelated fact; provides diagnostic value about students’ understanding of suffix rules.",
              "reasoning": "Students must apply a rule to choose the correct form, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 40.27535104751587,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.96
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "2533f03b-b36a-4876-8761-49efde47272e",
      "evaluations": {
        "diverse_041": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1: Determine intent → MCQ practice/assessment (no instructional walkthrough). Student-facing: stem and four options with generic labels. Metadata: correct answer A; brief explanation. No stimuli.\n\nStep 2 – Issues (committed):\n- ISSUE1 (educational_accuracy): Options self-label correctness, making the answer trivially visible pre-attempt. Snippets: A: “The correct choice that matches the standard.”; B/C/D: “An incorrect distractor…”. This undermines assessment purpose.\n- ISSUE2 (curriculum_alignment): The item references CCSS L.3.2.E but does not present any spelling or suffix content; thus it does not assess the actual standard.\n- ISSUE3 (distractor_quality): Distractors are placeholders (“An incorrect distractor.”) and implausible; they do not represent real student errors.\n- ISSUE4 (reveals_misconceptions): Because options are not content-based, the item cannot reveal misconceptions about spelling/suffix rules.\n- ISSUE5 (difficulty_alignment): Labeled difficulty “medium,” but due to self-labeled options, cognitive demand is trivial (below grade-level expectations). Scenario 2 from Difficulty Definitions applies (none provided → define our own bar).\n- ISSUE6 (mastery_learning_alignment): Requires no reasoning or application; the correct answer is effectively announced in the options.\n\nChecklist A (Field Consistency): Answer A matches explanation; no mismatches.\nChecklist B1 (Answer Giveaway): Yes—pre-attempt giveaway via option texts. Hence educational_accuracy fail.\nChecklist B2 (Stimulus): No stimulus; N/A.\nChecklist C (Diction/Typo): No typos that impede understanding; content is generic but grammatically fine.\n\nStep 3 – Metric scores assigned accordingly.\nStep 4 – Overall per rules: C=1 (educational_accuracy), N=5 (curriculum_alignment, distractor_quality, reveals_misconceptions, difficulty_alignment, mastery_learning_alignment). Range 0.55–0.75; choose lower half due to multiple failures and a critical fail → 0.60.\nStep 5 – Consistency check: Each 0.0 metric is tied to a specific issue; passes.",
              "reasoning": "Significant problems: the options literally label which is correct and which are incorrect, so the answer is given away. The item does not actually assess Grade 3 spelling/suffix skills (L.3.2.E). Distractors are not plausible and cannot reveal misconceptions. Difficulty is mislabeled as medium because the task is trivial. These issues together make the item unsuitable as practice or assessment.",
              "suggested_improvements": "- Replace the stem with a concrete, student-friendly prompt that targets L.3.2.E (e.g., “Which is the correct spelling when adding -ing to stop?”).\n- Remove self-referential option labels. Provide content-based choices with one correct answer (e.g., stoping, stopping, stoppping, stopin).\n- Ensure distractors reflect real misconceptions (e.g., not doubling final consonant, incorrect y→i change, forgetting to drop final e).\n- Avoid referencing the standard code in the student-facing stem; describe the skill in plain language.\n- Align difficulty to “medium” by using a slightly tricky rule (e.g., doubling consonant or y→i with different base words) without making it overly complex.\n- Provide an explanation that states the applicable spelling rule and why the correct option follows it, rather than tautologically stating it “matches the standard.”"
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No factual claims beyond generic labels. Answer key indicates A; explanation references A. No contradictions, math/science facts, or stimulus mismatches.",
              "reasoning": "No factual errors or inconsistencies were found between the answer, options, and explanation.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The options advertise correctness/incorrectness, making the correct answer trivially obtainable pre-attempt—an explicit giveaway. Additionally, the item does not engage the specified skill (spelling with suffixes), so it fails to assess its stated educational intent.",
              "reasoning": "The answer is given away in the options (“The correct choice…” vs. “An incorrect distractor.”), and the item does not actually assess spelling/suffix skills for L.3.2.E.",
              "suggested_improvements": "Create a real Grade 3 spelling item (e.g., choose the correct suffix spelling) and ensure options don’t reveal correctness by their wording."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, culture-agnostic content; no sensitive or region-specific references.",
              "reasoning": "Culturally neutral and age-appropriate; no localization concerns.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: Explicitly references L.3.2.E but provides no words or suffix usage to assess conventional spelling; thus misaligned with the cited standard.",
              "reasoning": "Although it references L.3.2.E, the item does not measure conventional spelling or suffix application, so it is not aligned.",
              "suggested_improvements": "Write an item that requires applying spelling rules for suffixes (e.g., doubling consonants, dropping final e, y→i) with plausible answer choices."
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "The stem is understandable as a prompt to choose an option, even though it references a standard code. No ambiguous phrasing causing multiple interpretations.",
              "reasoning": "Despite referencing a standard code, the task (choose the best choice) is clear and unambiguous.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No clear, enforceable item specification was provided. Confidence is SOFT; no prescriptive format rules to enforce.",
              "reasoning": "No applicable hard item-writing specification to violate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: With placeholder, self-labeled distractors, the item cannot surface or diagnose misconceptions about spelling and suffix rules.",
              "reasoning": "Distractors do not reflect real student errors, so the item has little diagnostic value for misconceptions.",
              "suggested_improvements": "Use distractors that mirror common errors (e.g., stoping, smileed, crys) to reveal whether students understand doubling, dropping e, and y→i rules."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "Scenario 2 applies: No Difficulty Definitions provided. For L.3.2.E at Grade 3, “medium” should involve applying common suffix rules (e.g., doubling, dropping e, y→i) across varied base words. This item is trivial because the correct option is explicitly labeled as correct, requiring no application or reasoning. Hence, clear mismatch with “medium.”",
              "reasoning": "Labeled “medium,” but due to the answer being telegraphed, the actual cognitive demand is trivial and not at the intended level.",
              "suggested_improvements": "Design items requiring students to apply suffix rules in non-obvious cases (e.g., hop→hopping vs. hope→hoping; cry→cries), without giveaways."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context is referenced; N/A but passes.",
              "reasoning": "Self-contained; no passage involved.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: Choices are not plausible content-based alternatives; they announce correctness or incorrectness. No grammatical or conceptual parity; they telegraph the answer.",
              "reasoning": "Distractors are implausible and self-identified as incorrect, making the correct answer obvious.",
              "suggested_improvements": "Replace with content-based, grammatically parallel options that represent typical errors with suffix spelling rules."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus to evaluate; no issues.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE6: The task requires no application or reasoning; the answer is effectively given in the choice text, offering no measure of mastery.",
              "reasoning": "No meaningful thinking is required; the item cannot distinguish understanding from guessing or copying labels.",
              "suggested_improvements": "Require students to apply a spelling rule to select the correct form, and ensure options don’t give away correctness by their wording."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 97.17503833770752,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_041\"\nLINE 11:         'diverse_041', '2.3.0', '{\"request_id\": \"2533f03b-b3...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "e7832d9e-dfb0-47a2-b284-c1ee8179b4aa",
      "evaluations": {
        "diverse_042": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Intent: This is a standalone MCQ practice/assessment item for Grade 3 ELA (L.3.2.F spelling patterns). No reveal cues; options are visible.\n\nStep 2 – Issues (committed):\n- ISSUE1 (educational_accuracy): Stem: \"Which choice best demonstrates the skill described in L.3.2.F at easy difficulty?\" This does not actually assess spelling patterns/generalizations; it asks a meta-question about a standard. Fails to measure the intended skill; also the correct option is trivially indicated by its wording (see ISSUE3).\n- ISSUE2 (curriculum_alignment): Same stem as above; content is meta and does not align to CCSS L.3.2.F (spelling patterns/generalizations). No words, patterns, or rules are presented.\n- ISSUE3 (distractor_quality): Option A: \"The correct choice that matches the standard.\" Options B–D: \"An incorrect distractor.\"/\"Another incorrect distractor.\" The correct answer is telegraphed; distractors are implausible placeholders, not content-based.\n- ISSUE4 (clarity_precision): Stem references \"L.3.2.F\" (a standards code); Grade 3 students would not know this code, making the task unclear about what evidence to use. The options are meta labels rather than substantive content, so it’s unclear how to decide.\n- ISSUE5 (reveals_misconceptions): Distractors do not represent plausible spelling-pattern errors; they are generic placeholders, offering no diagnostic value.\n- ISSUE6 (difficulty_alignment): Labeled \"easy\" for Grade 3, but the task requires no grade-level skill application—just picking the only option labeled as “correct.” This is far below Grade 3 cognitive demand.\n- ISSUE7 (mastery_learning_alignment): The task requires no application of spelling rules or reasoning; success depends on recognizing a meta label, not demonstrating understanding.\n\nChecklist A (Field consistency): Correct answer key = A, explanation says A; consistent. No mismatches.\nChecklist B1 (Answer giveaway): Practice item; the answer is trivially obtainable because Option A literally states it’s the correct choice. This is a giveaway → educational_accuracy issue noted in ISSUE1/3.\nChecklist B2 (Stimulus quality): No stimulus present; N/A.\nChecklist C (Diction/Typo): No typos or merged words; issue is conceptual/clarity, not mechanics.\n\nStep 3 – Metric scores set accordingly.\nStep 4 – Overall determined with C=1 (educational_accuracy) and N=7 → allowed range 0.55–0.75; chosen 0.60 (lower half due to critical failure and multiple non-critical failures).\nStep 5 – Self-consistency: Every 0.0 metric tied to a specific issue above.",
              "reasoning": "This item is a meta-question about a standard rather than a real Grade 3 spelling-pattern task. The correct option is telegraphed by its wording, the distractors are placeholders, and the stem references a standards code students wouldn’t know. It does not assess L.3.2.F, offers no diagnostic value, and sits far below appropriate difficulty.",
              "suggested_improvements": "- Replace the stem with a student-friendly prompt that directly assesses spelling patterns (e.g., \"Which word is spelled correctly?\" or \"Which word uses the correct ending for -ing?\").\n- Provide substantive, parallel options using Grade 3-appropriate word families, syllable patterns, or ending rules (e.g., hop/hopping, hope/hoping; drop final e before -ing; double consonants in CVC patterns).\n- Remove meta labels like \"correct choice\"/\"incorrect distractor\"; ensure no option telegraphs correctness.\n- Craft distractors that reflect common misconceptions (e.g., hopeing, runing, planing vs planning).\n- Align difficulty to “easy” by using familiar word families and single-step pattern application.\n- Use student-facing language; do not reference standards codes in the stem."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No factual claims beyond meta labels. Answer key (A) matches the explanation. No contradictory info or image. Field consistency check passed.",
              "reasoning": "Answer key and explanation are consistent; no factual statements to be wrong.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The item does not assess L.3.2.F; it asks which option \"matches the standard\" without presenting any spelling content. Additionally, the correct choice is trivially indicated by its wording (answer giveaway) in a practice item, violating the educational purpose.",
              "reasoning": "It fails to assess the intended spelling-pattern skill and trivially gives away the answer via option wording.",
              "suggested_improvements": "Ask students to apply a specific spelling pattern/generalization with real word options; avoid meta references and telegraphed correctness."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, culture-free content. No sensitive or region-specific elements.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: Explicit standard L.3.2.F (spelling patterns) is cited, but the item provides no words/patterns; it’s a meta selection task unrelated to the actual skill.",
              "reasoning": "Despite naming L.3.2.F, the item does not measure spelling patterns/generalizations.",
              "suggested_improvements": "Present words that require applying L.3.2.F (e.g., syllable patterns, ending rules) and ask students to choose the correctly spelled word or apply the rule."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: The stem references a standards code (\"L.3.2.F\") unfamiliar to Grade 3 students, making it unclear what knowledge to use. Options are meta labels, not substantive content, creating ambiguity about the decision basis.",
              "reasoning": "Students won’t know what L.3.2.F means, and the options provide no concrete basis for choice.",
              "suggested_improvements": "Use student-friendly language describing the task (e.g., \"Choose the correctly spelled word\") and provide real examples rather than meta labels."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit item-writing specification provided to enforce; curriculum context is soft and not a prescriptive spec. By rule, pass.",
              "reasoning": "No clear, enforceable item spec was provided; therefore, no violation.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE5: Distractors are placeholders (\"An incorrect distractor\") and do not reflect plausible Grade 3 spelling errors, providing no diagnostic insight.",
              "reasoning": "Incorrect options do not correspond to common spelling-pattern mistakes.",
              "suggested_improvements": "Design distractors around real misconceptions (e.g., not doubling consonants, not dropping final e, misusing -ed vs -ing)."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "Scenario 2 (no difficulty definitions provided). Applied bar: Easy Grade 3 L.3.2.F should require a simple application of a known spelling pattern/generalization (e.g., choose correct -ing form). Actual item requires no application—students can pick the only option labeled “correct,” which is far below Grade 3 skill (≥2-grade mismatch).",
              "reasoning": "The task doesn’t require Grade 3-level application; it’s trivially solvable by test-wise reading of labels.",
              "suggested_improvements": "Create an easy-level item that requires one clear application of a Grade 3 spelling rule with familiar words."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage/context provided or referenced.",
              "reasoning": "Not applicable; self-contained.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: Choices are not content-based; the correct option is telegraphed by “The correct choice that matches the standard,” while others are labeled “incorrect distractor(s).” Implausible, not homogeneous in function, and obviously different in meaning; poor diagnostic value.",
              "reasoning": "Distractors are placeholders and the correct answer is given away by wording.",
              "suggested_improvements": "Replace with parallel, plausible word choices reflecting specific spelling patterns so the correct answer isn’t obvious by phrasing."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing misleading or distracting.",
              "reasoning": "No harmful or misleading stimulus.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE7: No reasoning or application of spelling patterns is required; success depends on recognizing meta labels, not demonstrating understanding.",
              "reasoning": "Does not require application or reasoning related to the target skill.",
              "suggested_improvements": "Require students to apply a specific spelling rule (e.g., choose the correctly spelled form when adding -ing/-ed), enabling evidence of understanding."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 93.49638652801514,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_042\"\nLINE 11:         'diverse_042', '2.3.0', '{\"request_id\": \"e7832d9e-df...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "0181fd09-fb22-4aac-9415-6627d8f6dab7",
      "evaluations": {
        "diverse_043": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.42,
              "internal_reasoning": "Step 1 – Identify intent: Standalone MCQ practice for Grade 3 spelling patterns (CCSS L.3.2.F). No passage or stimulus. \n\nStep 2 – Issues (commit list):\n- ISSUE1 (factual_accuracy): Stem says “add the suffix -ing to each word,” but keyed correct option C ends with “potatoes,” which is not an -ing form. Quote: stem “…add the suffix “-ing” to each word.” vs option C “…potatoes.” This contradicts the task.\n- ISSUE2 (factual_accuracy): Explanation contains incorrect rule for race → racing: it says “change the silent e to i before adding -ing” (should be “drop the silent e”). Quote: “change the silent e to i before adding -ing.”\n- ISSUE3 (educational_accuracy): Because the keyed answer uses a plural (potatoes) instead of -ing, the item fails to assess the intended skill (adding -ing consistently across all four base words).\n- ISSUE4 (distractor_quality): Option B includes “making,” a word not derived from any of the base words (stop, race, carry, potato). Options A and D include “potating,” which is not a plausible application of adding -ing to “potato.” D also has “carryying,” an implausible error.\n\nChecklists:\n- Checklist A (Field consistency): Fails due to mismatch between stem and keyed answer; also rationale error (“e to i”).\n- Checklist B1 (Giveaway): No giveaways pre-attempt.\n- Checklist B2 (Stimulus quality): No stimulus.\n- Checklist C (Diction/Typo): Stem clear; answer option spellings are intentionally varied; no stray symbols.\n\nStep 3 – Metric scores based on committed issues:\n- factual_accuracy = 0.0 (ISSUE1, ISSUE2)\n- educational_accuracy = 0.0 (ISSUE3)\n- distractor_quality = 0.0 (ISSUE4)\n- All other metrics pass (no independent issues).\n\nStep 4 – Overall per rules: C=2 (factual_accuracy, educational_accuracy), N=1 (distractor_quality). Allowed range = 0.0–0.65. Choose 0.42 reflecting severe contradictions.\n\nStep 5 – Consistency check: Each failed metric maps to a specific issue; no orphan issues.",
              "reasoning": "Major contradiction: the prompt asks for adding -ing to all four base words, but the keyed correct list ends with “potatoes,” which is a plural, not an -ing form. The explanation also misstates the rule for race → racing. Some distractors are weak or irrelevant (e.g., “making,” “potating,” “carryying”). Aside from these, the stem is clear, level-appropriate, and aligned to the standard’s focus on spelling patterns.",
              "suggested_improvements": "- Make stem and correct answer consistent: either (a) replace “potato” with a verb that naturally takes -ing (e.g., go → going, bake → baking, echo → echoing), or (b) if you intend to test plural -es with potato, revise the stem and all options accordingly (but then don’t include -ing words).\n- Fix the explanation: use “drop the silent e before adding -ing” for race → racing; do not say “change e to i.”\n- Ensure all options use the given base words; replace “making” with “racing.”\n- Use more plausible error forms: e.g., raceing (not dropping e), stoping (not doubling p), carriing (changing y to i before -ing). Avoid non-words like “potating” or “carryying.”"
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "Two concrete factual/consistency errors: (1) The keyed correct option C includes “potatoes,” which contradicts the stem’s instruction to add -ing to all four base words. (2) The explanation incorrectly states the rule for race → racing as “change the silent e to i,” whereas the correct rule is “drop the silent e before adding -ing.” These are unambiguous factual/consistency failures.",
              "reasoning": "The keyed correct choice violates the task (uses plural “potatoes” instead of an -ing form), and the explanation misstates the e-dropping rule for forming racing.",
              "suggested_improvements": "- Replace “potatoes” with the appropriate -ing form by changing the base word (e.g., use go → going) or redesign the item. \n- Correct the explanation to “drop the silent e before adding -ing.”"
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "The intended skill is adding -ing to base words (L.3.2.F spelling patterns). Because the keyed answer includes a plural (potatoes) rather than an -ing form, the item fails to assess the stated skill consistently across all four words, undermining its educational purpose.",
              "reasoning": "The task claims to assess adding -ing to all base words, but the keyed answer includes a plural form, so the item does not actually measure the intended skill.",
              "suggested_improvements": "Revise the word set so all four require -ing and adjust the answer key accordingly, or change the prompt to match the actual endings assessed."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral classroom context, no cultural dependencies or sensitive content. Age-appropriate.",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Target standard CCSS.ELA-LITERACY.L.3.2.F (spelling patterns and generalizations) is appropriate for adding suffixes like -ing and handling ending rules. Despite item errors, the intended skill fits the standard; no evidence of a different standard focus.",
              "reasoning": "The intended focus—spelling patterns with suffixes—is aligned to L.3.2.F for Grade 3.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "The stem is clear and unambiguous about the task. The contradiction is factual/consistency, not clarity. No merged non-words or confusing symbols in student-facing instructions.",
              "reasoning": "The prompt clearly states the task; confusion arises from content inconsistency, not wording.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit hard item-spec requirements provided beyond the standard; confidence level is SOFT. No enforceable spec to violate.",
              "reasoning": "No applicable hard specification rules were provided.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Some distractors do reflect common errors (e.g., raceing not dropping e, stoping not doubling p, carring/altering y). Although other distractors are weak, there is still diagnostic value regarding common -ing rules.",
              "reasoning": "Several options capture typical -ing spelling mistakes, offering some diagnostic insight.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided for this standard. Applied own bar: For Grade 3 spelling, “hard” can involve applying multiple rules across several base words (doubling final consonant, dropping silent e, handling y before -ing) simultaneously. The intended task (4 words, multiple rules) matches that bar. Despite content errors, intended cognitive demand is appropriate for a hard item at this grade.",
              "reasoning": "Applying multiple -ing rules across four words is appropriate for a harder Grade 3 item.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context; item is self-contained.",
              "reasoning": "No passage required or referenced.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "Concrete issues: Option B includes “making,” which does not derive from the given base words; Options A and D include “potating,” which is not a plausible -ing formation from potato; D includes “carryying,” an implausible error form. These reduce plausibility and parallelism across choices.",
              "reasoning": "Some distractors are not parallel or plausible (e.g., “making,” “potating,” “carryying”), weakening the set’s quality.",
              "suggested_improvements": "- Ensure all options use only the given base words.\n- Replace weak distractors with plausible errors: raceing, stoping, carriing. Avoid non-words like potating or doubled-y forms.\n- If you keep a word ending in -o, select a verb like go → going or echo → echoing to allow plausible wrong forms (e.g., goeing)."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus is provided; nothing misleading or distracting.",
              "reasoning": "No image or external stimulus to evaluate; not applicable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "The intended task requires applying multiple spelling generalizations, not rote recall of a single fact; it can distinguish partial from full understanding. Despite content flaws, the task type supports mastery learning.",
              "reasoning": "Requires applying rules, not mere recall; good for diagnosing understanding of spelling patterns.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 148.6326982975006,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.42
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "3f579d4a-da7c-41af-a5e9-f8ce2e14ac42",
      "evaluations": {
        "diverse_045": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1: Identified as a practice/assessment MCQ for Grade 3 ELA (L.3.2.G). No stimulus. \n\nStep 2 – Issues:\n- ISSUE1 (educational_accuracy): Option A states “The correct choice that matches the standard.” This trivially reveals the answer pre-attempt (answer giveaway). The item also does not actually assess consulting reference materials/spellings.\n- ISSUE2 (curriculum_alignment): Stem references L.3.2.G, but no task about checking/correcting spellings or using reference materials appears; choices are placeholders.\n- ISSUE3 (clarity_precision): Stem “Which choice best demonstrates the skill described in L.3.2.G at easy difficulty?” uses unexplained standard code and internal difficulty label—unclear/technical for 3rd graders.\n- ISSUE4 (distractor_quality): Choices are meta and self-referential (“The correct choice…”, “An incorrect distractor.”); implausible and telegraph the key.\n- ISSUE5 (mastery_learning_alignment): No reasoning or application is required; students can select the self-identified correct option.\n- ISSUE6 (reveals_misconceptions): Structure provides no opportunity to surface misconceptions about dictionary use/spelling (no authentic task/context).\n- ISSUE7 (difficulty_alignment): Labeled “easy,” but the cognitive demand is trivial (select the option that says it’s correct), at least two grade levels below G3 expectations for the target skill.\n\nChecklist A (Field Consistency): Answer key and explanation both indicate A; no cross-field mismatches.\nChecklist B1 (Answer Giveaway): Yes—answer is trivially visible in Option A text pre-attempt → educational_accuracy failure.\nChecklist B2 (Stimulus Quality): No stimulus present.\nChecklist C (Diction/Typo): No typos; issue is technical/unclear phrasing in stem.\n\nStep 3: Scores set per issues above.\nStep 4: Overall per rules: C=1 (educational_accuracy), N=6 (curriculum_alignment, clarity_precision, distractor_quality, reveals_misconceptions, difficulty_alignment, mastery_learning_alignment). Range 0.55–0.75; choose lower half due to critical failure and multiple non-critical fails.\nStep 5: All issues reflected in metric scores.",
              "reasoning": "The item is meta and non-instructional for 3rd graders: the stem references a standard code and difficulty label, and Option A literally declares itself correct. This trivially gives away the answer, does not assess the stated standard (dictionary/spelling skill), lacks clarity for students, and provides no plausible distractors or diagnostic value. It also requires no reasoning and is far below the intended difficulty for Grade 3 L.3.2.G.",
              "suggested_improvements": "- Replace the stem with a student-friendly, standard-aligned task (e.g., “Which resource would you use to check the spelling of a word?” or “Which is the correct spelling?”). \n- Remove meta references (“L.3.2.G,” “at easy difficulty”). Use plain language. \n- Provide authentic options: e.g., for reference tools—Dictionary, Thesaurus, Atlas, Encyclopedia; for spelling—four variants with one correct spelling. \n- Craft distractors that reflect real misconceptions (e.g., choosing a thesaurus instead of a dictionary; plausible misspellings like “acommodate,” “accomodate” vs “accommodate” adapted to Grade 3 level with simpler words). \n- Ensure students must apply the skill (use guide words or identify correct spelling), not select a self-identified answer. \n- Calibrate to “easy” by using high-frequency words and clear contrasts or a straightforward reference-tools scenario."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No concrete factual claims beyond meta references. Answer key (A) matches the option text and explanation. No contradictions or image issues. Checklist A passed.",
              "reasoning": "No factual errors or internal inconsistencies are present.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: Pre-attempt giveaway—Option A says “The correct choice…,” making the answer trivial. Also, the item does not actually assess L.3.2.G (consulting reference materials/checking spellings). This undermines the educational purpose.",
              "reasoning": "The answer is trivially revealed by Option A, and the item does not require applying the dictionary/spelling-check skill, so it fails to measure the intended learning goal.",
              "suggested_improvements": "Replace with a genuine L.3.2.G task (e.g., identify which tool checks spelling, or choose the correctly spelled word) and remove any self-identifying language in options."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, no cultural references or sensitive content.",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: The standard CCSS.ELA-LITERACY.L.3.2.G focuses on consulting reference materials/beginning dictionaries to check/correct spellings. The item does not include any such task; it only references the code and uses placeholder options.",
              "reasoning": "The question does not assess consulting reference materials or checking/correcting spelling; thus it is misaligned with L.3.2.G.",
              "suggested_improvements": "Create an item that asks students to use or select appropriate reference materials or to identify correct spellings using guide words or simple dictionary entries."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: Stem uses technical/meta language: “Which choice best demonstrates the skill described in L.3.2.G at easy difficulty?” Third graders won’t know L.3.2.G, and “at easy difficulty” is internal jargon, making the task unclear in meaning even if the action (choose an option) is apparent.",
              "reasoning": "The stem’s reference to an unexplained standard code and difficulty label is unclear and inappropriate for 3rd graders.",
              "suggested_improvements": "State the task in plain language (e.g., “Which tool helps you check how to spell a word?”) and remove meta/jargon."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and provides no enforceable item spec. No explicit, prescriptive item-writing rules to enforce.",
              "reasoning": "No clear skill specification to enforce; thus no spec violation.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE6: The structure and content do not present an authentic task tied to dictionary/spelling use; thus the item cannot surface relevant misconceptions (e.g., confusing a thesaurus with a dictionary, misuse of guide words). This is independent of the poor distractor wording.",
              "reasoning": "The item provides no opportunity to diagnose misunderstandings about the target skill.",
              "suggested_improvements": "Use distractors that reflect common confusions (dictionary vs. thesaurus, misreading guide words, plausible misspellings) within a concrete task."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "No Difficulty Definitions provided → Scenario 2. Applied bar: For Grade 3 L.3.2.G, an “easy” item should still require minimal application (e.g., choosing the correct reference tool or the correctly spelled high-frequency word). This item is trivial—students can select Option A solely because it declares itself correct—requiring virtually no application or grade-level reasoning. This is ≥2 grades easier than an appropriate Grade 3 “easy” task.",
              "reasoning": "The problem is far below a reasonable Grade 3 “easy” bar; it requires no application of the intended skill.",
              "suggested_improvements": "Design an easy but authentic task (e.g., select “dictionary” to check spelling or pick the correctly spelled simple word) without self-identifying answers."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context is referenced or required.",
              "reasoning": "N/A—self-contained item.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: Choices are self-referential and implausible (“The correct choice…”, “An incorrect distractor.”). They lack grammatical/semantic plausibility and telegraph the key, failing multiple distractor-quality checks.",
              "reasoning": "Distractors are not plausible and the correct answer is telegraphed by wording.",
              "suggested_improvements": "Write content-based, parallel options tied to the skill (e.g., Dictionary, Thesaurus, Atlas, Encyclopedia) or plausible spelling variants for a simple word."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing harmful or misleading.",
              "reasoning": "No stimulus issues.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE5: The task demands no reasoning or application—students can select the self-identified correct option. This provides no evidence of mastery or understanding of L.3.2.G.",
              "reasoning": "No computation or reasoning is required; getting it right does not indicate understanding.",
              "suggested_improvements": "Require students to apply the skill (e.g., interpret guide words, choose the correct reference tool, or identify correct spelling) so a correct response reflects understanding."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 111.56315779685974,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_045\"\nLINE 11:         'diverse_045', '2.3.0', '{\"request_id\": \"3f579d4a-da...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "request_id": "639f85b8-b4e2-479c-9d0d-ee7f1c737f60",
      "evaluations": {
        "diverse_046": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.74,
              "internal_reasoning": "Step 1 – Intent: Standalone MCQ for Grade 3 ELA, practice/assessment, targeting CCSS.ELA-LITERACY.L.3.2.G (use a beginning dictionary to correct spelling).\n\nStep 2 – Issues:\n- ISSUE1 (factual_accuracy): Problematic pronunciation/respelling for “substantial” in the dictionary entry: \"sub•stan•tial (səb-ˈstan-tē-əl)\". The sequence “tē-əl” implies /tiː-əl/ (“tee-uhl”), whereas standard pronunciation is /səbˈstænʃəl/ (commonly shown in child-friendly respelling as “suhb-STAN-shuhl”). A beginning dictionary would typically show the “-tial” pronounced like “-shəl,” not “tē-əl.” This is a factual inaccuracy in the provided reference entry.\n\nChecklist A (Field Consistency): Answer key B matches options and explanation; consistent – pass.\nChecklist B1 (Answer Giveaway): No explicit answer revealed pre-attempt; dictionary entries appropriately scaffold – pass.\nChecklist B2 (Stimulus Quality): No image; dictionary entries are fine aside from pronunciation accuracy – pass here (the inaccuracy is handled under factual_accuracy, not stimulus_quality).\nChecklist C (Diction/Typo): Wording clear. Minor format mismatch (“underlined” vs bold emphasis) but not confusing – pass.\n\nStep 3 – Metric scores set accordingly (factual_accuracy=0.0 due to ISSUE1; others pass).\nStep 4 – Overall score: C=1 (factual_accuracy fail), N=0 → allowed range 0.70–0.84. Because a critical metric failed, choose lower half → 0.74.\nStep 5 – Consistency: The single cited issue maps to factual_accuracy; all other metrics reflect no issues.\n",
              "reasoning": "Strong item for Grade 3: it asks students to use a beginning dictionary to correct a misspelling, aligns to the standard, and offers plausible distractors. However, the pronunciation/respelling given for “substantial” is inaccurate (“tē-əl” suggests ‘tee-uhl’ rather than the usual ‘-shul’ sound). This factual inaccuracy in the provided dictionary entry necessitates a downgrade. Everything else (clarity, alignment, difficulty, distractors) is solid.",
              "suggested_improvements": "Correct the dictionary pronunciation for “substantial” to reflect the ‘-shul’ sound (e.g., IPA /səbˈstænʃəl/ or child-friendly respelling “suhb-STAN-shuhl”). Optionally, align wording with formatting by saying “underlined (or bolded) word.”"
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The pronunciation/respelling for “substantial” is presented as “səb-ˈstan-tē-əl,” which indicates a /tiː-əl/ (“tee-uhl”) sequence, not the correct ‘-shul’ sound (/ʃəl/). Beginning dictionaries typically represent this as “-shəl.” This is a concrete factual inaccuracy within the student-facing dictionary entry.",
              "reasoning": "The dictionary entry for “substantial” shows an incorrect pronunciation/respelling, which is a factual error in the provided reference material.",
              "suggested_improvements": "Change the pronunciation to a correct form, e.g., IPA /səbˈstænʃəl/ or a kid-friendly respelling like “suhb-STAN-shuhl.”"
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The task directly measures consulting a beginning dictionary to correct spelling, with POS cues and definitions. No pre-attempt answer giveaway. The instructional focus is appropriate for Grade 3.",
              "reasoning": "Effectively assesses using a dictionary to choose the correct spelling and part of speech; no answer giveaway.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral U.S. English context, age-appropriate, no cultural sensitivities.",
              "reasoning": "Culturally neutral and age-appropriate; no localization issues.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly targets CCSS.ELA-LITERACY.L.3.2.G: consult a beginning dictionary to check and correct spellings. The prompt and entries match the standard.",
              "reasoning": "Directly aligned to L.3.2.G: using a beginning dictionary to correct spelling.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Prompt is clear about replacing the misspelled, emphasized word. Minor mismatch between “underlined” vs bold emphasis does not create real ambiguity. Students can easily identify the target word.",
              "reasoning": "Clear instructions and unambiguous task; wording is straightforward for Grade 3.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit hard item spec provided beyond the standard; nothing to enforce; therefore compliant by default.",
              "reasoning": "No applicable hard specification constraints were provided; item format is appropriate.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to plausible errors: preserving the misspelling (A), another common-type misspelling (C), and choosing a different word from the dictionary list (D) ignoring part of speech/meaning.",
              "reasoning": "Options target likely errors (keeping the misspelling, similar-looking misspelling, or wrong dictionary entry).",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2 (no difficulty definitions provided). For Grade 3 L.3.2.G, “Hard” can involve: using dictionary entries with part-of-speech and meaning cues to resolve a non-trivial misspelling among close distractors. This item fits: students must match POS (adjective), use meaning, and discriminate among similar spellings, which is relatively challenging for Grade 3.",
              "reasoning": "Cognitive demand (using POS and meaning from entries to resolve a tricky misspelling) is appropriate for a “hard” Grade 3 item.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage; the item is self-contained.",
              "reasoning": "No external passage required or referenced; N/A and acceptable.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are parallel (single-word spellings), plausible, and not obviously ruled out without reasoning. Length and specificity are balanced; the correct answer is not telegraphed by format.",
              "reasoning": "Well-constructed, plausible distractors aligned to common errors; balanced and parallel.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No image stimulus. Dictionary entries are appropriate as text stimulus; the pronunciation inaccuracy is handled under factual_accuracy rather than stimulus quality, since the stimulus itself isn’t misleading in form.",
              "reasoning": "Textual stimulus (dictionary entries) is appropriate and not distracting.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying reference skills (selecting correct spelling based on POS and meaning), not mere recall; diagnostic value present.",
              "reasoning": "Students must use reference material and reasoning, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 89.05975317955017,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.74
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "08520765-8e3e-4d95-8971-887278ae6616",
      "evaluations": {
        "diverse_050": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.74,
              "internal_reasoning": "Step 1 – Intent: Standalone MCQ for Grade 3 ELA (practice/assessment). No reveal cues; answer key/explanation treated as metadata/help for verification only.\n\nStep 2 – Issues:\n- ISSUE1 (factual_accuracy): In answer_explanation: \"'little' suggests the opposite of hungry\". This is inaccurate. \"little\" does not mean the opposite of hungry; in this slot it is ungrammatical without 'a' and, with 'a', would mean \"slightly hungry,\" not the opposite. This is a concrete factual/misleading statement in the metadata rationale.\n- ISSUE2 (distractor_quality): Option D \"little\" produces an ungrammatical sentence (\"was little hungry\"). It is an obviously implausible distractor compared to the others, reducing quality/diagnostic value and breaking grammatical parallelism with the other adverbs/adjectives that do fit.\n\nChecklist A (Field consistency): Correct answer C matches options; rationale otherwise consistent. One inaccurate claim about D noted above. \nChecklist B1 (Answer giveaway): None in student-facing text. \nChecklist B2 (Stimulus): No stimulus. \nChecklist C (Typos/diction): No typos in student-facing text; stem is clear.\n\nStep 3 – Metric scores anchored to issues above. \nStep 4 – Overall: C=1 (factual_accuracy fail), N=1 (distractor_quality fail) → allowed range 0.70–0.84. Because a critical metric failed, choose lower half → 0.74.\nStep 5 – Self-consistency: Each 0.0 has a cited issue; all other metrics pass.",
              "reasoning": "Strong, well-aligned item assessing word choice for effect. The keyed answer (ravenous) is appropriate and the stem is clear. However, the explanation incorrectly states that “little” suggests the opposite of hungry, and one distractor (“little”) is grammatically implausible in the blank, reducing distractor quality. Fixing these would make the item solid.",
              "suggested_improvements": "- Revise the explanation: note that “little” does not fit grammatically here; with ‘a’ it would mean “slightly hungry,” which is not very hungry.\n- Replace D with a plausible, grammatically fitting but incorrect choice such as “slightly” or “somewhat” to contrast intensity without being the strongest choice."
            },
            "factual_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: The explanation claims: \"'little' suggests the opposite of hungry.\" This is untrue. \"little\" does not mean the opposite of hungry; in context it is ungrammatical without 'a' and, with 'a', means a small degree of hunger. Since explanations are part of supporting content and must be accurate, this is a factual accuracy failure.",
              "reasoning": "The rationale contains an inaccurate claim about the meaning/use of “little” in this context.",
              "suggested_improvements": "Change the line to: “'Little' does not work here; you would need ‘a little,’ which means ‘slightly hungry,’ not ‘very hungry.’”"
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The item clearly targets L.3.3.A (choosing words for effect). No pre-attempt answer giveaway. The keyed answer rightly emphasizes a vivid, precise word choice. Instructional intent is met.",
              "reasoning": "It effectively assesses choosing a vivid word to convey intensity, matching the intended standard, with no answer giveaway.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, age-appropriate context (puppy, park). No cultural sensitivities or region-specific dependencies.",
              "reasoning": "Culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Directly aligns to CCSS.ELA-LITERACY.L.3.3.A: selecting words/phrases for effect. The prompt asks for the best word to create a vivid effect indicating very hungry.",
              "reasoning": "Directly aligned to the standard on choosing words for effect.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "The stem is explicit about the goal: make the sentence more vivid and show very hungry. No ambiguous instructions. Grammar and structure are clear.",
              "reasoning": "Clear, unambiguous wording and task.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context is SOFT and provides no explicit item-writing spec. No enforceable specs identified; thus no violation.",
              "reasoning": "No explicit specification to enforce; item follows common MCQ norms.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors A (“very”) and B (“quite”) plausibly reflect weaker or plain intensifiers students might choose, revealing misunderstanding about strength/vividness. D is weak, but A/B suffice for diagnostic value.",
              "reasoning": "Plausible alternatives (especially A and B) can reveal confusion about intensity/vividness.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "No Difficulty Definitions provided in context. Applied own bar: For Grade 3 L.3.3.A, Medium difficulty = selecting the strongest/vivid word among plausible choices; may include one less-common vocabulary item requiring context reasoning. Here, students weigh intensity (“very/quite” vs. “ravenous”). Vocabulary makes it moderate but appropriate—not ≥2 grade levels off.",
              "reasoning": "Cognitive demand is appropriate for Grade 3: choosing the strongest word for effect among plausible options.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "Self-contained sentence; no passage. N/A but passes.",
              "reasoning": "No passage needed or referenced.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: Option D (“little”) yields an ungrammatical sentence (“was little hungry”) and is not a plausible or parallel alternative to the others. This weakens the set’s plausibility balance.",
              "reasoning": "One distractor is clearly implausible/ungrammatical, reducing the quality of the choices.",
              "suggested_improvements": "Replace D with a grammatically fitting, milder alternative such as “slightly” or “somewhat” so all options are plausible but only one is best for vivid effect."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus provided; nothing misleading or distracting.",
              "reasoning": "No stimulus; not applicable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying understanding of word choice for effect, not rote recall. Students must compare intensity/vividness across options.",
              "reasoning": "Students must apply reasoning about word intensity and effect, supporting mastery learning.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 88.96480464935303,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.74
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "b21dd128-6426-4aaf-9460-3a96d7e5ab83",
      "evaluations": {
        "diverse_052": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "ACCEPTABLE",
            "overall": {
              "score": 0.96,
              "internal_reasoning": "Step 1: Identified student-facing stem and options; explanation treated as metadata. Item type: practice MCQ.\nStep 2: Issues check—none found. Checklist A (field consistency): Answer key D matches reasoning; explanation aligns with options. Checklist B (giveaway): No pre-attempt answer giveaway. Checklist C (diction/typos): Clean; no merged words or confusing symbols.\nVerification: The original sentence includes informal/nonstandard elements (objective case pronoun as subject “Me,” singular verb with compound subject “was,” colloquial “gonna”). Option D corrects all: “My cousin and I were going to ride the roller coaster, but it was too scary.” Other options each leave at least one issue.\nScoring: C=0 critical fails, N=0 non-critical fails → choose within 0.85–1.0. Solid construction but not unusually exceptional → 0.96.",
              "reasoning": "Well-constructed MCQ that accurately targets differences between spoken and written standard English. The correct option fully corrects pronoun case, subject–verb agreement, and formality. Distractors are plausible and diagnostic. No clarity or alignment issues.",
              "suggested_improvements": null
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "Independent check: D is the only option that fixes all issues (subject pronoun “I,” plural verb “were,” standard “going to”). A retains “was” and “gonna”; B retains “Me and my cousin” as subject; C retains “was” with plural subject. Explanation is consistent with this analysis. No contradictions or mismatches.",
              "reasoning": "The labeled correct answer is truly correct, and the explanation matches the options and reasoning.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 1.0,
              "internal_reasoning": "The item evaluates recognizing/applying conventions of written standard English from a spoken-like sentence. No pre-attempt giveaways. Cognitive demand is appropriate for Grade 3 knowledge-of-language focus (pronoun case, verb agreement, register).",
              "reasoning": "Directly assesses the intended skill without revealing the answer and at an appropriate level for the objective.",
              "suggested_improvements": null
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral, age-appropriate context (roller coaster). Uses en-US conventions. No cultural sensitivities or stereotypes required to answer.",
              "reasoning": "Culturally neutral and age-appropriate; fits the en-US locale.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 1.0,
              "internal_reasoning": "Targets CCSS.ELA-LITERACY.L.3.3.B: recognizing/observing differences between spoken and written standard English. The task requires choosing the sentence that conforms to written conventions from a colloquial original.",
              "reasoning": "Well-aligned to the Grade 3 Knowledge of Language standard on spoken vs. written conventions.",
              "suggested_improvements": null
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "Stem clearly states the task and provides the source sentence. No ambiguous instructions; grammar and punctuation are clear. Students know they must choose the best rewritten sentence.",
              "reasoning": "Prompt is unambiguous and precisely worded for Grade 3.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "No explicit hard item-writing specifications provided in the curriculum context (SOFT). Per rules, pass by default.",
              "reasoning": "No applicable hard spec to enforce; nothing violates common item-writing norms.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 1.0,
              "internal_reasoning": "Distractors map to common errors: A (keeps ‘was’ + ‘gonna’), B (subject pronoun case error ‘Me’), C (verb agreement error ‘was’). These are plausible choices reflecting partial understanding.",
              "reasoning": "Incorrect options reflect realistic student misconceptions, enabling diagnostic insight.",
              "suggested_improvements": null
            },
            "difficulty_alignment": {
              "score": 1.0,
              "internal_reasoning": "Scenario 2: No Difficulty Definitions provided. Applied bar: For Grade 3 L.3.3.B, “Hard” can involve integrating multiple conventions (pronoun case, subject–verb agreement, register) and selecting the single option that fixes all. This item fits that bar—students must evaluate several conventions simultaneously—appropriate for the high end of Grade 3 without exceeding by 2+ grade levels.",
              "reasoning": "Difficulty is appropriate for a challenging Grade 3 item requiring multiple convention checks.",
              "suggested_improvements": null
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "Self-contained sentence; no external passage required or referenced.",
              "reasoning": "No passage involved; references are clear and contained in the item.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 1.0,
              "internal_reasoning": "Choices are grammatically parallel, similar length, and each is plausible by fixing some but not all errors. No length or specificity imbalances telegraph the answer.",
              "reasoning": "Strong, plausible distractors with good parallelism and diagnostic value.",
              "suggested_improvements": null
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No external stimulus present; nothing misleading or distracting.",
              "reasoning": "Not applicable—no stimulus to evaluate; no harm introduced.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 1.0,
              "internal_reasoning": "Requires applying multiple conventions simultaneously to judge correctness (pronoun case, agreement, register). Not mere recall; provides diagnostic evidence of understanding.",
              "reasoning": "Supports mastery by requiring multi-criterion evaluation rather than simple recall.",
              "suggested_improvements": null
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 59.061517000198364,
      "inceptbench_version": "2.3.0",
      "errors": [],
      "overall_score": 0.96
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "e71d5457-6812-48b1-a0a1-77203a2a234f",
      "evaluations": {
        "diverse_055": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1: Determined item is a standalone MCQ (practice/assessment), not instructional. Target standard inferred: CCSS.ELA-LITERACY.L.3.4.A (use sentence-level context clues). No stimulus.\n\nStep 2 – Issues:\n- ISSUE1 (educational_accuracy): Option A text is “The correct choice that matches the standard.” This trivially gives away the answer in student-facing content for a practice/assessment item.\n- ISSUE2 (curriculum_alignment): Stem “Which choice best demonstrates the skill described in L.3.4.A at hard difficulty?” and generic options do not assess using sentence-level context to determine word meaning. No sentence/context provided.\n- ISSUE3 (clarity_precision): Reference to “L.3.4.A” is not student-friendly; 3rd graders are unlikely to know standard codes. Task is unclear: no sentence or word to analyze.\n- ISSUE4 (distractor_quality): B/C/D are “An incorrect distractor.” / “Another incorrect distractor.” → implausible, generic, and telegraph wrongness.\n- ISSUE5 (reveals_misconceptions): Because choices are generic and implausible, the item cannot diagnose misconceptions about context clues.\n- ISSUE6 (difficulty_alignment): Labeled “hard” but the task is trivial (answer labeled as correct) and does not require multi-step reasoning.\n- ISSUE7 (mastery_learning_alignment): No reasoning/application required; it’s meta and answer is self-identified.\n\nChecklist A (Field Consistency): Answer key A matches option A; explanation consistent. No mismatches.\nChecklist B1 (Answer Giveaway): Fails—answer is explicit in option A text, pre-attempt.\nChecklist B2 (Stimulus Quality): No stimulus.\nChecklist C (Diction/Typo): No typos; clarity problem due to code-like reference, not typos.\n\nStep 3: Metric scores assigned accordingly.\nStep 4: C=1 (educational_accuracy), N=6 (clarity, curriculum, distractor, reveals_misconceptions, difficulty, mastery) → overall range 0.55–0.75. Lower half chosen due to critical fail and multiple non-critical fails.\nStep 5: Consistency checked: every failed metric tied to a specific issue.",
              "reasoning": "The item is a placeholder-style MCQ that does not actually assess using sentence-level context. It references a standard code students wouldn’t understand and gives away the answer via option A’s wording. Distractors are generic and implausible, so the question lacks diagnostic value, does not align to the stated standard, and does not require meaningful reasoning. Overall quality is poor for student use.",
              "suggested_improvements": "- Replace the stem with a student-friendly prompt tied to an actual sentence, e.g., “Read the sentence: ‘The kitten was famished after playing all day.’ What does ‘famished’ most likely mean?”\n- Provide context-rich sentences where the target word’s meaning must be inferred from surrounding clues.\n- Remove standard codes from student-facing text; use clear language about the task.\n- Write plausible distractors reflecting common misconceptions (e.g., antonym, unrelated meaning, partial-cue misread) and one correct meaning.\n- To reach hard difficulty, make context clues subtle or competing (multiple possible meanings, requiring synthesis of several cues).\n- Ensure the correct answer is not telegraphed by wording or length; keep options parallel and specific."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No factual claims beyond labeling A as correct; explanation and key are consistent with provided options. No image/passage contradictions or field mismatches.",
              "reasoning": "There are no factual claims to be wrong, and the labeled correct answer matches the options and explanation.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: Trivial answer giveaway—option A literally states it is the correct choice. Also, the item does not assess the intended skill (no sentence/context clues task). As a practice/assessment item, this undermines purpose.",
              "reasoning": "Option A’s text reveals the correct answer, and the item does not require using sentence-level context to determine meaning.",
              "suggested_improvements": "Create a real context-clue task with an unfamiliar word in a sentence and plausible meaning options; avoid any wording that signals the correct answer."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral language, no cultural references or sensitive content. Age-appropriate tone (despite meta nature).",
              "reasoning": "Content is culturally neutral and age-appropriate.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: L.3.4.A targets using sentence-level context to infer meaning. The item has no sentence or target word; options are meta placeholders. Clear misalignment.",
              "reasoning": "The question does not measure using context clues as described by L.3.4.A.",
              "suggested_improvements": "Provide a sentence with contextual clues and ask for the meaning of a highlighted word; ensure options reflect real semantic choices."
            },
            "clarity_precision": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: The stem references “L.3.4.A” (a code students won’t understand) and lacks a concrete task (no sentence/word). Students could interpret it as needing to know the standard code or simply pick the option admitting correctness, which changes their approach.",
              "reasoning": "The stem is not student-friendly and does not clearly state the action; referencing a standard code confuses 3rd graders.",
              "suggested_improvements": "Use student-facing language and provide a concrete task: include a sentence and ask what a highlighted word means using clues from the sentence."
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context confidence is SOFT and provides no enforceable item-format spec. No explicit hard requirements cited; thus cannot claim a spec violation.",
              "reasoning": "No clear, enforceable item specification applies.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE5: Distractors are generic and implausible, offering no insight into context-clue misconceptions (e.g., choosing antonyms, relying on single misleading clue).",
              "reasoning": "Choices do not target plausible errors about context clues, limiting diagnostic value.",
              "suggested_improvements": "Design distractors around common errors: picking a near-synonym that ignores key clue words, choosing a word that matches tone but not meaning, or relying on a single misleading clue."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "No Difficulty Definitions available; applying own bar: Hard (for L.3.4.A) would require subtle/multiple context clues or competing plausible meanings. Actual item is trivial (answer self-labeled) and does not engage the skill at all, so difficulty labeling is mismatched.",
              "reasoning": "The item is not hard; it is trivial due to the self-identified correct option and absence of the target skill.",
              "suggested_improvements": "Increase difficulty by providing nuanced context requiring synthesis of multiple clues and carefully crafted plausible distractors."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage/stimulus is provided or required; nothing to reference.",
              "reasoning": "Not applicable; passes by default.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: Distractors are overtly generic (“An incorrect distractor.”), not parallel in meaning, implausible, and telegraph the correct answer by contrast with A.",
              "reasoning": "Choices are not plausible or well-constructed, and the correct answer is telegraphed.",
              "suggested_improvements": "Write four parallel, specific options that could each plausibly fit the sentence’s clues; avoid meta labels and keep lengths/details balanced."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus present; nothing harmful or misleading.",
              "reasoning": "No image or passage to evaluate; pass.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE7: No reasoning or application is required; the answer is effectively declared within an option and no context-clues task exists.",
              "reasoning": "Does not require students to apply context-clue reasoning; purely meta and trivial.",
              "suggested_improvements": "Require students to infer meaning from sentence-level clues and justify the choice implicitly via well-constructed options that reflect different interpretations."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 74.37362957000732,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_055\"\nLINE 11:         'diverse_055', '2.3.0', '{\"request_id\": \"e71d5457-68...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "request_id": "c8350876-f5a2-4fde-9f69-6d77ed3bedb8",
      "evaluations": {
        "diverse_057": {
          "inceptbench_new_evaluation": {
            "content_type": "question",
            "overall_rating": "INFERIOR",
            "overall": {
              "score": 0.6,
              "internal_reasoning": "Step 1 – Intent/type: Standalone MCQ, practice/assessment. Target standard inferred: CCSS.ELA-LITERACY.L.3.4.B (affixes). Grade 3.\n\nStep 2 – Issues (committed list):\nISSUE1 (educational_accuracy): Giveaway in option text. Snippet: \"A) The correct choice that matches the standard.\" This trivially signals the correct answer pre-attempt.\nISSUE2 (curriculum_alignment): Misaligned with L.3.4.B; the stem asks, \"Which choice best demonstrates the skill described in L.3.4.B at easy difficulty?\" but offers no affix/content task; options are meta-labels, not about affixes.\nISSUE3 (reveals_misconceptions): Distractors are placeholders (\"An incorrect distractor.\") and do not reflect plausible misconceptions about affixes.\nISSUE4 (distractor_quality): Choices are not plausible and the correct option is telegraphed by wording (“The correct choice…”). Poor diagnostic quality and telegraphing.\nISSUE5 (difficulty_alignment): Labeled \"easy\" for Grade 3, but task is trivial (select the option that literally says it’s correct). At least two grade levels easier than intended skill application.\nISSUE6 (mastery_learning_alignment): Requires no reasoning/application of L.3.4.B; success depends on noticing meta-labeling, not understanding affixes.\n\nChecklist A – Field consistency: Answer key A matches explanation \"Option A is correct…\" and options exist. No cross-field mismatches.\nChecklist B1 – Giveaway (practice/assessment): Yes; explicit giveaway in option A text before attempt.\nChecklist B2 – Stimulus quality: No stimulus.\nChecklist C – Diction/typos: No merged non-words or stray symbols. Stem references a standard code, which is not student-friendly but not an ambiguity per se.\n\nStep 3 – Metric scoring based on issues:\n- factual_accuracy: Pass (no factual contradictions/mislabeled answer relative to this meta content)\n- educational_accuracy: Fail (ISSUE1, also off-purpose)\n- curriculum_alignment: Fail (ISSUE2)\n- clarity_precision: Pass (the action—choose an option—is clear; though not student-friendly, it’s not ambiguous under the strict rule)\n- specification_compliance: Pass (no enforceable spec provided; Confidence SOFT)\n- reveals_misconceptions: Fail (ISSUE3)\n- difficulty_alignment: Fail (ISSUE5; ≥2-grade mismatch due to triviality)\n- passage_reference: Pass (no passage)\n- distractor_quality: Fail (ISSUE4)\n- stimulus_quality: Pass (no stimulus)\n- mastery_learning_alignment: Fail (ISSUE6)\n- localization_quality: Pass (neutral/appropriate)\n\nStep 4 – Overall per rules: C=1 (educational_accuracy), N=5 (curriculum_alignment, reveals_misconceptions, difficulty_alignment, distractor_quality, mastery_learning_alignment). Range 0.55–0.75; choose lower half due to a critical failure and multiple non-critical failures → 0.60.\n\nStep 5 – Consistency: Each 0.0 metric maps to a specific committed issue; no stray failures.",
              "reasoning": "Major issues: the correct answer is explicitly telegraphed by option A’s wording, and the item does not actually assess L.3.4.B (affix meaning). Distractors are placeholders that don’t reflect misconceptions, making the item non-diagnostic. Difficulty is trivial because success requires only spotting the “correct choice” label, not applying the target skill. Other dimensions (factual accuracy, clarity of action, stimulus, localization) are acceptable.",
              "suggested_improvements": "Rewrite as an actual L.3.4.B task with student-friendly language and meaningful options. Example: Stem—“What does the word ‘preheat’ mean?” Choices—A) to heat before cooking (correct), B) to heat again, C) to cool down, D) to make something very hot suddenly. Use familiar base words and common prefixes/suffixes for easy difficulty. Ensure distractors reflect plausible misconceptions (e.g., confusing pre- with re-, or antonym choice). Remove any meta-labels that reveal the answer."
            },
            "factual_accuracy": {
              "score": 1.0,
              "internal_reasoning": "No contradictions or incorrect facts presented; answer key (A) matches the explanation. Although content is meta and low-quality, that is not a factual error under the rubric.",
              "reasoning": "Answer key and explanation are internally consistent; no factual statements are wrong.",
              "suggested_improvements": null
            },
            "educational_accuracy": {
              "score": 0.0,
              "internal_reasoning": "ISSUE1: Option A explicitly says it is correct, creating a pre-attempt giveaway in a practice/assessment item. Also, the item does not assess the intended skill (no affix task).",
              "reasoning": "The correct answer is trivially revealed by the option text, and the item does not actually assess understanding of affixes as intended.",
              "suggested_improvements": "Replace meta-language with a real affix task and plausible options; avoid any wording that signals correctness in the option itself."
            },
            "localization_quality": {
              "score": 1.0,
              "internal_reasoning": "Neutral language; no culturally specific or sensitive content. Age-appropriate.",
              "reasoning": "Content is culturally neutral and appropriate for a broad US audience.",
              "suggested_improvements": null
            },
            "curriculum_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE2: L.3.4.B targets meaning of words formed by adding affixes. The item references the standard but provides no affix-based task or vocabulary, so it is misaligned.",
              "reasoning": "Although it names the standard, the item doesn’t measure it; no affix or derived-word meaning is involved.",
              "suggested_improvements": "Pose a question using a familiar base word and a common prefix/suffix (e.g., un-, re-, pre-, -less) and ask for the derived meaning."
            },
            "clarity_precision": {
              "score": 1.0,
              "internal_reasoning": "The directive to choose an option is clear; while referencing a standard code is not student-friendly, the action required is unambiguous under the strict criteria.",
              "reasoning": "Students can tell they must select an answer; no ambiguous phrasing or conflicting interpretations in the prompt itself.",
              "suggested_improvements": null
            },
            "specification_compliance": {
              "score": 1.0,
              "internal_reasoning": "Curriculum context marked SOFT with no explicit enforceable item spec; thus no spec violation can be asserted.",
              "reasoning": "No clear, prescriptive item-spec requirements were provided to enforce.",
              "suggested_improvements": null
            },
            "reveals_misconceptions": {
              "score": 0.0,
              "internal_reasoning": "ISSUE3: Distractors are placeholders and do not target plausible misunderstandings about affixes.",
              "reasoning": "Incorrect choices are not linked to realistic student errors, so the item has little diagnostic value.",
              "suggested_improvements": "Design distractors around common confusions (e.g., prefix pre- vs re-, interpreting -less as “less than” rather than “without”)."
            },
            "difficulty_alignment": {
              "score": 0.0,
              "internal_reasoning": "No Difficulty Definitions provided; applying Scenario 2 rules. For Grade 3 L.3.4.B, an “easy” item should require applying prefix/suffix meaning to a familiar base word. Here, the task is trivial (identify the option that says it’s correct), which is ≥2 grade levels easier than intended; it demands no application of the standard.",
              "reasoning": "The item is far easier than a Grade 3 “easy” affix task because it requires no language analysis or application.",
              "suggested_improvements": "Create a one-step application task using very common affixes and high-frequency base words; avoid meta cues that reveal the answer."
            },
            "passage_reference": {
              "score": 1.0,
              "internal_reasoning": "No passage or external context to reference.",
              "reasoning": "Not applicable; item is self-contained.",
              "suggested_improvements": null
            },
            "distractor_quality": {
              "score": 0.0,
              "internal_reasoning": "ISSUE4: Distractors are generic placeholders and not plausible; the correct answer is telegraphed by meta wording. This violates plausibility and makes the correct option stand out.",
              "reasoning": "Choices do not present realistic alternatives and the correct option is obvious from its wording.",
              "suggested_improvements": "Write parallel, content-based options with similar style/length; avoid meta labels. Ensure each distractor reflects a specific, plausible misconception."
            },
            "stimulus_quality": {
              "score": 1.0,
              "internal_reasoning": "No stimulus; nothing harmful or misleading.",
              "reasoning": "No image or additional stimulus to evaluate; thus acceptable.",
              "suggested_improvements": null
            },
            "mastery_learning_alignment": {
              "score": 0.0,
              "internal_reasoning": "ISSUE6: The item elicits no reasoning or application of affix knowledge; success depends on recognizing meta-labeling in options, not mastery of the skill.",
              "reasoning": "Does not require understanding or applying affix meaning; purely trivial selection.",
              "suggested_improvements": "Require students to interpret the meaning of a derived word using affix knowledge to demonstrate understanding."
            },
            "subcontent_evaluations": null
          }
        }
      },
      "evaluation_time_seconds": 70.36157441139221,
      "inceptbench_version": "2.3.0",
      "errors": [
        "Could not save evaluation result to the DB: invalid input syntax for type integer: \"diverse_057\"\nLINE 11:         'diverse_057', '2.3.0', '{\"request_id\": \"c8350876-f5...\n                 ^\n"
      ],
      "overall_score": 0.6
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    },
    {
      "overall_score": 0.0,
      "status": "error",
      "message": "HTTP 500: Internal Server Error | 服务器返回: {\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n ",
      "response_body": "{\"detail\":\"Runner Failed: InceptBench Logic Error: libxcb.so.1: cannot open shared object file: No such file or directory\\nTrace: Traceback (most recent call last):\\n  File \\\"/app/runner.py\\\", line 25, in main\\n    result = client.evaluate_dict(request_payload)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/client.py\\\", line 28, in evaluate_dict\\n    return evaluate_with_routing(data)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/src/inceptbench/orchestrator.py\\\", line 3160, in evaluate_with_routing\\n    from inceptbench_new.service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/__init__.py\\\", line 26, in <module>\\n    from .service import EvaluationService\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/service.py\\\", line 14, in <module>\\n    from .orchestrator.evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/__init__.py\\\", line 9, in <module>\\n    from .evaluation_orchestrator import EvaluationOrchestrator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/orchestrator/evaluation_orchestrator.py\\\", line 16, in <module>\\n    from inceptbench_new.evaluators.article import ArticleEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/article.py\\\", line 15, in <module>\\n    from .base import BaseEvaluator\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/evaluators/base.py\\\", line 21, in <module>\\n    from inceptbench_new.tools.image_analyzer import analyze_images, format_analysis_for_prompt\\n  File \\\"/app/incept_versions/2.3.0/usr/src/app/inceptbench_new/tools/image_analyzer.py\\\", line 21, in <module>\\n    import cv2\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 181, in <module>\\n    bootstrap()\\n  File \\\"/usr/local/lib/python3.11/site-packages/cv2/__init__.py\\\", line 153, in bootstrap\\n    native_module = importlib.import_module(\\\"cv2\\\")\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/local/lib/python3.11/importlib/__init__.py\\\", line 126, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nImportError: libxcb.so.1: cannot open shared object file: No such file or directory\\n\"}"
    }
  ],
  "avg_score": 0.12,
  "pass_count": 15,
  "pass_rate": 6.3,
  "pass_rate_if_errors_as_fail": 6.3
}